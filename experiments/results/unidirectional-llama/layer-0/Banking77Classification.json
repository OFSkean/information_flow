{"dataset_revision": "0fd18e25b25c072e09e0d92ab615fda904d66300", "evaluation_time": 102.12657189369202, "kg_co2_emissions": null, "mteb_version": "1.12.49", "scores": {"test": [{"accuracy": 0.5562662337662337, "f1": 0.5438684987253762, "f1_weighted": 0.5438684987253763, "hf_subset": "default", "languages": ["eng-Latn"], "main_score": 0.5562662337662337, "scores_per_experiment": [{"accuracy": 0.5613636363636364, "f1": 0.5506616854472889, "f1_weighted": 0.550661685447289}, {"accuracy": 0.5107142857142857, "f1": 0.4959194543432485, "f1_weighted": 0.49591945434324847}, {"accuracy": 0.6038961038961039, "f1": 0.5919564633501524, "f1_weighted": 0.5919564633501525}, {"accuracy": 0.5402597402597402, "f1": 0.5334712382917224, "f1_weighted": 0.5334712382917223}, {"accuracy": 0.5178571428571429, "f1": 0.5070681124001925, "f1_weighted": 0.5070681124001925}, {"accuracy": 0.5792207792207792, "f1": 0.5585839159730801, "f1_weighted": 0.5585839159730801}, {"accuracy": 0.587987012987013, "f1": 0.5766974539600959, "f1_weighted": 0.5766974539600959}, {"accuracy": 0.5178571428571429, "f1": 0.5041343810819917, "f1_weighted": 0.5041343810819917}, {"accuracy": 0.5691558441558442, "f1": 0.5557408901357188, "f1_weighted": 0.5557408901357186}, {"accuracy": 0.5743506493506494, "f1": 0.5644513922702714, "f1_weighted": 0.5644513922702714}]}]}, "task_name": "Banking77Classification", "avg_layerwise_entropy": 0.936873851197802, "num_samples": 64}