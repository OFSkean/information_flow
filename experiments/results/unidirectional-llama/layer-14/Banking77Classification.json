{"dataset_revision": "0fd18e25b25c072e09e0d92ab615fda904d66300", "evaluation_time": 131.5358214378357, "kg_co2_emissions": null, "mteb_version": "1.12.49", "scores": {"test": [{"accuracy": 0.6052922077922077, "f1": 0.6039354933887853, "f1_weighted": 0.6039354933887853, "hf_subset": "default", "languages": ["eng-Latn"], "main_score": 0.6052922077922077, "scores_per_experiment": [{"accuracy": 0.6048701298701299, "f1": 0.6038718126006684, "f1_weighted": 0.6038718126006685}, {"accuracy": 0.5938311688311688, "f1": 0.5937690904793512, "f1_weighted": 0.5937690904793511}, {"accuracy": 0.5993506493506493, "f1": 0.5969617879143452, "f1_weighted": 0.5969617879143452}, {"accuracy": 0.5889610389610389, "f1": 0.5854470430691137, "f1_weighted": 0.5854470430691137}, {"accuracy": 0.6087662337662337, "f1": 0.6057077348600847, "f1_weighted": 0.6057077348600846}, {"accuracy": 0.6146103896103896, "f1": 0.6137906599151405, "f1_weighted": 0.6137906599151405}, {"accuracy": 0.6087662337662337, "f1": 0.6088714808637725, "f1_weighted": 0.6088714808637726}, {"accuracy": 0.6025974025974026, "f1": 0.5999277273619028, "f1_weighted": 0.5999277273619029}, {"accuracy": 0.6175324675324675, "f1": 0.6186829499683726, "f1_weighted": 0.6186829499683727}, {"accuracy": 0.6136363636363636, "f1": 0.6123246468551012, "f1_weighted": 0.6123246468551014}]}]}, "task_name": "Banking77Classification", "avg_layerwise_entropy": 0.08441682819079718, "num_samples": 64}