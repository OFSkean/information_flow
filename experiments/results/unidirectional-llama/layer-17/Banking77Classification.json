{"dataset_revision": "0fd18e25b25c072e09e0d92ab615fda904d66300", "evaluation_time": 141.7132785320282, "kg_co2_emissions": null, "mteb_version": "1.12.49", "scores": {"test": [{"accuracy": 0.6437012987012987, "f1": 0.642610220557333, "f1_weighted": 0.642610220557333, "hf_subset": "default", "languages": ["eng-Latn"], "main_score": 0.6437012987012987, "scores_per_experiment": [{"accuracy": 0.6623376623376623, "f1": 0.6597391012379655, "f1_weighted": 0.6597391012379656}, {"accuracy": 0.6314935064935064, "f1": 0.6325178307597189, "f1_weighted": 0.6325178307597189}, {"accuracy": 0.6347402597402597, "f1": 0.6334733597379102, "f1_weighted": 0.6334733597379102}, {"accuracy": 0.6613636363636364, "f1": 0.6616011122583857, "f1_weighted": 0.6616011122583857}, {"accuracy": 0.6230519480519481, "f1": 0.6206879718215682, "f1_weighted": 0.6206879718215681}, {"accuracy": 0.6480519480519481, "f1": 0.6479243053920621, "f1_weighted": 0.6479243053920621}, {"accuracy": 0.6594155844155845, "f1": 0.6592019584917502, "f1_weighted": 0.6592019584917503}, {"accuracy": 0.6285714285714286, "f1": 0.6281708269072943, "f1_weighted": 0.6281708269072943}, {"accuracy": 0.6545454545454545, "f1": 0.6511780939573728, "f1_weighted": 0.6511780939573728}, {"accuracy": 0.6334415584415585, "f1": 0.6316076450093019, "f1_weighted": 0.6316076450093018}]}]}, "task_name": "Banking77Classification", "avg_layerwise_entropy": 0.14657928238104928, "num_samples": 64}