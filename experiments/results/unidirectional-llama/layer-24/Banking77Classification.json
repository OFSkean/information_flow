{"dataset_revision": "0fd18e25b25c072e09e0d92ab615fda904d66300", "evaluation_time": 165.94898128509521, "kg_co2_emissions": null, "mteb_version": "1.12.49", "scores": {"test": [{"accuracy": 0.6606493506493507, "f1": 0.6587997541256321, "f1_weighted": 0.6587997541256321, "hf_subset": "default", "languages": ["eng-Latn"], "main_score": 0.6606493506493507, "scores_per_experiment": [{"accuracy": 0.6392857142857142, "f1": 0.6374293538020639, "f1_weighted": 0.6374293538020639}, {"accuracy": 0.6480519480519481, "f1": 0.6466056408734642, "f1_weighted": 0.6466056408734642}, {"accuracy": 0.6821428571428572, "f1": 0.6793225745669178, "f1_weighted": 0.6793225745669176}, {"accuracy": 0.6714285714285714, "f1": 0.6693625981783431, "f1_weighted": 0.6693625981783432}, {"accuracy": 0.6558441558441559, "f1": 0.6545986769497921, "f1_weighted": 0.6545986769497921}, {"accuracy": 0.6727272727272727, "f1": 0.6713623198060663, "f1_weighted": 0.6713623198060663}, {"accuracy": 0.6548701298701298, "f1": 0.6535543730027149, "f1_weighted": 0.653554373002715}, {"accuracy": 0.6503246753246753, "f1": 0.6494389432563652, "f1_weighted": 0.6494389432563652}, {"accuracy": 0.6613636363636364, "f1": 0.6589050216010829, "f1_weighted": 0.6589050216010828}, {"accuracy": 0.6704545454545454, "f1": 0.6674180392195105, "f1_weighted": 0.6674180392195103}]}]}, "task_name": "Banking77Classification", "avg_layerwise_entropy": 0.3870952220435542, "num_samples": 64}