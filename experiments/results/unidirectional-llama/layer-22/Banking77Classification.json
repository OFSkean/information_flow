{"dataset_revision": "0fd18e25b25c072e09e0d92ab615fda904d66300", "evaluation_time": 163.24599957466125, "kg_co2_emissions": null, "mteb_version": "1.12.49", "scores": {"test": [{"accuracy": 0.6641233766233767, "f1": 0.662009937583073, "f1_weighted": 0.662009937583073, "hf_subset": "default", "languages": ["eng-Latn"], "main_score": 0.6641233766233767, "scores_per_experiment": [{"accuracy": 0.6561688311688312, "f1": 0.653414600030006, "f1_weighted": 0.653414600030006}, {"accuracy": 0.6733766233766234, "f1": 0.6716407193354593, "f1_weighted": 0.6716407193354592}, {"accuracy": 0.6821428571428572, "f1": 0.6805261394946802, "f1_weighted": 0.6805261394946801}, {"accuracy": 0.6603896103896104, "f1": 0.658617323121165, "f1_weighted": 0.6586173231211653}, {"accuracy": 0.662012987012987, "f1": 0.6593125337306635, "f1_weighted": 0.6593125337306635}, {"accuracy": 0.6691558441558442, "f1": 0.6652948758932418, "f1_weighted": 0.665294875893242}, {"accuracy": 0.6564935064935065, "f1": 0.6550650197148605, "f1_weighted": 0.6550650197148605}, {"accuracy": 0.6652597402597402, "f1": 0.665124779105226, "f1_weighted": 0.6651247791052262}, {"accuracy": 0.6558441558441559, "f1": 0.6546748940818834, "f1_weighted": 0.6546748940818834}, {"accuracy": 0.6603896103896104, "f1": 0.6564284913235456, "f1_weighted": 0.6564284913235456}]}]}, "task_name": "Banking77Classification", "avg_layerwise_entropy": 0.31616603700112356, "num_samples": 64}