{"dataset_revision": "0fd18e25b25c072e09e0d92ab615fda904d66300", "evaluation_time": 148.8093330860138, "kg_co2_emissions": null, "mteb_version": "1.12.49", "scores": {"test": [{"accuracy": 0.6476298701298702, "f1": 0.6455176580410882, "f1_weighted": 0.6455176580410881, "hf_subset": "default", "languages": ["eng-Latn"], "main_score": 0.6476298701298702, "scores_per_experiment": [{"accuracy": 0.6584415584415585, "f1": 0.6535393811382936, "f1_weighted": 0.6535393811382935}, {"accuracy": 0.6344155844155844, "f1": 0.6323568374963465, "f1_weighted": 0.6323568374963466}, {"accuracy": 0.6545454545454545, "f1": 0.6533261934525528, "f1_weighted": 0.6533261934525529}, {"accuracy": 0.6451298701298701, "f1": 0.6447047330331572, "f1_weighted": 0.6447047330331573}, {"accuracy": 0.65, "f1": 0.6493394145255209, "f1_weighted": 0.6493394145255209}, {"accuracy": 0.672077922077922, "f1": 0.6720741903259062, "f1_weighted": 0.6720741903259062}, {"accuracy": 0.6451298701298701, "f1": 0.6416957927260079, "f1_weighted": 0.6416957927260077}, {"accuracy": 0.6425324675324675, "f1": 0.6388434232741665, "f1_weighted": 0.6388434232741665}, {"accuracy": 0.6425324675324675, "f1": 0.6403805588172138, "f1_weighted": 0.6403805588172137}, {"accuracy": 0.6314935064935064, "f1": 0.6289160556217157, "f1_weighted": 0.6289160556217156}]}]}, "task_name": "Banking77Classification", "avg_layerwise_entropy": 0.17788392406451223, "num_samples": 64}