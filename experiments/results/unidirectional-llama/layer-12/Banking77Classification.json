{"dataset_revision": "0fd18e25b25c072e09e0d92ab615fda904d66300", "evaluation_time": 123.29776072502136, "kg_co2_emissions": null, "mteb_version": "1.12.49", "scores": {"test": [{"accuracy": 0.6026623376623377, "f1": 0.5994592564109705, "f1_weighted": 0.5994592564109705, "hf_subset": "default", "languages": ["eng-Latn"], "main_score": 0.6026623376623377, "scores_per_experiment": [{"accuracy": 0.5876623376623377, "f1": 0.5834879459606811, "f1_weighted": 0.5834879459606812}, {"accuracy": 0.6191558441558441, "f1": 0.6132318893412717, "f1_weighted": 0.6132318893412717}, {"accuracy": 0.6035714285714285, "f1": 0.5994001995541955, "f1_weighted": 0.5994001995541957}, {"accuracy": 0.5987012987012987, "f1": 0.5972409442417062, "f1_weighted": 0.5972409442417064}, {"accuracy": 0.6058441558441559, "f1": 0.6023058324680809, "f1_weighted": 0.6023058324680811}, {"accuracy": 0.5967532467532467, "f1": 0.5969857646056531, "f1_weighted": 0.596985764605653}, {"accuracy": 0.5876623376623377, "f1": 0.5833197880967608, "f1_weighted": 0.5833197880967607}, {"accuracy": 0.6198051948051948, "f1": 0.6187962196826742, "f1_weighted": 0.6187962196826741}, {"accuracy": 0.6084415584415584, "f1": 0.6035731846990747, "f1_weighted": 0.6035731846990746}, {"accuracy": 0.599025974025974, "f1": 0.5962507954596067, "f1_weighted": 0.5962507954596067}]}]}, "task_name": "Banking77Classification", "avg_layerwise_entropy": 0.06971424926624468, "num_samples": 64}