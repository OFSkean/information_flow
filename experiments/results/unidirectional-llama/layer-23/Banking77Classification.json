{"dataset_revision": "0fd18e25b25c072e09e0d92ab615fda904d66300", "evaluation_time": 161.5290355682373, "kg_co2_emissions": null, "mteb_version": "1.12.49", "scores": {"test": [{"accuracy": 0.650616883116883, "f1": 0.6491520101672751, "f1_weighted": 0.6491520101672752, "hf_subset": "default", "languages": ["eng-Latn"], "main_score": 0.650616883116883, "scores_per_experiment": [{"accuracy": 0.6532467532467533, "f1": 0.652623924550163, "f1_weighted": 0.6526239245501629}, {"accuracy": 0.6373376623376623, "f1": 0.6352898287443938, "f1_weighted": 0.635289828744394}, {"accuracy": 0.6435064935064935, "f1": 0.6405895917485165, "f1_weighted": 0.6405895917485164}, {"accuracy": 0.6558441558441559, "f1": 0.6538368595493139, "f1_weighted": 0.6538368595493138}, {"accuracy": 0.65, "f1": 0.6499669411158617, "f1_weighted": 0.6499669411158621}, {"accuracy": 0.6506493506493507, "f1": 0.6485079599167118, "f1_weighted": 0.6485079599167118}, {"accuracy": 0.6668831168831169, "f1": 0.6645574923989965, "f1_weighted": 0.6645574923989964}, {"accuracy": 0.6662337662337663, "f1": 0.6675153212656241, "f1_weighted": 0.6675153212656241}, {"accuracy": 0.6331168831168831, "f1": 0.6299751312403566, "f1_weighted": 0.6299751312403568}, {"accuracy": 0.6493506493506493, "f1": 0.6486570511428125, "f1_weighted": 0.6486570511428125}]}]}, "task_name": "Banking77Classification", "avg_layerwise_entropy": 0.3513666357484046, "num_samples": 64}