{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 27.452717304229736,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.822298221614227,
        "f1": 0.817959714612044,
        "f1_weighted": 0.8251883379051238,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.822298221614227,
        "scores_per_experiment": [
          {
            "accuracy": 0.8189694482444141,
            "f1": 0.8097211951625973,
            "f1_weighted": 0.8206159450691118
          },
          {
            "accuracy": 0.82124943000456,
            "f1": 0.8202403444678287,
            "f1_weighted": 0.8248020461708113
          },
          {
            "accuracy": 0.8066575467396261,
            "f1": 0.8028394834204305,
            "f1_weighted": 0.8075301675677523
          },
          {
            "accuracy": 0.8276333789329685,
            "f1": 0.8246175327793887,
            "f1_weighted": 0.8331286937261805
          },
          {
            "accuracy": 0.8445052439580484,
            "f1": 0.8380801405874929,
            "f1_weighted": 0.8464447038371419
          },
          {
            "accuracy": 0.8130414956680346,
            "f1": 0.8118870869847602,
            "f1_weighted": 0.8170684281036961
          },
          {
            "accuracy": 0.815093479252166,
            "f1": 0.8124990324686601,
            "f1_weighted": 0.8164170917790968
          },
          {
            "accuracy": 0.8155494756041952,
            "f1": 0.8082603211473102,
            "f1_weighted": 0.8203838031467422
          },
          {
            "accuracy": 0.8235294117647058,
            "f1": 0.8197695866442483,
            "f1_weighted": 0.8280702275721592
          },
          {
            "accuracy": 0.8367533059735522,
            "f1": 0.8316824224577222,
            "f1_weighted": 0.8374222720785469
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.794317673378076,
        "f1": 0.7974934393045652,
        "f1_weighted": 0.7998668323715494,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.794317673378076,
        "scores_per_experiment": [
          {
            "accuracy": 0.8026845637583893,
            "f1": 0.7982422592125428,
            "f1_weighted": 0.8042257901291101
          },
          {
            "accuracy": 0.8,
            "f1": 0.8051879834756769,
            "f1_weighted": 0.8069903966670602
          },
          {
            "accuracy": 0.7548098434004474,
            "f1": 0.7609526585027894,
            "f1_weighted": 0.7591908081765883
          },
          {
            "accuracy": 0.7977628635346756,
            "f1": 0.8031755369911692,
            "f1_weighted": 0.8045662642849207
          },
          {
            "accuracy": 0.8263982102908277,
            "f1": 0.8283922936086969,
            "f1_weighted": 0.8304923419827644
          },
          {
            "accuracy": 0.7950782997762863,
            "f1": 0.8031501198187968,
            "f1_weighted": 0.8014078940145546
          },
          {
            "accuracy": 0.7870246085011185,
            "f1": 0.7926894839661753,
            "f1_weighted": 0.7928316935614272
          },
          {
            "accuracy": 0.8098434004474273,
            "f1": 0.8084840573232538,
            "f1_weighted": 0.8125794905407641
          },
          {
            "accuracy": 0.7422818791946308,
            "f1": 0.7525221341907931,
            "f1_weighted": 0.7599248429755383
          },
          {
            "accuracy": 0.8272930648769575,
            "f1": 0.8221378659557576,
            "f1_weighted": 0.8264588013827673
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}