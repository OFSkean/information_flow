{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "evaluation_time": 147.17669439315796,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.21",
  "scores": {
    "test": [
      {
        "accuracy": 0.42890000000000006,
        "f1": 0.38895106426492626,
        "f1_weighted": 0.45357695276646925,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.42890000000000006,
        "scores_per_experiment": [
          {
            "accuracy": 0.429,
            "f1": 0.389406844079853,
            "f1_weighted": 0.4464190575189386
          },
          {
            "accuracy": 0.428,
            "f1": 0.39324273165857476,
            "f1_weighted": 0.4579126020291195
          },
          {
            "accuracy": 0.462,
            "f1": 0.4098842676649758,
            "f1_weighted": 0.4845374789128967
          },
          {
            "accuracy": 0.4105,
            "f1": 0.35731299095664776,
            "f1_weighted": 0.4342078806431927
          },
          {
            "accuracy": 0.448,
            "f1": 0.4018364271998294,
            "f1_weighted": 0.4743069789887726
          },
          {
            "accuracy": 0.396,
            "f1": 0.3667558284151895,
            "f1_weighted": 0.41663092108383554
          },
          {
            "accuracy": 0.4675,
            "f1": 0.4249375807776035,
            "f1_weighted": 0.49385349260274036
          },
          {
            "accuracy": 0.3995,
            "f1": 0.3720080216761152,
            "f1_weighted": 0.4277447214886903
          },
          {
            "accuracy": 0.4435,
            "f1": 0.4039705849934619,
            "f1_weighted": 0.46260797624962285
          },
          {
            "accuracy": 0.405,
            "f1": 0.37015536522701226,
            "f1_weighted": 0.43754841814688283
          }
        ]
      }
    ]
  },
  "task_name": "EmotionClassification"
}