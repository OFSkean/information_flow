{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "evaluation_time": 57.11174011230469,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.21",
  "scores": {
    "test": [
      {
        "accuracy": 0.40504999999999997,
        "f1": 0.3575580549204852,
        "f1_weighted": 0.4299411728813207,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.40504999999999997,
        "scores_per_experiment": [
          {
            "accuracy": 0.429,
            "f1": 0.35250407126074995,
            "f1_weighted": 0.45485779385613884
          },
          {
            "accuracy": 0.3795,
            "f1": 0.34022950249088263,
            "f1_weighted": 0.4076812700974967
          },
          {
            "accuracy": 0.3785,
            "f1": 0.3513928211450498,
            "f1_weighted": 0.3950900034356163
          },
          {
            "accuracy": 0.4045,
            "f1": 0.3483465794912693,
            "f1_weighted": 0.4218232649967581
          },
          {
            "accuracy": 0.439,
            "f1": 0.38223350483333157,
            "f1_weighted": 0.46064043116035697
          },
          {
            "accuracy": 0.426,
            "f1": 0.3759409416198225,
            "f1_weighted": 0.4491430984876313
          },
          {
            "accuracy": 0.4285,
            "f1": 0.3847088633941101,
            "f1_weighted": 0.45495881348335065
          },
          {
            "accuracy": 0.3785,
            "f1": 0.34375592999348686,
            "f1_weighted": 0.39735852721845183
          },
          {
            "accuracy": 0.387,
            "f1": 0.34954345020849864,
            "f1_weighted": 0.42823751815958
          },
          {
            "accuracy": 0.4,
            "f1": 0.3469248847676501,
            "f1_weighted": 0.4296210079178271
          }
        ]
      }
    ]
  },
  "task_name": "EmotionClassification"
}