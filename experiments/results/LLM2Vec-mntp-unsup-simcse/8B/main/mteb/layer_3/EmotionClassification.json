{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "evaluation_time": 36.557875871658325,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.21",
  "scores": {
    "test": [
      {
        "accuracy": 0.2992,
        "f1": 0.2672546144759043,
        "f1_weighted": 0.3198064454131424,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.2992,
        "scores_per_experiment": [
          {
            "accuracy": 0.2705,
            "f1": 0.24597786777993388,
            "f1_weighted": 0.2868159269571896
          },
          {
            "accuracy": 0.296,
            "f1": 0.2605521726842835,
            "f1_weighted": 0.31292934528585137
          },
          {
            "accuracy": 0.33,
            "f1": 0.28617972357856664,
            "f1_weighted": 0.3512510066481033
          },
          {
            "accuracy": 0.3165,
            "f1": 0.2883813952317555,
            "f1_weighted": 0.33852314020503127
          },
          {
            "accuracy": 0.295,
            "f1": 0.26507585281082596,
            "f1_weighted": 0.3164293414747892
          },
          {
            "accuracy": 0.275,
            "f1": 0.2490652348038419,
            "f1_weighted": 0.30133828048440464
          },
          {
            "accuracy": 0.2955,
            "f1": 0.2662959839299825,
            "f1_weighted": 0.31483500105862605
          },
          {
            "accuracy": 0.2865,
            "f1": 0.25460025475327547,
            "f1_weighted": 0.30328388038164206
          },
          {
            "accuracy": 0.323,
            "f1": 0.28777580703534483,
            "f1_weighted": 0.34677072913658386
          },
          {
            "accuracy": 0.304,
            "f1": 0.2686418521512329,
            "f1_weighted": 0.32588780249920285
          }
        ]
      }
    ]
  },
  "task_name": "EmotionClassification"
}