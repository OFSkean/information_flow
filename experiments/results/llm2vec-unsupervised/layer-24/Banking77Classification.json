{"dataset_revision": "0fd18e25b25c072e09e0d92ab615fda904d66300", "evaluation_time": 170.11254501342773, "kg_co2_emissions": null, "mteb_version": "1.12.49", "scores": {"test": [{"accuracy": 0.828961038961039, "f1": 0.8284448695519714, "f1_weighted": 0.8284448695519714, "hf_subset": "default", "languages": ["eng-Latn"], "main_score": 0.828961038961039, "scores_per_experiment": [{"accuracy": 0.839935064935065, "f1": 0.8397001599607421, "f1_weighted": 0.8397001599607423}, {"accuracy": 0.8327922077922078, "f1": 0.8322779469673172, "f1_weighted": 0.8322779469673172}, {"accuracy": 0.8159090909090909, "f1": 0.814471876109102, "f1_weighted": 0.8144718761091021}, {"accuracy": 0.8198051948051948, "f1": 0.8194630548767954, "f1_weighted": 0.8194630548767957}, {"accuracy": 0.826948051948052, "f1": 0.8266730154552608, "f1_weighted": 0.8266730154552611}, {"accuracy": 0.813961038961039, "f1": 0.8133454774678115, "f1_weighted": 0.8133454774678114}, {"accuracy": 0.825974025974026, "f1": 0.8261158551427691, "f1_weighted": 0.8261158551427691}, {"accuracy": 0.8363636363636363, "f1": 0.8355789047729665, "f1_weighted": 0.8355789047729666}, {"accuracy": 0.8318181818181818, "f1": 0.8306977968425204, "f1_weighted": 0.8306977968425208}, {"accuracy": 0.8461038961038961, "f1": 0.8461246079244283, "f1_weighted": 0.8461246079244286}]}]}, "task_name": "Banking77Classification", "avg_layerwise_entropy": 0.5867129765635695, "num_samples": 64}