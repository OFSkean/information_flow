{"dataset_revision": "0fd18e25b25c072e09e0d92ab615fda904d66300", "evaluation_time": 135.08367037773132, "kg_co2_emissions": null, "mteb_version": "1.12.49", "scores": {"test": [{"accuracy": 0.5010064935064935, "f1": 0.4912726012422991, "f1_weighted": 0.4912726012422991, "hf_subset": "default", "languages": ["eng-Latn"], "main_score": 0.5010064935064935, "scores_per_experiment": [{"accuracy": 0.4792207792207792, "f1": 0.47397337964332886, "f1_weighted": 0.4739733796433288}, {"accuracy": 0.5064935064935064, "f1": 0.4968784711935995, "f1_weighted": 0.49687847119359946}, {"accuracy": 0.49967532467532466, "f1": 0.4870255023128888, "f1_weighted": 0.4870255023128888}, {"accuracy": 0.5292207792207793, "f1": 0.5234174294564464, "f1_weighted": 0.5234174294564463}, {"accuracy": 0.487012987012987, "f1": 0.4799227864267313, "f1_weighted": 0.47992278642673136}, {"accuracy": 0.5012987012987012, "f1": 0.4851350670930331, "f1_weighted": 0.48513506709303317}, {"accuracy": 0.5110389610389611, "f1": 0.49850113108474514, "f1_weighted": 0.4985011310847452}, {"accuracy": 0.5022727272727273, "f1": 0.49193352987113576, "f1_weighted": 0.4919335298711357}, {"accuracy": 0.48993506493506495, "f1": 0.4835331885735838, "f1_weighted": 0.48353318857358374}, {"accuracy": 0.5038961038961038, "f1": 0.492405526767498, "f1_weighted": 0.492405526767498}]}]}, "task_name": "Banking77Classification", "avg_layerwise_entropy": 0.019021819849973576, "num_samples": 64}