{"dataset_revision": "0fd18e25b25c072e09e0d92ab615fda904d66300", "evaluation_time": 140.94957375526428, "kg_co2_emissions": null, "mteb_version": "1.12.49", "scores": {"test": [{"accuracy": 0.6713961038961039, "f1": 0.6651425963016863, "f1_weighted": 0.6651425963016864, "hf_subset": "default", "languages": ["eng-Latn"], "main_score": 0.6713961038961039, "scores_per_experiment": [{"accuracy": 0.6792207792207792, "f1": 0.6713465663565715, "f1_weighted": 0.6713465663565714}, {"accuracy": 0.6928571428571428, "f1": 0.6890792451884394, "f1_weighted": 0.6890792451884395}, {"accuracy": 0.6766233766233766, "f1": 0.6712358633611984, "f1_weighted": 0.6712358633611982}, {"accuracy": 0.6675324675324675, "f1": 0.6612145588497977, "f1_weighted": 0.6612145588497977}, {"accuracy": 0.6399350649350649, "f1": 0.6298875327656335, "f1_weighted": 0.6298875327656336}, {"accuracy": 0.6733766233766234, "f1": 0.669858381001712, "f1_weighted": 0.6698583810017121}, {"accuracy": 0.6834415584415584, "f1": 0.6742982549458408, "f1_weighted": 0.6742982549458408}, {"accuracy": 0.6633116883116883, "f1": 0.6576412236878927, "f1_weighted": 0.6576412236878928}, {"accuracy": 0.6649350649350649, "f1": 0.6568432360187543, "f1_weighted": 0.6568432360187544}, {"accuracy": 0.6727272727272727, "f1": 0.6700211008410223, "f1_weighted": 0.6700211008410226}]}]}, "task_name": "Banking77Classification", "avg_layerwise_entropy": 0.06468321948963784, "num_samples": 64}