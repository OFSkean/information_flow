{"dataset_revision": "0fd18e25b25c072e09e0d92ab615fda904d66300", "evaluation_time": 162.89977741241455, "kg_co2_emissions": null, "mteb_version": "1.12.49", "scores": {"test": [{"accuracy": 0.832987012987013, "f1": 0.8325525181780316, "f1_weighted": 0.8325525181780318, "hf_subset": "default", "languages": ["eng-Latn"], "main_score": 0.832987012987013, "scores_per_experiment": [{"accuracy": 0.8392857142857143, "f1": 0.8377712701854635, "f1_weighted": 0.8377712701854637}, {"accuracy": 0.8350649350649351, "f1": 0.8342353010408153, "f1_weighted": 0.8342353010408152}, {"accuracy": 0.8435064935064935, "f1": 0.8439196784582303, "f1_weighted": 0.8439196784582305}, {"accuracy": 0.8224025974025974, "f1": 0.8214076716989793, "f1_weighted": 0.8214076716989792}, {"accuracy": 0.8217532467532468, "f1": 0.8207966463464537, "f1_weighted": 0.8207966463464539}, {"accuracy": 0.814935064935065, "f1": 0.8167588646328323, "f1_weighted": 0.8167588646328324}, {"accuracy": 0.8282467532467532, "f1": 0.8271261693139055, "f1_weighted": 0.8271261693139058}, {"accuracy": 0.8464285714285714, "f1": 0.8468102136648714, "f1_weighted": 0.8468102136648715}, {"accuracy": 0.8392857142857143, "f1": 0.8385418837320038, "f1_weighted": 0.838541883732004}, {"accuracy": 0.8389610389610389, "f1": 0.8381574827067599, "f1_weighted": 0.83815748270676}]}]}, "task_name": "Banking77Classification", "avg_layerwise_entropy": 0.61742756918023, "num_samples": 64}