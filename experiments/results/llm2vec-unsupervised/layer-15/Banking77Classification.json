{"dataset_revision": "0fd18e25b25c072e09e0d92ab615fda904d66300", "evaluation_time": 172.11735939979553, "kg_co2_emissions": null, "mteb_version": "1.12.49", "scores": {"test": [{"accuracy": 0.7227272727272729, "f1": 0.7206519636810811, "f1_weighted": 0.7206519636810811, "hf_subset": "default", "languages": ["eng-Latn"], "main_score": 0.7227272727272729, "scores_per_experiment": [{"accuracy": 0.7256493506493507, "f1": 0.7211198613768934, "f1_weighted": 0.7211198613768935}, {"accuracy": 0.7142857142857143, "f1": 0.7143742649492969, "f1_weighted": 0.714374264949297}, {"accuracy": 0.7386363636363636, "f1": 0.7371134662725359, "f1_weighted": 0.7371134662725359}, {"accuracy": 0.7350649350649351, "f1": 0.7309714490836697, "f1_weighted": 0.7309714490836696}, {"accuracy": 0.7103896103896103, "f1": 0.7114983197648551, "f1_weighted": 0.7114983197648551}, {"accuracy": 0.7347402597402597, "f1": 0.7329412421217146, "f1_weighted": 0.7329412421217147}, {"accuracy": 0.7126623376623377, "f1": 0.7084657870673702, "f1_weighted": 0.7084657870673702}, {"accuracy": 0.7275974025974026, "f1": 0.7262987975797653, "f1_weighted": 0.7262987975797651}, {"accuracy": 0.7139610389610389, "f1": 0.7112009922463342, "f1_weighted": 0.7112009922463342}, {"accuracy": 0.7142857142857143, "f1": 0.7125354563483769, "f1_weighted": 0.7125354563483769}]}]}, "task_name": "Banking77Classification", "avg_layerwise_entropy": 0.21328021290497504, "num_samples": 64}