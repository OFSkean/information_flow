{"dataset_revision": "0fd18e25b25c072e09e0d92ab615fda904d66300", "evaluation_time": 148.52505469322205, "kg_co2_emissions": null, "mteb_version": "1.12.49", "scores": {"test": [{"accuracy": 0.7131168831168833, "f1": 0.710173516489814, "f1_weighted": 0.710173516489814, "hf_subset": "default", "languages": ["eng-Latn"], "main_score": 0.7131168831168833, "scores_per_experiment": [{"accuracy": 0.6993506493506494, "f1": 0.696026925995828, "f1_weighted": 0.696026925995828}, {"accuracy": 0.712012987012987, "f1": 0.7097758643478009, "f1_weighted": 0.7097758643478009}, {"accuracy": 0.7022727272727273, "f1": 0.6986725375457093, "f1_weighted": 0.6986725375457092}, {"accuracy": 0.698051948051948, "f1": 0.696549517093135, "f1_weighted": 0.6965495170931348}, {"accuracy": 0.7178571428571429, "f1": 0.7121569800940638, "f1_weighted": 0.7121569800940639}, {"accuracy": 0.7292207792207792, "f1": 0.7265511738849256, "f1_weighted": 0.7265511738849255}, {"accuracy": 0.7188311688311688, "f1": 0.7161098567542257, "f1_weighted": 0.7161098567542254}, {"accuracy": 0.7292207792207792, "f1": 0.7258203677241787, "f1_weighted": 0.7258203677241785}, {"accuracy": 0.7051948051948052, "f1": 0.7040290946697864, "f1_weighted": 0.7040290946697864}, {"accuracy": 0.7191558441558441, "f1": 0.7160428467884863, "f1_weighted": 0.7160428467884861}]}]}, "task_name": "Banking77Classification", "avg_layerwise_entropy": 0.119141385927132, "num_samples": 64}