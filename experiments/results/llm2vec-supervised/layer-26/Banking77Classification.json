{"dataset_revision": "0fd18e25b25c072e09e0d92ab615fda904d66300", "evaluation_time": 180.43928027153015, "kg_co2_emissions": null, "mteb_version": "1.12.49", "scores": {"test": [{"accuracy": 0.8789285714285715, "f1": 0.878201127879494, "f1_weighted": 0.878201127879494, "hf_subset": "default", "languages": ["eng-Latn"], "main_score": 0.8789285714285715, "scores_per_experiment": [{"accuracy": 0.8808441558441559, "f1": 0.8808326603594236, "f1_weighted": 0.8808326603594234}, {"accuracy": 0.8769480519480519, "f1": 0.8770186493957343, "f1_weighted": 0.8770186493957346}, {"accuracy": 0.8811688311688312, "f1": 0.8793532258751185, "f1_weighted": 0.879353225875119}, {"accuracy": 0.8821428571428571, "f1": 0.8811247847459253, "f1_weighted": 0.8811247847459251}, {"accuracy": 0.875, "f1": 0.8748370749575384, "f1_weighted": 0.8748370749575382}, {"accuracy": 0.8766233766233766, "f1": 0.8751664975773968, "f1_weighted": 0.8751664975773974}, {"accuracy": 0.8775974025974026, "f1": 0.8769632795070462, "f1_weighted": 0.8769632795070463}, {"accuracy": 0.8837662337662338, "f1": 0.8822924887761938, "f1_weighted": 0.8822924887761935}, {"accuracy": 0.8795454545454545, "f1": 0.8793455477279336, "f1_weighted": 0.8793455477279339}, {"accuracy": 0.8756493506493507, "f1": 0.8750770698726278, "f1_weighted": 0.8750770698726278}]}]}, "task_name": "Banking77Classification", "avg_layerwise_entropy": 0.40204113628167504, "num_samples": 64}