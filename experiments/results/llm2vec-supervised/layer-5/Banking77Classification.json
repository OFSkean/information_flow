{"dataset_revision": "0fd18e25b25c072e09e0d92ab615fda904d66300", "evaluation_time": 143.25851678848267, "kg_co2_emissions": null, "mteb_version": "1.12.49", "scores": {"test": [{"accuracy": 0.7152922077922078, "f1": 0.710385593750654, "f1_weighted": 0.710385593750654, "hf_subset": "default", "languages": ["eng-Latn"], "main_score": 0.7152922077922078, "scores_per_experiment": [{"accuracy": 0.7298701298701299, "f1": 0.7276336596520536, "f1_weighted": 0.727633659652054}, {"accuracy": 0.7133116883116883, "f1": 0.7079606725940913, "f1_weighted": 0.7079606725940912}, {"accuracy": 0.701948051948052, "f1": 0.6993641360632337, "f1_weighted": 0.6993641360632339}, {"accuracy": 0.7146103896103896, "f1": 0.7050661432014291, "f1_weighted": 0.7050661432014292}, {"accuracy": 0.7217532467532467, "f1": 0.7166777527719104, "f1_weighted": 0.7166777527719105}, {"accuracy": 0.7220779220779221, "f1": 0.7171336818620563, "f1_weighted": 0.7171336818620564}, {"accuracy": 0.7198051948051948, "f1": 0.7160698329350758, "f1_weighted": 0.7160698329350759}, {"accuracy": 0.7162337662337662, "f1": 0.708267679473677, "f1_weighted": 0.7082676794736769}, {"accuracy": 0.702922077922078, "f1": 0.697623230226968, "f1_weighted": 0.6976232302269683}, {"accuracy": 0.7103896103896103, "f1": 0.7080591487260443, "f1_weighted": 0.7080591487260441}]}]}, "task_name": "Banking77Classification", "avg_layerwise_entropy": 0.04118897668648838, "num_samples": 64}