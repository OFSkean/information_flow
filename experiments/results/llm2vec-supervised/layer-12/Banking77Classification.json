{"dataset_revision": "0fd18e25b25c072e09e0d92ab615fda904d66300", "evaluation_time": 160.71180057525635, "kg_co2_emissions": null, "mteb_version": "1.12.49", "scores": {"test": [{"accuracy": 0.7414935064935064, "f1": 0.7389153976398666, "f1_weighted": 0.7389153976398668, "hf_subset": "default", "languages": ["eng-Latn"], "main_score": 0.7414935064935064, "scores_per_experiment": [{"accuracy": 0.7415584415584415, "f1": 0.739145113672343, "f1_weighted": 0.7391451136723431}, {"accuracy": 0.7337662337662337, "f1": 0.7297241960909453, "f1_weighted": 0.7297241960909455}, {"accuracy": 0.7431818181818182, "f1": 0.7421719648333027, "f1_weighted": 0.7421719648333029}, {"accuracy": 0.7425324675324675, "f1": 0.7365833160334371, "f1_weighted": 0.7365833160334369}, {"accuracy": 0.7399350649350649, "f1": 0.7377937917214796, "f1_weighted": 0.7377937917214797}, {"accuracy": 0.7233766233766233, "f1": 0.7204796954584197, "f1_weighted": 0.7204796954584198}, {"accuracy": 0.7451298701298701, "f1": 0.7426151744181585, "f1_weighted": 0.7426151744181587}, {"accuracy": 0.7467532467532467, "f1": 0.7444520931525137, "f1_weighted": 0.7444520931525136}, {"accuracy": 0.7529220779220779, "f1": 0.7505884313223515, "f1_weighted": 0.7505884313223516}, {"accuracy": 0.7457792207792208, "f1": 0.7456001996957158, "f1_weighted": 0.7456001996957158}]}]}, "task_name": "Banking77Classification", "avg_layerwise_entropy": 0.11064963479827329, "num_samples": 64}