{"dataset_revision": "0fd18e25b25c072e09e0d92ab615fda904d66300", "evaluation_time": 152.58849358558655, "kg_co2_emissions": null, "mteb_version": "1.12.49", "scores": {"test": [{"accuracy": 0.7301298701298701, "f1": 0.7267688359551773, "f1_weighted": 0.7267688359551774, "hf_subset": "default", "languages": ["eng-Latn"], "main_score": 0.7301298701298701, "scores_per_experiment": [{"accuracy": 0.7285714285714285, "f1": 0.7262667933486568, "f1_weighted": 0.726266793348657}, {"accuracy": 0.737987012987013, "f1": 0.7347806134648552, "f1_weighted": 0.7347806134648551}, {"accuracy": 0.7327922077922078, "f1": 0.728006662437492, "f1_weighted": 0.7280066624374921}, {"accuracy": 0.7136363636363636, "f1": 0.7102502657014272, "f1_weighted": 0.7102502657014272}, {"accuracy": 0.7146103896103896, "f1": 0.7115736000419964, "f1_weighted": 0.7115736000419963}, {"accuracy": 0.7415584415584415, "f1": 0.7391076258735858, "f1_weighted": 0.7391076258735859}, {"accuracy": 0.7321428571428571, "f1": 0.7266727703803603, "f1_weighted": 0.7266727703803603}, {"accuracy": 0.7298701298701299, "f1": 0.725744787707841, "f1_weighted": 0.7257447877078411}, {"accuracy": 0.7428571428571429, "f1": 0.7406358365425871, "f1_weighted": 0.7406358365425869}, {"accuracy": 0.7272727272727273, "f1": 0.7246494040529711, "f1_weighted": 0.724649404052971}]}]}, "task_name": "Banking77Classification", "avg_layerwise_entropy": 0.06556132732871392, "num_samples": 64}