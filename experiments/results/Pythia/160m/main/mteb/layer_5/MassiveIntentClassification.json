{
  "dataset_revision": "4672e20407010da34463acc759c162ca9734bca6",
  "evaluation_time": 76.91513109207153,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.5462676529926026,
        "f1": 0.5163056875692947,
        "f1_weighted": 0.5503320271846588,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5462676529926026,
        "scores_per_experiment": [
          {
            "accuracy": 0.5501008742434432,
            "f1": 0.5221073336074711,
            "f1_weighted": 0.554197346862644
          },
          {
            "accuracy": 0.5453934095494284,
            "f1": 0.5115594531931823,
            "f1_weighted": 0.5509223981735353
          },
          {
            "accuracy": 0.5537995965030262,
            "f1": 0.5281315228873403,
            "f1_weighted": 0.5566382014040356
          },
          {
            "accuracy": 0.5537995965030262,
            "f1": 0.5170193553339315,
            "f1_weighted": 0.5609805191473938
          },
          {
            "accuracy": 0.5544720914593141,
            "f1": 0.5231157007270564,
            "f1_weighted": 0.556265014798072
          },
          {
            "accuracy": 0.5248823133826497,
            "f1": 0.5090173085368994,
            "f1_weighted": 0.524196519151194
          },
          {
            "accuracy": 0.5363147276395427,
            "f1": 0.512974840343129,
            "f1_weighted": 0.5417266854043847
          },
          {
            "accuracy": 0.5453934095494284,
            "f1": 0.5052465011968839,
            "f1_weighted": 0.5528482222315186
          },
          {
            "accuracy": 0.5359784801613988,
            "f1": 0.5071069282444592,
            "f1_weighted": 0.5396877612715905
          },
          {
            "accuracy": 0.562542030934768,
            "f1": 0.526777931622594,
            "f1_weighted": 0.5658576034022194
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.561583866207575,
        "f1": 0.5308960473588027,
        "f1_weighted": 0.5656766197954292,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.561583866207575,
        "scores_per_experiment": [
          {
            "accuracy": 0.5533694048204624,
            "f1": 0.5222155793045298,
            "f1_weighted": 0.5553907302438973
          },
          {
            "accuracy": 0.5705853418593212,
            "f1": 0.5297034537211778,
            "f1_weighted": 0.5748905605111582
          },
          {
            "accuracy": 0.5828824397442204,
            "f1": 0.5526856038478303,
            "f1_weighted": 0.5857377476758773
          },
          {
            "accuracy": 0.5691096901131333,
            "f1": 0.5301300965632333,
            "f1_weighted": 0.5765696935856296
          },
          {
            "accuracy": 0.5804230201672406,
            "f1": 0.5488664070835394,
            "f1_weighted": 0.5840210922239036
          },
          {
            "accuracy": 0.5425479586817511,
            "f1": 0.5282354738181989,
            "f1_weighted": 0.5423369910977768
          },
          {
            "accuracy": 0.5258239055582883,
            "f1": 0.5067933478081507,
            "f1_weighted": 0.5287568948555844
          },
          {
            "accuracy": 0.558780127889818,
            "f1": 0.5273682033787933,
            "f1_weighted": 0.5650365801569054
          },
          {
            "accuracy": 0.5386128873585834,
            "f1": 0.5125195299061143,
            "f1_weighted": 0.5467571994692247
          },
          {
            "accuracy": 0.5937038858829317,
            "f1": 0.5504427781564591,
            "f1_weighted": 0.5972687081343341
          }
        ]
      }
    ]
  },
  "task_name": "MassiveIntentClassification"
}