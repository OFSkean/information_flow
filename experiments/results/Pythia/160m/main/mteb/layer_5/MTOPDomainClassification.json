{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 45.744386196136475,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.7909256725946193,
        "f1": 0.7854497917465493,
        "f1_weighted": 0.7920473443565892,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7909256725946193,
        "scores_per_experiment": [
          {
            "accuracy": 0.7539899680802553,
            "f1": 0.7484507257712738,
            "f1_weighted": 0.7527077984996264
          },
          {
            "accuracy": 0.801641586867305,
            "f1": 0.7966624809913653,
            "f1_weighted": 0.8054024536764239
          },
          {
            "accuracy": 0.7936616507067944,
            "f1": 0.7809529955630379,
            "f1_weighted": 0.7973016898981279
          },
          {
            "accuracy": 0.8041495668034656,
            "f1": 0.7972628302670134,
            "f1_weighted": 0.8058540406728921
          },
          {
            "accuracy": 0.8230734154126766,
            "f1": 0.8181778492529762,
            "f1_weighted": 0.823707264689156
          },
          {
            "accuracy": 0.7934336525307798,
            "f1": 0.7919988134968334,
            "f1_weighted": 0.7934266457196975
          },
          {
            "accuracy": 0.7758777929776561,
            "f1": 0.770206444837008,
            "f1_weighted": 0.7727681879448742
          },
          {
            "accuracy": 0.7729138166894665,
            "f1": 0.7702554509388855,
            "f1_weighted": 0.7771749904109821
          },
          {
            "accuracy": 0.7952576379388965,
            "f1": 0.7953563862593601,
            "f1_weighted": 0.7966966428337057
          },
          {
            "accuracy": 0.7952576379388965,
            "f1": 0.7851739400877384,
            "f1_weighted": 0.7954337292204048
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7849664429530201,
        "f1": 0.7833024799844881,
        "f1_weighted": 0.7856797130357126,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7849664429530201,
        "scores_per_experiment": [
          {
            "accuracy": 0.7503355704697987,
            "f1": 0.7531260664406072,
            "f1_weighted": 0.7486455143443004
          },
          {
            "accuracy": 0.8026845637583893,
            "f1": 0.8023567891208386,
            "f1_weighted": 0.8052408640173715
          },
          {
            "accuracy": 0.7874720357941835,
            "f1": 0.7772467547159795,
            "f1_weighted": 0.7902321849825068
          },
          {
            "accuracy": 0.8017897091722596,
            "f1": 0.800095585044846,
            "f1_weighted": 0.8037634822127848
          },
          {
            "accuracy": 0.8147651006711409,
            "f1": 0.8170153136315047,
            "f1_weighted": 0.8149817829892357
          },
          {
            "accuracy": 0.7838926174496644,
            "f1": 0.7854627856598827,
            "f1_weighted": 0.7833818297296721
          },
          {
            "accuracy": 0.7668903803131991,
            "f1": 0.7605163105246447,
            "f1_weighted": 0.7649099349521783
          },
          {
            "accuracy": 0.7722595078299777,
            "f1": 0.7738889755504775,
            "f1_weighted": 0.7755976972654892
          },
          {
            "accuracy": 0.7879194630872484,
            "f1": 0.7877645031034884,
            "f1_weighted": 0.7885542085529309
          },
          {
            "accuracy": 0.78165548098434,
            "f1": 0.7755517160526119,
            "f1_weighted": 0.7814896313106567
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}