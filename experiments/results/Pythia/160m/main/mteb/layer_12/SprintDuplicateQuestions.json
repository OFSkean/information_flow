{
  "dataset_revision": "d66bd1f72af766a5cc4b0ca5e00c162f89e8cc46",
  "evaluation_time": 24.960381984710693,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "cosine_accuracy": 0.9902673267326733,
        "cosine_accuracy_threshold": 0.999237596988678,
        "cosine_ap": 0.2161529829214276,
        "cosine_f1": 0.30286599535243997,
        "cosine_f1_threshold": 0.9982037544250488,
        "cosine_precision": 0.24715549936788875,
        "cosine_recall": 0.391,
        "dot_accuracy": 0.9900891089108911,
        "dot_accuracy_threshold": 72847.8984375,
        "dot_ap": 0.01789430564802357,
        "dot_f1": 0.04870259481037925,
        "dot_f1_threshold": 72488.7421875,
        "dot_precision": 0.04053156146179402,
        "dot_recall": 0.061,
        "euclidean_accuracy": 0.9902673267326733,
        "euclidean_accuracy_threshold": 10.48154067993164,
        "euclidean_ap": 0.21713928677692873,
        "euclidean_f1": 0.30593047034764825,
        "euclidean_f1_threshold": 16.010910034179688,
        "euclidean_precision": 0.25882352941176473,
        "euclidean_recall": 0.374,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.231136257489635,
        "manhattan_accuracy": 0.9902871287128713,
        "manhattan_accuracy_threshold": 242.91015625,
        "manhattan_ap": 0.231136257489635,
        "manhattan_f1": 0.31987331749802056,
        "manhattan_f1_threshold": 353.166015625,
        "manhattan_precision": 0.26474442988204455,
        "manhattan_recall": 0.404,
        "max_accuracy": 0.9902871287128713,
        "max_ap": 0.231136257489635,
        "max_f1": 0.31987331749802056,
        "max_precision": 0.26474442988204455,
        "max_recall": 0.404,
        "similarity_accuracy": 0.9902673267326733,
        "similarity_accuracy_threshold": 0.999237596988678,
        "similarity_ap": 0.2161529829214276,
        "similarity_f1": 0.30286599535243997,
        "similarity_f1_threshold": 0.9982037544250488,
        "similarity_precision": 0.24715549936788875,
        "similarity_recall": 0.391
      }
    ],
    "validation": [
      {
        "cosine_accuracy": 0.9904257425742574,
        "cosine_accuracy_threshold": 0.9989898204803467,
        "cosine_ap": 0.16094743626146754,
        "cosine_f1": 0.22168867547018808,
        "cosine_f1_threshold": 0.9982357621192932,
        "cosine_precision": 0.1847898599066044,
        "cosine_recall": 0.277,
        "dot_accuracy": 0.9901584158415841,
        "dot_accuracy_threshold": 72776.984375,
        "dot_ap": 0.023055322653586795,
        "dot_f1": 0.04637575314953441,
        "dot_f1_threshold": 72393.0625,
        "dot_precision": 0.028367210185392004,
        "dot_recall": 0.127,
        "euclidean_accuracy": 0.9904257425742574,
        "euclidean_accuracy_threshold": 12.103418350219727,
        "euclidean_ap": 0.16199247340474512,
        "euclidean_f1": 0.22589753933037518,
        "euclidean_f1_threshold": 15.967369079589844,
        "euclidean_precision": 0.18931710615280595,
        "euclidean_recall": 0.28,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.17096293788703298,
        "manhattan_accuracy": 0.9904158415841584,
        "manhattan_accuracy_threshold": 267.3382568359375,
        "manhattan_ap": 0.17096293788703298,
        "manhattan_f1": 0.2331378299120235,
        "manhattan_f1_threshold": 354.478515625,
        "manhattan_precision": 0.1840277777777778,
        "manhattan_recall": 0.318,
        "max_accuracy": 0.9904257425742574,
        "max_ap": 0.17096293788703298,
        "max_f1": 0.2331378299120235,
        "max_precision": 0.18931710615280595,
        "max_recall": 0.318,
        "similarity_accuracy": 0.9904257425742574,
        "similarity_accuracy_threshold": 0.9989898204803467,
        "similarity_ap": 0.16094743626146754,
        "similarity_f1": 0.22168867547018808,
        "similarity_f1_threshold": 0.9982357621192932,
        "similarity_precision": 0.1847898599066044,
        "similarity_recall": 0.277
      }
    ]
  },
  "task_name": "SprintDuplicateQuestions"
}