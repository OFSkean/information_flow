{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 50.65320110321045,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.7533059735522115,
        "f1": 0.7491988648222063,
        "f1_weighted": 0.7565021824063909,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7533059735522115,
        "scores_per_experiment": [
          {
            "accuracy": 0.7220702234382125,
            "f1": 0.718987248930455,
            "f1_weighted": 0.7216018513128496
          },
          {
            "accuracy": 0.791609667122663,
            "f1": 0.7900598434920557,
            "f1_weighted": 0.7939007605789626
          },
          {
            "accuracy": 0.7485180118559052,
            "f1": 0.7427374131289909,
            "f1_weighted": 0.7579109999620701
          },
          {
            "accuracy": 0.7435020519835841,
            "f1": 0.7354724039396566,
            "f1_weighted": 0.7469960643621562
          },
          {
            "accuracy": 0.7797537619699042,
            "f1": 0.7744836760865664,
            "f1_weighted": 0.7829903827418125
          },
          {
            "accuracy": 0.753077975376197,
            "f1": 0.749666709771481,
            "f1_weighted": 0.7557153004257906
          },
          {
            "accuracy": 0.7489740082079344,
            "f1": 0.7434701836406054,
            "f1_weighted": 0.7472433324609419
          },
          {
            "accuracy": 0.7191062471500228,
            "f1": 0.7238191423262988,
            "f1_weighted": 0.7258273803748574
          },
          {
            "accuracy": 0.7649338805289557,
            "f1": 0.7605442707743812,
            "f1_weighted": 0.7684730049570199
          },
          {
            "accuracy": 0.7615139078887369,
            "f1": 0.7527477561315717,
            "f1_weighted": 0.7643627468874477
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7518120805369127,
        "f1": 0.7495475945426049,
        "f1_weighted": 0.7541688890730236,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7518120805369127,
        "scores_per_experiment": [
          {
            "accuracy": 0.727069351230425,
            "f1": 0.7310645452519577,
            "f1_weighted": 0.725187666019902
          },
          {
            "accuracy": 0.7856823266219239,
            "f1": 0.786560239751514,
            "f1_weighted": 0.7875935927596062
          },
          {
            "accuracy": 0.7431767337807607,
            "f1": 0.738454155557167,
            "f1_weighted": 0.7512789687968314
          },
          {
            "accuracy": 0.7615212527964206,
            "f1": 0.7581173381730892,
            "f1_weighted": 0.7656487655377038
          },
          {
            "accuracy": 0.7767337807606264,
            "f1": 0.7763013924032816,
            "f1_weighted": 0.7782402815855823
          },
          {
            "accuracy": 0.7539149888143176,
            "f1": 0.7527096103535377,
            "f1_weighted": 0.7563654222115429
          },
          {
            "accuracy": 0.7369127516778523,
            "f1": 0.7277707967519663,
            "f1_weighted": 0.7352231315703922
          },
          {
            "accuracy": 0.716331096196868,
            "f1": 0.7174129160920701,
            "f1_weighted": 0.7203702009052609
          },
          {
            "accuracy": 0.7570469798657719,
            "f1": 0.752800443858851,
            "f1_weighted": 0.7598857619677293
          },
          {
            "accuracy": 0.7597315436241611,
            "f1": 0.7542845072326145,
            "f1_weighted": 0.7618950993756849
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}