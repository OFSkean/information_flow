{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 45.59446620941162,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.7912448700410396,
        "f1": 0.7864767751341863,
        "f1_weighted": 0.7922569625858037,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7912448700410396,
        "scores_per_experiment": [
          {
            "accuracy": 0.7601459188326494,
            "f1": 0.7542721547024424,
            "f1_weighted": 0.7598668301010391
          },
          {
            "accuracy": 0.8064295485636115,
            "f1": 0.8036647925263671,
            "f1_weighted": 0.809618752692702
          },
          {
            "accuracy": 0.7840857273141815,
            "f1": 0.7760385699106913,
            "f1_weighted": 0.788019112072304
          },
          {
            "accuracy": 0.8055175558595531,
            "f1": 0.7984971411517278,
            "f1_weighted": 0.80651129849894
          },
          {
            "accuracy": 0.8198814409484724,
            "f1": 0.8143057574723489,
            "f1_weighted": 0.8195034993053275
          },
          {
            "accuracy": 0.7929776561787506,
            "f1": 0.7903871506502429,
            "f1_weighted": 0.7925844553637047
          },
          {
            "accuracy": 0.7720018239854081,
            "f1": 0.7660964736397511,
            "f1_weighted": 0.7685233798701037
          },
          {
            "accuracy": 0.781577747378021,
            "f1": 0.7777345565562114,
            "f1_weighted": 0.7854055072227656
          },
          {
            "accuracy": 0.802781577747378,
            "f1": 0.8035233681961952,
            "f1_weighted": 0.8034906314292771
          },
          {
            "accuracy": 0.7870497036023711,
            "f1": 0.7802477865358857,
            "f1_weighted": 0.7890461593018738
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.789351230425056,
        "f1": 0.7874680110396686,
        "f1_weighted": 0.7902621475746282,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.789351230425056,
        "scores_per_experiment": [
          {
            "accuracy": 0.7659955257270693,
            "f1": 0.7658880978170068,
            "f1_weighted": 0.7664382858442919
          },
          {
            "accuracy": 0.8116331096196868,
            "f1": 0.8105337553062341,
            "f1_weighted": 0.8138807048360811
          },
          {
            "accuracy": 0.7794183445190157,
            "f1": 0.7723993198043477,
            "f1_weighted": 0.781951056806411
          },
          {
            "accuracy": 0.8147651006711409,
            "f1": 0.8118456940133079,
            "f1_weighted": 0.8166393729815091
          },
          {
            "accuracy": 0.8147651006711409,
            "f1": 0.8162522973741165,
            "f1_weighted": 0.8140867951671016
          },
          {
            "accuracy": 0.7812080536912752,
            "f1": 0.7793591783278874,
            "f1_weighted": 0.7811810067398937
          },
          {
            "accuracy": 0.7691275167785235,
            "f1": 0.7631729999024469,
            "f1_weighted": 0.7672087402236488
          },
          {
            "accuracy": 0.7803131991051454,
            "f1": 0.781472325442276,
            "f1_weighted": 0.7847166835737239
          },
          {
            "accuracy": 0.7906040268456376,
            "f1": 0.7911395116657512,
            "f1_weighted": 0.7907337945830416
          },
          {
            "accuracy": 0.7856823266219239,
            "f1": 0.782616930743312,
            "f1_weighted": 0.7857850349905797
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}