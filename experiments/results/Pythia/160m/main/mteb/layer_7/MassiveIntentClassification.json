{
  "dataset_revision": "4672e20407010da34463acc759c162ca9734bca6",
  "evaluation_time": 78.75112867355347,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.5434767989240081,
        "f1": 0.5099452764809167,
        "f1_weighted": 0.54802577287216,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5434767989240081,
        "scores_per_experiment": [
          {
            "accuracy": 0.5366509751176867,
            "f1": 0.5063397331076839,
            "f1_weighted": 0.5399435179851494
          },
          {
            "accuracy": 0.5487558843308675,
            "f1": 0.5100927627604143,
            "f1_weighted": 0.5537137679560412
          },
          {
            "accuracy": 0.5420309347679892,
            "f1": 0.5091903670871382,
            "f1_weighted": 0.5454956617215319
          },
          {
            "accuracy": 0.5642232683254875,
            "f1": 0.5234184689692069,
            "f1_weighted": 0.5717727244890043
          },
          {
            "accuracy": 0.5615332885003362,
            "f1": 0.5230738147280317,
            "f1_weighted": 0.5643054144450647
          },
          {
            "accuracy": 0.5211835911230666,
            "f1": 0.501451152635185,
            "f1_weighted": 0.5234286248527609
          },
          {
            "accuracy": 0.5373234700739744,
            "f1": 0.5089070595833424,
            "f1_weighted": 0.5411924898452924
          },
          {
            "accuracy": 0.5450571620712845,
            "f1": 0.5000912680266664,
            "f1_weighted": 0.5532137353262915
          },
          {
            "accuracy": 0.5265635507733692,
            "f1": 0.5057204568413106,
            "f1_weighted": 0.5314559417477931
          },
          {
            "accuracy": 0.5514458641560188,
            "f1": 0.5111676810701881,
            "f1_weighted": 0.5557358503526714
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.558042302016724,
        "f1": 0.5282912072312488,
        "f1_weighted": 0.5627836214622087,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.558042302016724,
        "scores_per_experiment": [
          {
            "accuracy": 0.5538612887358584,
            "f1": 0.520049656876867,
            "f1_weighted": 0.5554549623389556
          },
          {
            "accuracy": 0.5676340383669454,
            "f1": 0.5316252395627036,
            "f1_weighted": 0.5744533150374557
          },
          {
            "accuracy": 0.5755041810132808,
            "f1": 0.5411093429150452,
            "f1_weighted": 0.5819863648856383
          },
          {
            "accuracy": 0.5666502705361535,
            "f1": 0.5250693660574913,
            "f1_weighted": 0.5727712989591773
          },
          {
            "accuracy": 0.5740285292670929,
            "f1": 0.5420141436712935,
            "f1_weighted": 0.5782352326680229
          },
          {
            "accuracy": 0.5346778160354156,
            "f1": 0.524131467316229,
            "f1_weighted": 0.5350107070413341
          },
          {
            "accuracy": 0.5194294146581406,
            "f1": 0.5064981913980984,
            "f1_weighted": 0.5236120517506877
          },
          {
            "accuracy": 0.5602557796360059,
            "f1": 0.529455568012691,
            "f1_weighted": 0.5661858960978258
          },
          {
            "accuracy": 0.5376291195277915,
            "f1": 0.5122653416391417,
            "f1_weighted": 0.5452373319963446
          },
          {
            "accuracy": 0.5907525823905558,
            "f1": 0.550693754862927,
            "f1_weighted": 0.5948890538466451
          }
        ]
      }
    ]
  },
  "task_name": "MassiveIntentClassification"
}