{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 111.48271775245667,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.3401,
        "f1": 0.3393280983448089,
        "f1_weighted": 0.339328098344809,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.3401,
        "scores_per_experiment": [
          {
            "accuracy": 0.3612,
            "f1": 0.36187773329690975,
            "f1_weighted": 0.36187773329690975
          },
          {
            "accuracy": 0.3524,
            "f1": 0.3558670046587137,
            "f1_weighted": 0.3558670046587137
          },
          {
            "accuracy": 0.3194,
            "f1": 0.31686374005455537,
            "f1_weighted": 0.31686374005455537
          },
          {
            "accuracy": 0.3348,
            "f1": 0.33650292667131027,
            "f1_weighted": 0.33650292667131027
          },
          {
            "accuracy": 0.3794,
            "f1": 0.374013030471101,
            "f1_weighted": 0.37401303047110107
          },
          {
            "accuracy": 0.3014,
            "f1": 0.30012908937574456,
            "f1_weighted": 0.3001290893757446
          },
          {
            "accuracy": 0.3094,
            "f1": 0.31006080806630315,
            "f1_weighted": 0.31006080806630315
          },
          {
            "accuracy": 0.3548,
            "f1": 0.3441717115549195,
            "f1_weighted": 0.3441717115549195
          },
          {
            "accuracy": 0.3338,
            "f1": 0.3389434916907356,
            "f1_weighted": 0.33894349169073573
          },
          {
            "accuracy": 0.3544,
            "f1": 0.35485144760779663,
            "f1_weighted": 0.3548514476077966
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.33856,
        "f1": 0.337355106135058,
        "f1_weighted": 0.337355106135058,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.33856,
        "scores_per_experiment": [
          {
            "accuracy": 0.3446,
            "f1": 0.3462222677130024,
            "f1_weighted": 0.34622226771300246
          },
          {
            "accuracy": 0.3472,
            "f1": 0.3519016483282157,
            "f1_weighted": 0.35190164832821563
          },
          {
            "accuracy": 0.3358,
            "f1": 0.33362143558418256,
            "f1_weighted": 0.3336214355841825
          },
          {
            "accuracy": 0.3222,
            "f1": 0.3223723384089806,
            "f1_weighted": 0.3223723384089806
          },
          {
            "accuracy": 0.3654,
            "f1": 0.35539775560688774,
            "f1_weighted": 0.35539775560688774
          },
          {
            "accuracy": 0.3052,
            "f1": 0.30214809335121834,
            "f1_weighted": 0.30214809335121834
          },
          {
            "accuracy": 0.3258,
            "f1": 0.3266310043483381,
            "f1_weighted": 0.326631004348338
          },
          {
            "accuracy": 0.3458,
            "f1": 0.3358832208930563,
            "f1_weighted": 0.3358832208930562
          },
          {
            "accuracy": 0.3318,
            "f1": 0.3380860819022788,
            "f1_weighted": 0.3380860819022788
          },
          {
            "accuracy": 0.3618,
            "f1": 0.36128721521441914,
            "f1_weighted": 0.36128721521441914
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}