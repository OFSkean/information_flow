{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 123.8384518623352,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.33104,
        "f1": 0.33019725064195293,
        "f1_weighted": 0.3301972506419528,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.33104,
        "scores_per_experiment": [
          {
            "accuracy": 0.3454,
            "f1": 0.3428419646004041,
            "f1_weighted": 0.342841964600404
          },
          {
            "accuracy": 0.3412,
            "f1": 0.33983445194037576,
            "f1_weighted": 0.3398344519403757
          },
          {
            "accuracy": 0.3194,
            "f1": 0.31711391122629917,
            "f1_weighted": 0.3171139112262991
          },
          {
            "accuracy": 0.338,
            "f1": 0.3383425883229846,
            "f1_weighted": 0.3383425883229846
          },
          {
            "accuracy": 0.3702,
            "f1": 0.3629813424750288,
            "f1_weighted": 0.3629813424750288
          },
          {
            "accuracy": 0.3028,
            "f1": 0.30392097588510986,
            "f1_weighted": 0.30392097588510986
          },
          {
            "accuracy": 0.2694,
            "f1": 0.2696663533048452,
            "f1_weighted": 0.2696663533048451
          },
          {
            "accuracy": 0.334,
            "f1": 0.33329457820751685,
            "f1_weighted": 0.3332945782075168
          },
          {
            "accuracy": 0.3418,
            "f1": 0.344152927592486,
            "f1_weighted": 0.344152927592486
          },
          {
            "accuracy": 0.3482,
            "f1": 0.3498234128644785,
            "f1_weighted": 0.34982341286447843
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.33009999999999995,
        "f1": 0.3291780608674447,
        "f1_weighted": 0.3291780608674447,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.33009999999999995,
        "scores_per_experiment": [
          {
            "accuracy": 0.3396,
            "f1": 0.3391028309513261,
            "f1_weighted": 0.3391028309513261
          },
          {
            "accuracy": 0.3408,
            "f1": 0.3398238135514696,
            "f1_weighted": 0.3398238135514696
          },
          {
            "accuracy": 0.327,
            "f1": 0.32600505656088974,
            "f1_weighted": 0.3260050565608898
          },
          {
            "accuracy": 0.3324,
            "f1": 0.33034889073227447,
            "f1_weighted": 0.33034889073227447
          },
          {
            "accuracy": 0.3684,
            "f1": 0.35750734557617375,
            "f1_weighted": 0.3575073455761738
          },
          {
            "accuracy": 0.3066,
            "f1": 0.30737204480775715,
            "f1_weighted": 0.3073720448077571
          },
          {
            "accuracy": 0.2704,
            "f1": 0.2710843955461666,
            "f1_weighted": 0.27108439554616653
          },
          {
            "accuracy": 0.3252,
            "f1": 0.32690735295056605,
            "f1_weighted": 0.32690735295056605
          },
          {
            "accuracy": 0.3432,
            "f1": 0.3462087429488463,
            "f1_weighted": 0.34620874294884635
          },
          {
            "accuracy": 0.3474,
            "f1": 0.3474201350489774,
            "f1_weighted": 0.3474201350489774
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}