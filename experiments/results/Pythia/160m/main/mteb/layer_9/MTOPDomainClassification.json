{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 47.88686966896057,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.7906064751481988,
        "f1": 0.7874209637916744,
        "f1_weighted": 0.7917773162226953,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7906064751481988,
        "scores_per_experiment": [
          {
            "accuracy": 0.7628818969448244,
            "f1": 0.758677408466852,
            "f1_weighted": 0.7630233266980206
          },
          {
            "accuracy": 0.8178294573643411,
            "f1": 0.8165690905452092,
            "f1_weighted": 0.8194652917218611
          },
          {
            "accuracy": 0.7913816689466484,
            "f1": 0.78341986029561,
            "f1_weighted": 0.79548538654237
          },
          {
            "accuracy": 0.8082535339717283,
            "f1": 0.8002763540366119,
            "f1_weighted": 0.8094692409779656
          },
          {
            "accuracy": 0.8160054719562243,
            "f1": 0.8115004738927205,
            "f1_weighted": 0.8159310701429869
          },
          {
            "accuracy": 0.7861377108983129,
            "f1": 0.785407196206178,
            "f1_weighted": 0.7859160454122517
          },
          {
            "accuracy": 0.771545827633379,
            "f1": 0.770472161170442,
            "f1_weighted": 0.7687544979958766
          },
          {
            "accuracy": 0.7740538075695395,
            "f1": 0.7711253023876439,
            "f1_weighted": 0.7776515613064909
          },
          {
            "accuracy": 0.7984496124031008,
            "f1": 0.8017860702547516,
            "f1_weighted": 0.7992423863359643
          },
          {
            "accuracy": 0.7795257637938896,
            "f1": 0.7749757206607252,
            "f1_weighted": 0.7828343550931647
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7880089485458613,
        "f1": 0.7874183676484308,
        "f1_weighted": 0.7888249901615058,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7880089485458613,
        "scores_per_experiment": [
          {
            "accuracy": 0.7695749440715883,
            "f1": 0.7717402886324674,
            "f1_weighted": 0.769950962511773
          },
          {
            "accuracy": 0.8259507829977628,
            "f1": 0.8257235266617333,
            "f1_weighted": 0.8271586933855427
          },
          {
            "accuracy": 0.7874720357941835,
            "f1": 0.7814847929319595,
            "f1_weighted": 0.7899282865709596
          },
          {
            "accuracy": 0.8089485458612975,
            "f1": 0.8078847510988157,
            "f1_weighted": 0.8112420454774071
          },
          {
            "accuracy": 0.8089485458612975,
            "f1": 0.809023618053822,
            "f1_weighted": 0.8083064585381844
          },
          {
            "accuracy": 0.7736017897091723,
            "f1": 0.7733126986628857,
            "f1_weighted": 0.773596561358208
          },
          {
            "accuracy": 0.7718120805369127,
            "f1": 0.7704971422583138,
            "f1_weighted": 0.7702088740601881
          },
          {
            "accuracy": 0.7691275167785235,
            "f1": 0.7693636925658839,
            "f1_weighted": 0.7713887119408945
          },
          {
            "accuracy": 0.7897091722595079,
            "f1": 0.7922694741145304,
            "f1_weighted": 0.7904480930957207
          },
          {
            "accuracy": 0.7749440715883669,
            "f1": 0.7728836915038958,
            "f1_weighted": 0.7760212146761784
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}