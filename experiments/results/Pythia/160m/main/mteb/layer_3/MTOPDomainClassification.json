{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 43.89106464385986,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.8063155494756042,
        "f1": 0.7997501034140667,
        "f1_weighted": 0.8081693732254578,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8063155494756042,
        "scores_per_experiment": [
          {
            "accuracy": 0.7806657546739626,
            "f1": 0.7745916505310202,
            "f1_weighted": 0.780319613665314
          },
          {
            "accuracy": 0.8087095303237574,
            "f1": 0.8048670348776998,
            "f1_weighted": 0.8118401048823543
          },
          {
            "accuracy": 0.8125854993160054,
            "f1": 0.799981148984245,
            "f1_weighted": 0.8151538357527394
          },
          {
            "accuracy": 0.8196534427724578,
            "f1": 0.8093319091844464,
            "f1_weighted": 0.8232628583785943
          },
          {
            "accuracy": 0.8267213862289101,
            "f1": 0.8182088433322273,
            "f1_weighted": 0.8290347463873072
          },
          {
            "accuracy": 0.8034655722754218,
            "f1": 0.7978581271619379,
            "f1_weighted": 0.8045166818754439
          },
          {
            "accuracy": 0.7970816233470133,
            "f1": 0.7918748418244422,
            "f1_weighted": 0.7952391333183797
          },
          {
            "accuracy": 0.7788417692658459,
            "f1": 0.7760349576715195,
            "f1_weighted": 0.785100684924443
          },
          {
            "accuracy": 0.8123575011399908,
            "f1": 0.8108054270856679,
            "f1_weighted": 0.8139533123843564
          },
          {
            "accuracy": 0.8230734154126766,
            "f1": 0.8139470934874605,
            "f1_weighted": 0.8232727606856464
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7939149888143177,
        "f1": 0.7909015148078508,
        "f1_weighted": 0.795558358057002,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7939149888143177,
        "scores_per_experiment": [
          {
            "accuracy": 0.7731543624161074,
            "f1": 0.7737061878557836,
            "f1_weighted": 0.7725819291364192
          },
          {
            "accuracy": 0.8031319910514542,
            "f1": 0.8025881398584261,
            "f1_weighted": 0.8069042565117089
          },
          {
            "accuracy": 0.8017897091722596,
            "f1": 0.7908306333332217,
            "f1_weighted": 0.804219681216791
          },
          {
            "accuracy": 0.8053691275167785,
            "f1": 0.8018201947283927,
            "f1_weighted": 0.8085880446722392
          },
          {
            "accuracy": 0.8120805369127517,
            "f1": 0.8102669946348421,
            "f1_weighted": 0.8142454854737377
          },
          {
            "accuracy": 0.7910514541387025,
            "f1": 0.7883700262623559,
            "f1_weighted": 0.7913711178596186
          },
          {
            "accuracy": 0.7821029082774049,
            "f1": 0.7760125593136219,
            "f1_weighted": 0.7800883532658772
          },
          {
            "accuracy": 0.7534675615212528,
            "f1": 0.7556582177379508,
            "f1_weighted": 0.7597716352389385
          },
          {
            "accuracy": 0.7991051454138702,
            "f1": 0.7973579481414226,
            "f1_weighted": 0.8000238672473845
          },
          {
            "accuracy": 0.8178970917225951,
            "f1": 0.8124042462124912,
            "f1_weighted": 0.817789209947306
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}