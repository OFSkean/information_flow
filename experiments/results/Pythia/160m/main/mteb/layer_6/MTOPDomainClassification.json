{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 46.88589429855347,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.7914956680346558,
        "f1": 0.7865866398233728,
        "f1_weighted": 0.7923164308893684,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7914956680346558,
        "scores_per_experiment": [
          {
            "accuracy": 0.7601459188326494,
            "f1": 0.7541847083442499,
            "f1_weighted": 0.7587244951025107
          },
          {
            "accuracy": 0.8116735066119471,
            "f1": 0.8080681780431835,
            "f1_weighted": 0.814599638459611
          },
          {
            "accuracy": 0.7875056999544003,
            "f1": 0.7764704310042588,
            "f1_weighted": 0.7905019005532631
          },
          {
            "accuracy": 0.7982216142270862,
            "f1": 0.7917813088031328,
            "f1_weighted": 0.800021090976344
          },
          {
            "accuracy": 0.8130414956680346,
            "f1": 0.8085153265795456,
            "f1_weighted": 0.8128582739506773
          },
          {
            "accuracy": 0.8018695850433196,
            "f1": 0.8004774824861542,
            "f1_weighted": 0.8016036078439047
          },
          {
            "accuracy": 0.7808937528499772,
            "f1": 0.7763274369474616,
            "f1_weighted": 0.777591644682357
          },
          {
            "accuracy": 0.7790697674418605,
            "f1": 0.7759022957347088,
            "f1_weighted": 0.7833122042996564
          },
          {
            "accuracy": 0.7954856361149111,
            "f1": 0.79539334756771,
            "f1_weighted": 0.7966338746329434
          },
          {
            "accuracy": 0.7870497036023711,
            "f1": 0.7787458827233216,
            "f1_weighted": 0.7873175783924169
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.785413870246085,
        "f1": 0.7848501237447956,
        "f1_weighted": 0.7860853744877317,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.785413870246085,
        "scores_per_experiment": [
          {
            "accuracy": 0.760178970917226,
            "f1": 0.7624101430264374,
            "f1_weighted": 0.7595581687213475
          },
          {
            "accuracy": 0.8089485458612975,
            "f1": 0.8094307721093267,
            "f1_weighted": 0.810667352743584
          },
          {
            "accuracy": 0.7789709172259508,
            "f1": 0.7704789989827127,
            "f1_weighted": 0.7812056479060745
          },
          {
            "accuracy": 0.8080536912751678,
            "f1": 0.8094900477871355,
            "f1_weighted": 0.8106274209470955
          },
          {
            "accuracy": 0.7995525727069351,
            "f1": 0.8045413323161038,
            "f1_weighted": 0.7999028418801553
          },
          {
            "accuracy": 0.7874720357941835,
            "f1": 0.7883834205576442,
            "f1_weighted": 0.7869222592051803
          },
          {
            "accuracy": 0.7691275167785235,
            "f1": 0.7641303058428517,
            "f1_weighted": 0.7675698672450894
          },
          {
            "accuracy": 0.7785234899328859,
            "f1": 0.7794225652603771,
            "f1_weighted": 0.782429100000256
          },
          {
            "accuracy": 0.7901565995525727,
            "f1": 0.7904046101154436,
            "f1_weighted": 0.7897858786042498
          },
          {
            "accuracy": 0.7731543624161074,
            "f1": 0.7698090414499241,
            "f1_weighted": 0.772185207624285
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}