{
  "dataset_revision": "4672e20407010da34463acc759c162ca9734bca6",
  "evaluation_time": 62.3256254196167,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.5596503026227303,
        "f1": 0.5403026220803578,
        "f1_weighted": 0.5623461175113948,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5596503026227303,
        "scores_per_experiment": [
          {
            "accuracy": 0.5561533288500337,
            "f1": 0.5462131856345745,
            "f1_weighted": 0.5578421258907217
          },
          {
            "accuracy": 0.5830531271015468,
            "f1": 0.5610843137445212,
            "f1_weighted": 0.5878196947561871
          },
          {
            "accuracy": 0.5645595158036315,
            "f1": 0.5424265578474589,
            "f1_weighted": 0.5598772767621399
          },
          {
            "accuracy": 0.574310692669805,
            "f1": 0.5446068217670418,
            "f1_weighted": 0.5770247940259772
          },
          {
            "accuracy": 0.5642232683254875,
            "f1": 0.5334739061687195,
            "f1_weighted": 0.5659232567628704
          },
          {
            "accuracy": 0.5326160053799597,
            "f1": 0.5201374376601562,
            "f1_weighted": 0.5367482546565665
          },
          {
            "accuracy": 0.5484196368527237,
            "f1": 0.5411546573266895,
            "f1_weighted": 0.552433971541966
          },
          {
            "accuracy": 0.5564895763281775,
            "f1": 0.5359875227205475,
            "f1_weighted": 0.5599494464403427
          },
          {
            "accuracy": 0.5464021519838601,
            "f1": 0.5296539077404103,
            "f1_weighted": 0.5502933010581981
          },
          {
            "accuracy": 0.570275722932078,
            "f1": 0.5482879101934582,
            "f1_weighted": 0.5755490532189789
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.5659124446630595,
        "f1": 0.5442594415958699,
        "f1_weighted": 0.5681191932278963,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5659124446630595,
        "scores_per_experiment": [
          {
            "accuracy": 0.5602557796360059,
            "f1": 0.545484138659034,
            "f1_weighted": 0.5587977531115925
          },
          {
            "accuracy": 0.5833743236596163,
            "f1": 0.5412674936938917,
            "f1_weighted": 0.5895999402967876
          },
          {
            "accuracy": 0.5809149040826365,
            "f1": 0.5567608208827013,
            "f1_weighted": 0.5791843175490288
          },
          {
            "accuracy": 0.5715691096901131,
            "f1": 0.5391492441685356,
            "f1_weighted": 0.5734471066387913
          },
          {
            "accuracy": 0.5764879488440728,
            "f1": 0.5516863875509891,
            "f1_weighted": 0.5786083848235203
          },
          {
            "accuracy": 0.543531726512543,
            "f1": 0.5371466520005493,
            "f1_weighted": 0.5457630853681025
          },
          {
            "accuracy": 0.5425479586817511,
            "f1": 0.537881643715497,
            "f1_weighted": 0.5451848003656148
          },
          {
            "accuracy": 0.5499262174126907,
            "f1": 0.5242460161251489,
            "f1_weighted": 0.549623968863732
          },
          {
            "accuracy": 0.5641908509591737,
            "f1": 0.5470706390697134,
            "f1_weighted": 0.5689949916387265
          },
          {
            "accuracy": 0.5863256271519921,
            "f1": 0.5619013800926388,
            "f1_weighted": 0.5919875836230661
          }
        ]
      }
    ]
  },
  "task_name": "MassiveIntentClassification"
}