{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 37.23245310783386,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.7965572275421796,
        "f1": 0.7935699329568352,
        "f1_weighted": 0.7994436473956006,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7965572275421796,
        "scores_per_experiment": [
          {
            "accuracy": 0.7633378932968536,
            "f1": 0.7599349342107113,
            "f1_weighted": 0.7649432557688434
          },
          {
            "accuracy": 0.7843137254901961,
            "f1": 0.7839319209292488,
            "f1_weighted": 0.7892427994942386
          },
          {
            "accuracy": 0.8011855905152758,
            "f1": 0.7937282336163117,
            "f1_weighted": 0.8025550914821377
          },
          {
            "accuracy": 0.8098495212038304,
            "f1": 0.8082694687467296,
            "f1_weighted": 0.81411140291398
          },
          {
            "accuracy": 0.8173734610123119,
            "f1": 0.8123843179978916,
            "f1_weighted": 0.821048805989391
          },
          {
            "accuracy": 0.7922936616507068,
            "f1": 0.7907096032248023,
            "f1_weighted": 0.7948109057230734
          },
          {
            "accuracy": 0.7909256725946192,
            "f1": 0.7876571478396734,
            "f1_weighted": 0.7917314979803364
          },
          {
            "accuracy": 0.7665298677610579,
            "f1": 0.765426891945104,
            "f1_weighted": 0.7731656818438796
          },
          {
            "accuracy": 0.8146374829001368,
            "f1": 0.8153454085081274,
            "f1_weighted": 0.8173518344440333
          },
          {
            "accuracy": 0.825125398996808,
            "f1": 0.8183114025497513,
            "f1_weighted": 0.8254751983160916
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7884116331096196,
        "f1": 0.7886572655410727,
        "f1_weighted": 0.790738042501363,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7884116331096196,
        "scores_per_experiment": [
          {
            "accuracy": 0.7472035794183445,
            "f1": 0.74675898609398,
            "f1_weighted": 0.7465151970384777
          },
          {
            "accuracy": 0.7941834451901566,
            "f1": 0.7969194614659796,
            "f1_weighted": 0.798520946939419
          },
          {
            "accuracy": 0.7932885906040269,
            "f1": 0.7898576297740534,
            "f1_weighted": 0.7947686684297994
          },
          {
            "accuracy": 0.8080536912751678,
            "f1": 0.8105171012269085,
            "f1_weighted": 0.8128732401779906
          },
          {
            "accuracy": 0.8125279642058165,
            "f1": 0.8141716856032963,
            "f1_weighted": 0.8153686652903979
          },
          {
            "accuracy": 0.7807606263982103,
            "f1": 0.7816302013025733,
            "f1_weighted": 0.7824402259189631
          },
          {
            "accuracy": 0.7821029082774049,
            "f1": 0.7816790834697475,
            "f1_weighted": 0.7832015275358293
          },
          {
            "accuracy": 0.7552572706935123,
            "f1": 0.7591845085054463,
            "f1_weighted": 0.7607961717604359
          },
          {
            "accuracy": 0.8085011185682327,
            "f1": 0.809765349826749,
            "f1_weighted": 0.8106922722883331
          },
          {
            "accuracy": 0.8022371364653244,
            "f1": 0.7960886481419923,
            "f1_weighted": 0.8022035096339845
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}