{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 48.657297134399414,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.7852257181942545,
        "f1": 0.7814020590889351,
        "f1_weighted": 0.7869544903513084,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7852257181942545,
        "scores_per_experiment": [
          {
            "accuracy": 0.7637938896488828,
            "f1": 0.7617943545238567,
            "f1_weighted": 0.7651030501380425
          },
          {
            "accuracy": 0.8164614683082535,
            "f1": 0.8145772431287844,
            "f1_weighted": 0.8187277086094056
          },
          {
            "accuracy": 0.780437756497948,
            "f1": 0.7710814864429518,
            "f1_weighted": 0.785997959509512
          },
          {
            "accuracy": 0.8011855905152758,
            "f1": 0.7925692548453398,
            "f1_weighted": 0.8035940382657678
          },
          {
            "accuracy": 0.8034655722754218,
            "f1": 0.7975667965406026,
            "f1_weighted": 0.8039794581161296
          },
          {
            "accuracy": 0.7954856361149111,
            "f1": 0.7918654928578396,
            "f1_weighted": 0.7958331524054917
          },
          {
            "accuracy": 0.7669858641130871,
            "f1": 0.765773035052943,
            "f1_weighted": 0.7637559873879938
          },
          {
            "accuracy": 0.760373917008664,
            "f1": 0.7575895928815196,
            "f1_weighted": 0.7650533331409495
          },
          {
            "accuracy": 0.7945736434108527,
            "f1": 0.7965868550707126,
            "f1_weighted": 0.7954799641314751
          },
          {
            "accuracy": 0.7694938440492476,
            "f1": 0.7646164795448009,
            "f1_weighted": 0.7720202518083172
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7786129753914989,
        "f1": 0.7772812929753455,
        "f1_weighted": 0.7800587289694323,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7786129753914989,
        "scores_per_experiment": [
          {
            "accuracy": 0.7503355704697987,
            "f1": 0.7553523644262665,
            "f1_weighted": 0.7510203873657643
          },
          {
            "accuracy": 0.8196868008948546,
            "f1": 0.8178588930602847,
            "f1_weighted": 0.8212605105738435
          },
          {
            "accuracy": 0.7722595078299777,
            "f1": 0.7644382497786112,
            "f1_weighted": 0.77615226479188
          },
          {
            "accuracy": 0.8080536912751678,
            "f1": 0.8065673071663891,
            "f1_weighted": 0.8116760975435654
          },
          {
            "accuracy": 0.7991051454138702,
            "f1": 0.7988646528680878,
            "f1_weighted": 0.7987810782468551
          },
          {
            "accuracy": 0.7847874720357941,
            "f1": 0.7814703871602012,
            "f1_weighted": 0.7854847774493298
          },
          {
            "accuracy": 0.7512304250559284,
            "f1": 0.7475355309806492,
            "f1_weighted": 0.7500564146113946
          },
          {
            "accuracy": 0.7498881431767338,
            "f1": 0.7509132109782427,
            "f1_weighted": 0.7532792734395375
          },
          {
            "accuracy": 0.7812080536912752,
            "f1": 0.7837791761460143,
            "f1_weighted": 0.7820448134066932
          },
          {
            "accuracy": 0.7695749440715883,
            "f1": 0.7660331571887092,
            "f1_weighted": 0.7708316722654599
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}