{
  "dataset_revision": "4672e20407010da34463acc759c162ca9734bca6",
  "evaluation_time": 79.63155770301819,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.5446200403496974,
        "f1": 0.5148701848330431,
        "f1_weighted": 0.5489652306104554,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5446200403496974,
        "scores_per_experiment": [
          {
            "accuracy": 0.5450571620712845,
            "f1": 0.5197870329058565,
            "f1_weighted": 0.5514211668147706
          },
          {
            "accuracy": 0.5480833893745797,
            "f1": 0.516808563813246,
            "f1_weighted": 0.5548508066544975
          },
          {
            "accuracy": 0.5427034297242771,
            "f1": 0.5111902327816106,
            "f1_weighted": 0.5461177735732556
          },
          {
            "accuracy": 0.5568258238063215,
            "f1": 0.522880086314021,
            "f1_weighted": 0.5613745383329897
          },
          {
            "accuracy": 0.5561533288500337,
            "f1": 0.5196486291181058,
            "f1_weighted": 0.55922300127195
          },
          {
            "accuracy": 0.519502353732347,
            "f1": 0.5050815663053693,
            "f1_weighted": 0.5179502313311958
          },
          {
            "accuracy": 0.531271015467384,
            "f1": 0.5085101307803109,
            "f1_weighted": 0.5355456877645616
          },
          {
            "accuracy": 0.5490921318090114,
            "f1": 0.5090692629583969,
            "f1_weighted": 0.5558717493406982
          },
          {
            "accuracy": 0.531271015467384,
            "f1": 0.509820959570585,
            "f1_weighted": 0.5355949214218161
          },
          {
            "accuracy": 0.5662407531943511,
            "f1": 0.5259053837829287,
            "f1_weighted": 0.5717024295988196
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.5571569109690112,
        "f1": 0.5269687819093777,
        "f1_weighted": 0.5613024106668459,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5571569109690112,
        "scores_per_experiment": [
          {
            "accuracy": 0.5636989670437776,
            "f1": 0.533336150741837,
            "f1_weighted": 0.5654637175333126
          },
          {
            "accuracy": 0.5563207083128382,
            "f1": 0.5099666628694306,
            "f1_weighted": 0.5621866447981361
          },
          {
            "accuracy": 0.5789473684210527,
            "f1": 0.5477790059494817,
            "f1_weighted": 0.5847286512730638
          },
          {
            "accuracy": 0.5750122970978849,
            "f1": 0.5388997681567346,
            "f1_weighted": 0.5808424252243056
          },
          {
            "accuracy": 0.5573044761436301,
            "f1": 0.5269153220532317,
            "f1_weighted": 0.5612576852268889
          },
          {
            "accuracy": 0.5272995573044762,
            "f1": 0.5156604434350563,
            "f1_weighted": 0.5268538827586363
          },
          {
            "accuracy": 0.5174618789965568,
            "f1": 0.4978451532424142,
            "f1_weighted": 0.5206116296870419
          },
          {
            "accuracy": 0.5568125922282341,
            "f1": 0.5268376248415082,
            "f1_weighted": 0.5621421111243464
          },
          {
            "accuracy": 0.544515494343335,
            "f1": 0.5190352258370248,
            "f1_weighted": 0.5505222248655433
          },
          {
            "accuracy": 0.5941957697983276,
            "f1": 0.5534124619670582,
            "f1_weighted": 0.5984151341771842
          }
        ]
      }
    ]
  },
  "task_name": "MassiveIntentClassification"
}