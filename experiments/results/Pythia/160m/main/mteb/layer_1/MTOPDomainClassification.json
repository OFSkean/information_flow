{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 41.930617809295654,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.768376652986776,
        "f1": 0.7629796544014054,
        "f1_weighted": 0.7713105753205234,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.768376652986776,
        "scores_per_experiment": [
          {
            "accuracy": 0.7293661650706794,
            "f1": 0.7313747676853765,
            "f1_weighted": 0.7333725816448204
          },
          {
            "accuracy": 0.7537619699042407,
            "f1": 0.7560063196356911,
            "f1_weighted": 0.7608644131757287
          },
          {
            "accuracy": 0.7761057911536707,
            "f1": 0.7655729613481616,
            "f1_weighted": 0.7802833933892184
          },
          {
            "accuracy": 0.7840857273141815,
            "f1": 0.7769402026282628,
            "f1_weighted": 0.7881543420296029
          },
          {
            "accuracy": 0.7995896032831737,
            "f1": 0.7914246806434662,
            "f1_weighted": 0.8018806151274913
          },
          {
            "accuracy": 0.7749658002735978,
            "f1": 0.7699728061748826,
            "f1_weighted": 0.7754631293467601
          },
          {
            "accuracy": 0.7448700410396717,
            "f1": 0.7354685788028945,
            "f1_weighted": 0.7426665299177642
          },
          {
            "accuracy": 0.7450980392156863,
            "f1": 0.740974185431385,
            "f1_weighted": 0.75014850755012
          },
          {
            "accuracy": 0.7758777929776561,
            "f1": 0.7727894884811574,
            "f1_weighted": 0.7800943900992573
          },
          {
            "accuracy": 0.8000455996352029,
            "f1": 0.7892725531827764,
            "f1_weighted": 0.8001778509244708
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7597762863534675,
        "f1": 0.7564776822516412,
        "f1_weighted": 0.761732365408725,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7597762863534675,
        "scores_per_experiment": [
          {
            "accuracy": 0.7337807606263982,
            "f1": 0.7351660284942342,
            "f1_weighted": 0.7365481119587806
          },
          {
            "accuracy": 0.7574944071588366,
            "f1": 0.759957772180787,
            "f1_weighted": 0.7617583101902589
          },
          {
            "accuracy": 0.760178970917226,
            "f1": 0.75162015794858,
            "f1_weighted": 0.7643164747749455
          },
          {
            "accuracy": 0.7753914988814318,
            "f1": 0.7747662004979627,
            "f1_weighted": 0.7798910987780752
          },
          {
            "accuracy": 0.792841163310962,
            "f1": 0.790222747235181,
            "f1_weighted": 0.7948239195726561
          },
          {
            "accuracy": 0.767337807606264,
            "f1": 0.7656305095179711,
            "f1_weighted": 0.7676289835232919
          },
          {
            "accuracy": 0.7279642058165549,
            "f1": 0.7164504717842756,
            "f1_weighted": 0.7251260362500592
          },
          {
            "accuracy": 0.7293064876957495,
            "f1": 0.7287282893045628,
            "f1_weighted": 0.7329296703480259
          },
          {
            "accuracy": 0.767337807606264,
            "f1": 0.7649516595321859,
            "f1_weighted": 0.7701452992493325
          },
          {
            "accuracy": 0.7861297539149888,
            "f1": 0.7772829860206714,
            "f1_weighted": 0.7841557494418242
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}