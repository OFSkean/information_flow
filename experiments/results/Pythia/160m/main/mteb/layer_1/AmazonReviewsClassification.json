{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 60.17677664756775,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.32454,
        "f1": 0.32306187240154866,
        "f1_weighted": 0.32306187240154866,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.32454,
        "scores_per_experiment": [
          {
            "accuracy": 0.343,
            "f1": 0.34478923521938637,
            "f1_weighted": 0.3447892352193864
          },
          {
            "accuracy": 0.3364,
            "f1": 0.3394967973590536,
            "f1_weighted": 0.3394967973590536
          },
          {
            "accuracy": 0.3058,
            "f1": 0.30748714018305257,
            "f1_weighted": 0.30748714018305257
          },
          {
            "accuracy": 0.3126,
            "f1": 0.3094026488698773,
            "f1_weighted": 0.3094026488698773
          },
          {
            "accuracy": 0.3764,
            "f1": 0.36574540529635263,
            "f1_weighted": 0.3657454052963526
          },
          {
            "accuracy": 0.2886,
            "f1": 0.29150067162621285,
            "f1_weighted": 0.2915006716262129
          },
          {
            "accuracy": 0.2792,
            "f1": 0.27897606255256957,
            "f1_weighted": 0.2789760625525696
          },
          {
            "accuracy": 0.343,
            "f1": 0.3399522523441218,
            "f1_weighted": 0.3399522523441218
          },
          {
            "accuracy": 0.3158,
            "f1": 0.314575826456977,
            "f1_weighted": 0.31457582645697696
          },
          {
            "accuracy": 0.3446,
            "f1": 0.3386926841078829,
            "f1_weighted": 0.33869268410788284
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.32123999999999997,
        "f1": 0.31974907830452315,
        "f1_weighted": 0.31974907830452315,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.32123999999999997,
        "scores_per_experiment": [
          {
            "accuracy": 0.3292,
            "f1": 0.33189988604978454,
            "f1_weighted": 0.3318998860497846
          },
          {
            "accuracy": 0.3278,
            "f1": 0.332428952949853,
            "f1_weighted": 0.332428952949853
          },
          {
            "accuracy": 0.307,
            "f1": 0.3093292680517455,
            "f1_weighted": 0.30932926805174543
          },
          {
            "accuracy": 0.2974,
            "f1": 0.2938022650126792,
            "f1_weighted": 0.2938022650126792
          },
          {
            "accuracy": 0.3782,
            "f1": 0.36529037910633144,
            "f1_weighted": 0.36529037910633144
          },
          {
            "accuracy": 0.2944,
            "f1": 0.29560417721961046,
            "f1_weighted": 0.29560417721961046
          },
          {
            "accuracy": 0.2854,
            "f1": 0.28457627613230485,
            "f1_weighted": 0.28457627613230485
          },
          {
            "accuracy": 0.322,
            "f1": 0.31945507957155805,
            "f1_weighted": 0.31945507957155805
          },
          {
            "accuracy": 0.3144,
            "f1": 0.31386258834114245,
            "f1_weighted": 0.31386258834114245
          },
          {
            "accuracy": 0.3566,
            "f1": 0.35124191061022164,
            "f1_weighted": 0.3512419106102216
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}