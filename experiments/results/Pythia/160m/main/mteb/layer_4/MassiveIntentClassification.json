{
  "dataset_revision": "4672e20407010da34463acc759c162ca9734bca6",
  "evaluation_time": 75.77886986732483,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.5410221923335575,
        "f1": 0.5112746223047168,
        "f1_weighted": 0.5446939411971751,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5410221923335575,
        "scores_per_experiment": [
          {
            "accuracy": 0.5342972427706792,
            "f1": 0.510652262086933,
            "f1_weighted": 0.5397016063096454
          },
          {
            "accuracy": 0.5490921318090114,
            "f1": 0.5121629217073282,
            "f1_weighted": 0.5528770708181074
          },
          {
            "accuracy": 0.5437121721587088,
            "f1": 0.5168772926469086,
            "f1_weighted": 0.545726597376531
          },
          {
            "accuracy": 0.5544720914593141,
            "f1": 0.5150338132435404,
            "f1_weighted": 0.5620282405073547
          },
          {
            "accuracy": 0.5497646267652992,
            "f1": 0.5107466447234418,
            "f1_weighted": 0.5500182004164601
          },
          {
            "accuracy": 0.5228648285137861,
            "f1": 0.5064869164099765,
            "f1_weighted": 0.5220845895402477
          },
          {
            "accuracy": 0.5215198386012105,
            "f1": 0.5026554382399945,
            "f1_weighted": 0.5272035341087506
          },
          {
            "accuracy": 0.5457296570275723,
            "f1": 0.5079319510926916,
            "f1_weighted": 0.553881871705986
          },
          {
            "accuracy": 0.531607262945528,
            "f1": 0.5056123670736438,
            "f1_weighted": 0.5335406283085308
          },
          {
            "accuracy": 0.5571620712844654,
            "f1": 0.5245866158227097,
            "f1_weighted": 0.5598770728801364
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.5529758976881456,
        "f1": 0.5257708864059618,
        "f1_weighted": 0.5566317136469229,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5529758976881456,
        "scores_per_experiment": [
          {
            "accuracy": 0.5391047712739794,
            "f1": 0.5176259699498309,
            "f1_weighted": 0.5381193684645772
          },
          {
            "accuracy": 0.5602557796360059,
            "f1": 0.513413875488262,
            "f1_weighted": 0.5653531312826008
          },
          {
            "accuracy": 0.5789473684210527,
            "f1": 0.5464657278570982,
            "f1_weighted": 0.580205828827676
          },
          {
            "accuracy": 0.5607476635514018,
            "f1": 0.524144361933301,
            "f1_weighted": 0.5688745176771174
          },
          {
            "accuracy": 0.5759960649286768,
            "f1": 0.5556754912243611,
            "f1_weighted": 0.5760444084991098
          },
          {
            "accuracy": 0.5351696999508117,
            "f1": 0.520674218220856,
            "f1_weighted": 0.5383686521330513
          },
          {
            "accuracy": 0.5164781111657649,
            "f1": 0.505316112940212,
            "f1_weighted": 0.5203684400367047
          },
          {
            "accuracy": 0.5489424495818986,
            "f1": 0.5195348818012001,
            "f1_weighted": 0.5551674566569835
          },
          {
            "accuracy": 0.5317265125430398,
            "f1": 0.5116056861297823,
            "f1_weighted": 0.5377281989116938
          },
          {
            "accuracy": 0.5823905558288244,
            "f1": 0.5432525385147131,
            "f1_weighted": 0.5860871339797143
          }
        ]
      }
    ]
  },
  "task_name": "MassiveIntentClassification"
}