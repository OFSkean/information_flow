{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 84.82424330711365,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.32944,
        "f1": 0.3280393636213129,
        "f1_weighted": 0.3280393636213129,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.32944,
        "scores_per_experiment": [
          {
            "accuracy": 0.3412,
            "f1": 0.34278921997682743,
            "f1_weighted": 0.34278921997682743
          },
          {
            "accuracy": 0.3318,
            "f1": 0.335174261610966,
            "f1_weighted": 0.33517426161096603
          },
          {
            "accuracy": 0.314,
            "f1": 0.3075648706388493,
            "f1_weighted": 0.30756487063884935
          },
          {
            "accuracy": 0.3382,
            "f1": 0.3386894326405639,
            "f1_weighted": 0.3386894326405639
          },
          {
            "accuracy": 0.38,
            "f1": 0.3728479960148986,
            "f1_weighted": 0.3728479960148986
          },
          {
            "accuracy": 0.2958,
            "f1": 0.2974050940273098,
            "f1_weighted": 0.2974050940273098
          },
          {
            "accuracy": 0.3004,
            "f1": 0.3005216357901852,
            "f1_weighted": 0.30052163579018526
          },
          {
            "accuracy": 0.347,
            "f1": 0.33889620945145743,
            "f1_weighted": 0.3388962094514574
          },
          {
            "accuracy": 0.2944,
            "f1": 0.29561662277664036,
            "f1_weighted": 0.29561662277664036
          },
          {
            "accuracy": 0.3516,
            "f1": 0.3508882932854309,
            "f1_weighted": 0.350888293285431
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.32822,
        "f1": 0.32666277895506657,
        "f1_weighted": 0.3266627789550665,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.32822,
        "scores_per_experiment": [
          {
            "accuracy": 0.3326,
            "f1": 0.33452845111626983,
            "f1_weighted": 0.3345284511162698
          },
          {
            "accuracy": 0.3302,
            "f1": 0.3351647456325332,
            "f1_weighted": 0.3351647456325332
          },
          {
            "accuracy": 0.327,
            "f1": 0.3233488041187391,
            "f1_weighted": 0.3233488041187391
          },
          {
            "accuracy": 0.3266,
            "f1": 0.3246643382487992,
            "f1_weighted": 0.32466433824879914
          },
          {
            "accuracy": 0.3854,
            "f1": 0.3765293064460109,
            "f1_weighted": 0.37652930644601085
          },
          {
            "accuracy": 0.3018,
            "f1": 0.3030914820599397,
            "f1_weighted": 0.30309148205993963
          },
          {
            "accuracy": 0.3048,
            "f1": 0.30544555646666216,
            "f1_weighted": 0.3054455564666622
          },
          {
            "accuracy": 0.3318,
            "f1": 0.32091974115630223,
            "f1_weighted": 0.32091974115630223
          },
          {
            "accuracy": 0.298,
            "f1": 0.29985281526653346,
            "f1_weighted": 0.29985281526653346
          },
          {
            "accuracy": 0.344,
            "f1": 0.34308254903887564,
            "f1_weighted": 0.34308254903887564
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}