{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 48.73882865905762,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.779046967624259,
        "f1": 0.7751085383340595,
        "f1_weighted": 0.7814636182334913,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.779046967624259,
        "scores_per_experiment": [
          {
            "accuracy": 0.7564979480164159,
            "f1": 0.7564963107040008,
            "f1_weighted": 0.7574713030386618
          },
          {
            "accuracy": 0.8109895120839034,
            "f1": 0.8074026458195973,
            "f1_weighted": 0.8133603806819134
          },
          {
            "accuracy": 0.7653898768809849,
            "f1": 0.7534288824171949,
            "f1_weighted": 0.7730162178437959
          },
          {
            "accuracy": 0.780437756497948,
            "f1": 0.7733355585688367,
            "f1_weighted": 0.7842959341833371
          },
          {
            "accuracy": 0.8046055631554948,
            "f1": 0.7973939674904614,
            "f1_weighted": 0.8054893016333983
          },
          {
            "accuracy": 0.7984496124031008,
            "f1": 0.7940550267230546,
            "f1_weighted": 0.7993908350978476
          },
          {
            "accuracy": 0.7626538987688098,
            "f1": 0.7597809685389895,
            "f1_weighted": 0.7603365837573627
          },
          {
            "accuracy": 0.7448700410396717,
            "f1": 0.7473640667587215,
            "f1_weighted": 0.7499187624508287
          },
          {
            "accuracy": 0.7922936616507068,
            "f1": 0.7931272215444399,
            "f1_weighted": 0.7937755285690659
          },
          {
            "accuracy": 0.774281805745554,
            "f1": 0.7687007347752973,
            "f1_weighted": 0.7775813350787015
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7744519015659954,
        "f1": 0.7740356553851698,
        "f1_weighted": 0.7766455170695792,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7744519015659954,
        "scores_per_experiment": [
          {
            "accuracy": 0.7552572706935123,
            "f1": 0.7611384861096475,
            "f1_weighted": 0.7554284180804767
          },
          {
            "accuracy": 0.8040268456375839,
            "f1": 0.8024008066801684,
            "f1_weighted": 0.8058276566488447
          },
          {
            "accuracy": 0.7615212527964206,
            "f1": 0.7523046639486395,
            "f1_weighted": 0.7665205521605102
          },
          {
            "accuracy": 0.7879194630872484,
            "f1": 0.786932851676172,
            "f1_weighted": 0.7936203597653484
          },
          {
            "accuracy": 0.8026845637583893,
            "f1": 0.8028817756348988,
            "f1_weighted": 0.8030379109135971
          },
          {
            "accuracy": 0.7803131991051454,
            "f1": 0.7793494996690318,
            "f1_weighted": 0.7818617380864131
          },
          {
            "accuracy": 0.760178970917226,
            "f1": 0.7579522802764163,
            "f1_weighted": 0.7596140312157714
          },
          {
            "accuracy": 0.7463087248322148,
            "f1": 0.7499658760254458,
            "f1_weighted": 0.7497332769152895
          },
          {
            "accuracy": 0.7789709172259508,
            "f1": 0.7804766036286206,
            "f1_weighted": 0.7797519151568578
          },
          {
            "accuracy": 0.767337807606264,
            "f1": 0.7669537102026573,
            "f1_weighted": 0.7710593117526823
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}