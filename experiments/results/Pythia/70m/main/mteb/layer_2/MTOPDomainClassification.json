{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 42.045212268829346,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.7342453260373917,
        "f1": 0.7280466636570928,
        "f1_weighted": 0.737048881841704,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7342453260373917,
        "scores_per_experiment": [
          {
            "accuracy": 0.6801185590515276,
            "f1": 0.6760522812983424,
            "f1_weighted": 0.6833419829302583
          },
          {
            "accuracy": 0.7325581395348837,
            "f1": 0.7335899956513448,
            "f1_weighted": 0.73712931084621
          },
          {
            "accuracy": 0.7282261741906064,
            "f1": 0.7184512348493933,
            "f1_weighted": 0.7367405326125551
          },
          {
            "accuracy": 0.7647058823529411,
            "f1": 0.7533098246398318,
            "f1_weighted": 0.7663127258818416
          },
          {
            "accuracy": 0.748062015503876,
            "f1": 0.7385513100147535,
            "f1_weighted": 0.749305123740113
          },
          {
            "accuracy": 0.7585499316005472,
            "f1": 0.7513672163854775,
            "f1_weighted": 0.7598672269978494
          },
          {
            "accuracy": 0.6940264477884177,
            "f1": 0.6863805919355519,
            "f1_weighted": 0.6905280606915178
          },
          {
            "accuracy": 0.7216142270861833,
            "f1": 0.7210662746270201,
            "f1_weighted": 0.7283653855702894
          },
          {
            "accuracy": 0.7503419972640218,
            "f1": 0.7453219234050117,
            "f1_weighted": 0.7536950518319433
          },
          {
            "accuracy": 0.764249886000912,
            "f1": 0.7563759837642011,
            "f1_weighted": 0.7652034173144621
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.72496644295302,
        "f1": 0.7228359258927992,
        "f1_weighted": 0.7271614493417906,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.72496644295302,
        "scores_per_experiment": [
          {
            "accuracy": 0.661744966442953,
            "f1": 0.6650082504203143,
            "f1_weighted": 0.6625346768477743
          },
          {
            "accuracy": 0.7319910514541387,
            "f1": 0.7340672704949689,
            "f1_weighted": 0.7357368391633899
          },
          {
            "accuracy": 0.7100671140939597,
            "f1": 0.7089630357417591,
            "f1_weighted": 0.7195881380390935
          },
          {
            "accuracy": 0.7597315436241611,
            "f1": 0.755536461510443,
            "f1_weighted": 0.7614302908035365
          },
          {
            "accuracy": 0.7548098434004474,
            "f1": 0.7526631903791828,
            "f1_weighted": 0.755963945872575
          },
          {
            "accuracy": 0.7480984340044743,
            "f1": 0.7428721592514743,
            "f1_weighted": 0.7478047021880133
          },
          {
            "accuracy": 0.6917225950782998,
            "f1": 0.6849233354549149,
            "f1_weighted": 0.6901012006406381
          },
          {
            "accuracy": 0.7006711409395974,
            "f1": 0.7047719087378185,
            "f1_weighted": 0.7064602188192298
          },
          {
            "accuracy": 0.7436241610738255,
            "f1": 0.7394222144369372,
            "f1_weighted": 0.7454641898886115
          },
          {
            "accuracy": 0.7472035794183445,
            "f1": 0.7401314325001795,
            "f1_weighted": 0.7465302911550437
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}