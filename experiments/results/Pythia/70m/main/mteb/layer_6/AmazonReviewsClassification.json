{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 81.59626007080078,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.32594,
        "f1": 0.3255448197498419,
        "f1_weighted": 0.3255448197498419,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.32594,
        "scores_per_experiment": [
          {
            "accuracy": 0.3436,
            "f1": 0.3373074478200919,
            "f1_weighted": 0.3373074478200919
          },
          {
            "accuracy": 0.3392,
            "f1": 0.3374279690700297,
            "f1_weighted": 0.33742796907002964
          },
          {
            "accuracy": 0.3026,
            "f1": 0.3031629037005159,
            "f1_weighted": 0.3031629037005159
          },
          {
            "accuracy": 0.3198,
            "f1": 0.323824072380304,
            "f1_weighted": 0.323824072380304
          },
          {
            "accuracy": 0.3538,
            "f1": 0.3528275106849145,
            "f1_weighted": 0.3528275106849145
          },
          {
            "accuracy": 0.3194,
            "f1": 0.3125640584193443,
            "f1_weighted": 0.3125640584193443
          },
          {
            "accuracy": 0.2756,
            "f1": 0.2740074142160914,
            "f1_weighted": 0.2740074142160915
          },
          {
            "accuracy": 0.3522,
            "f1": 0.352074739036071,
            "f1_weighted": 0.352074739036071
          },
          {
            "accuracy": 0.3236,
            "f1": 0.32523191168903814,
            "f1_weighted": 0.3252319116890381
          },
          {
            "accuracy": 0.3296,
            "f1": 0.33702017048201827,
            "f1_weighted": 0.3370201704820182
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.32378,
        "f1": 0.3234143790710891,
        "f1_weighted": 0.3234143790710891,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.32378,
        "scores_per_experiment": [
          {
            "accuracy": 0.3354,
            "f1": 0.3298041341255894,
            "f1_weighted": 0.3298041341255894
          },
          {
            "accuracy": 0.341,
            "f1": 0.34169461519214295,
            "f1_weighted": 0.3416946151921429
          },
          {
            "accuracy": 0.3136,
            "f1": 0.3141497623257036,
            "f1_weighted": 0.3141497623257036
          },
          {
            "accuracy": 0.3118,
            "f1": 0.31438634042359404,
            "f1_weighted": 0.314386340423594
          },
          {
            "accuracy": 0.3468,
            "f1": 0.34428496039850687,
            "f1_weighted": 0.34428496039850687
          },
          {
            "accuracy": 0.3166,
            "f1": 0.3082233687297533,
            "f1_weighted": 0.3082233687297533
          },
          {
            "accuracy": 0.2782,
            "f1": 0.2780756128784652,
            "f1_weighted": 0.2780756128784652
          },
          {
            "accuracy": 0.3402,
            "f1": 0.33999097925501454,
            "f1_weighted": 0.33999097925501454
          },
          {
            "accuracy": 0.3302,
            "f1": 0.33244211516726285,
            "f1_weighted": 0.33244211516726285
          },
          {
            "accuracy": 0.324,
            "f1": 0.3310919022148583,
            "f1_weighted": 0.33109190221485824
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}