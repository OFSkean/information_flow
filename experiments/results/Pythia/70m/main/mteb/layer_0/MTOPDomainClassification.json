{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 38.173333406448364,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.7881212950296398,
        "f1": 0.7864656214286164,
        "f1_weighted": 0.7912287141957319,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7881212950296398,
        "scores_per_experiment": [
          {
            "accuracy": 0.7649338805289557,
            "f1": 0.7615102800687221,
            "f1_weighted": 0.7663003245932308
          },
          {
            "accuracy": 0.775421796625627,
            "f1": 0.7788346543216701,
            "f1_weighted": 0.7796802826897468
          },
          {
            "accuracy": 0.7893296853625171,
            "f1": 0.7839181822333111,
            "f1_weighted": 0.7921572985852253
          },
          {
            "accuracy": 0.8116735066119471,
            "f1": 0.8096083131213284,
            "f1_weighted": 0.815826627546653
          },
          {
            "accuracy": 0.8084815321477428,
            "f1": 0.8057486619493858,
            "f1_weighted": 0.8148393174738305
          },
          {
            "accuracy": 0.791609667122663,
            "f1": 0.7929366008198339,
            "f1_weighted": 0.7934534262053178
          },
          {
            "accuracy": 0.7767897856817145,
            "f1": 0.7749585163487512,
            "f1_weighted": 0.7764397403696196
          },
          {
            "accuracy": 0.7633378932968536,
            "f1": 0.7604613725346905,
            "f1_weighted": 0.7690886934940814
          },
          {
            "accuracy": 0.7863657090743275,
            "f1": 0.7880298823712615,
            "f1_weighted": 0.7893539939110343
          },
          {
            "accuracy": 0.8132694938440492,
            "f1": 0.8086497505172097,
            "f1_weighted": 0.8151474370885796
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7820581655480985,
        "f1": 0.7828484738403504,
        "f1_weighted": 0.7844746793513715,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7820581655480985,
        "scores_per_experiment": [
          {
            "accuracy": 0.7579418344519016,
            "f1": 0.755698925661682,
            "f1_weighted": 0.7585315033529504
          },
          {
            "accuracy": 0.7758389261744967,
            "f1": 0.7796513845371904,
            "f1_weighted": 0.7783864177742293
          },
          {
            "accuracy": 0.7829977628635347,
            "f1": 0.781216505526094,
            "f1_weighted": 0.7857063066457038
          },
          {
            "accuracy": 0.8022371364653244,
            "f1": 0.806195681138501,
            "f1_weighted": 0.8066035889852381
          },
          {
            "accuracy": 0.8098434004474273,
            "f1": 0.8116283567482551,
            "f1_weighted": 0.8149714914609582
          },
          {
            "accuracy": 0.774496644295302,
            "f1": 0.7781797022303039,
            "f1_weighted": 0.7759586539182529
          },
          {
            "accuracy": 0.7677852348993288,
            "f1": 0.7639772682406452,
            "f1_weighted": 0.7670540906764652
          },
          {
            "accuracy": 0.7597315436241611,
            "f1": 0.7604270807076167,
            "f1_weighted": 0.7630452377073018
          },
          {
            "accuracy": 0.7914988814317674,
            "f1": 0.794093397219532,
            "f1_weighted": 0.7945394780589066
          },
          {
            "accuracy": 0.7982102908277405,
            "f1": 0.7974164363936833,
            "f1_weighted": 0.7999500249337085
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}