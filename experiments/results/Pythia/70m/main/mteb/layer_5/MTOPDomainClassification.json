{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 42.381105184555054,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.7340857273141814,
        "f1": 0.7280907305545369,
        "f1_weighted": 0.736211901972893,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7340857273141814,
        "scores_per_experiment": [
          {
            "accuracy": 0.6853625170998632,
            "f1": 0.6846753853866976,
            "f1_weighted": 0.6878404209848349
          },
          {
            "accuracy": 0.7432740538075695,
            "f1": 0.7359687995805032,
            "f1_weighted": 0.7470965166456618
          },
          {
            "accuracy": 0.7321021431828545,
            "f1": 0.7251740765697396,
            "f1_weighted": 0.7381568588940054
          },
          {
            "accuracy": 0.7514819881440948,
            "f1": 0.7436089477025458,
            "f1_weighted": 0.7526999901574861
          },
          {
            "accuracy": 0.7533059735522116,
            "f1": 0.7441063958842528,
            "f1_weighted": 0.7564930674218908
          },
          {
            "accuracy": 0.748062015503876,
            "f1": 0.7391315192956561,
            "f1_weighted": 0.748672326555398
          },
          {
            "accuracy": 0.7191062471500228,
            "f1": 0.712108849871753,
            "f1_weighted": 0.7164277687151583
          },
          {
            "accuracy": 0.7056543547651619,
            "f1": 0.705383830916123,
            "f1_weighted": 0.7097958243538702
          },
          {
            "accuracy": 0.7466940264477884,
            "f1": 0.7437598164813793,
            "f1_weighted": 0.7490304764162664
          },
          {
            "accuracy": 0.7558139534883721,
            "f1": 0.7469896838567179,
            "f1_weighted": 0.7559057695843573
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7252796420581655,
        "f1": 0.7225315518085402,
        "f1_weighted": 0.7265582539552271,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7252796420581655,
        "scores_per_experiment": [
          {
            "accuracy": 0.6738255033557047,
            "f1": 0.6764507101500814,
            "f1_weighted": 0.6756065127974079
          },
          {
            "accuracy": 0.7387024608501118,
            "f1": 0.7353277400308881,
            "f1_weighted": 0.7406011513603302
          },
          {
            "accuracy": 0.7167785234899329,
            "f1": 0.7117056025309142,
            "f1_weighted": 0.7231012312820859
          },
          {
            "accuracy": 0.7539149888143176,
            "f1": 0.7524544941755223,
            "f1_weighted": 0.7566346727691884
          },
          {
            "accuracy": 0.7422818791946308,
            "f1": 0.7358646897528093,
            "f1_weighted": 0.7443320869286691
          },
          {
            "accuracy": 0.7319910514541387,
            "f1": 0.7289925232887898,
            "f1_weighted": 0.7308782392980597
          },
          {
            "accuracy": 0.7069351230425056,
            "f1": 0.7011711777056172,
            "f1_weighted": 0.7048178755887016
          },
          {
            "accuracy": 0.7073825503355705,
            "f1": 0.7067607260154982,
            "f1_weighted": 0.7087889710863643
          },
          {
            "accuracy": 0.7328859060402685,
            "f1": 0.7318401454476731,
            "f1_weighted": 0.7335771131136919
          },
          {
            "accuracy": 0.7480984340044743,
            "f1": 0.7447477089876084,
            "f1_weighted": 0.7472446853277717
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}