{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 43.20706081390381,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.7152986776105792,
        "f1": 0.7082593560580175,
        "f1_weighted": 0.7172576708808199,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7152986776105792,
        "scores_per_experiment": [
          {
            "accuracy": 0.6741906064751482,
            "f1": 0.670889961984843,
            "f1_weighted": 0.6764411025988525
          },
          {
            "accuracy": 0.7188782489740082,
            "f1": 0.7120718875628417,
            "f1_weighted": 0.7247119481519622
          },
          {
            "accuracy": 0.7124943000455997,
            "f1": 0.7051145242960598,
            "f1_weighted": 0.7206049613434675
          },
          {
            "accuracy": 0.7243502051983585,
            "f1": 0.7070513261166393,
            "f1_weighted": 0.7237792549243052
          },
          {
            "accuracy": 0.7286821705426356,
            "f1": 0.7228248692916135,
            "f1_weighted": 0.730937382274666
          },
          {
            "accuracy": 0.7355221158230734,
            "f1": 0.7272984641567174,
            "f1_weighted": 0.7371162207412505
          },
          {
            "accuracy": 0.686046511627907,
            "f1": 0.6842514038833555,
            "f1_weighted": 0.6796305601113504
          },
          {
            "accuracy": 0.7104423164614683,
            "f1": 0.7036765703775012,
            "f1_weighted": 0.7151754099425102
          },
          {
            "accuracy": 0.730734154126767,
            "f1": 0.7275126564587399,
            "f1_weighted": 0.7336162567567475
          },
          {
            "accuracy": 0.7316461468308254,
            "f1": 0.7219018964518635,
            "f1_weighted": 0.7305636119630882
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7084116331096197,
        "f1": 0.7047847007773607,
        "f1_weighted": 0.7089657042119453,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7084116331096197,
        "scores_per_experiment": [
          {
            "accuracy": 0.6742729306487696,
            "f1": 0.6748499014532278,
            "f1_weighted": 0.6755634697839684
          },
          {
            "accuracy": 0.7181208053691275,
            "f1": 0.7138120642735617,
            "f1_weighted": 0.7210317585851712
          },
          {
            "accuracy": 0.7087248322147651,
            "f1": 0.7035378911324909,
            "f1_weighted": 0.7157966738883362
          },
          {
            "accuracy": 0.7284116331096196,
            "f1": 0.718481483351778,
            "f1_weighted": 0.7288734487063664
          },
          {
            "accuracy": 0.7225950782997763,
            "f1": 0.7215120184108756,
            "f1_weighted": 0.7226224149074585
          },
          {
            "accuracy": 0.7239373601789709,
            "f1": 0.7198618033492482,
            "f1_weighted": 0.7246671873550325
          },
          {
            "accuracy": 0.6572706935123043,
            "f1": 0.6546605763717483,
            "f1_weighted": 0.649914044930844
          },
          {
            "accuracy": 0.7024608501118568,
            "f1": 0.6987146214882934,
            "f1_weighted": 0.704907159545182
          },
          {
            "accuracy": 0.7315436241610739,
            "f1": 0.7296613556860357,
            "f1_weighted": 0.7326528066091657
          },
          {
            "accuracy": 0.7167785234899329,
            "f1": 0.712755292256347,
            "f1_weighted": 0.7136280778079268
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}