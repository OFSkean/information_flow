{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 71.18598771095276,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.31254000000000004,
        "f1": 0.31295820302472477,
        "f1_weighted": 0.31295820302472477,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.31254000000000004,
        "scores_per_experiment": [
          {
            "accuracy": 0.33,
            "f1": 0.332256858869754,
            "f1_weighted": 0.33225685886975403
          },
          {
            "accuracy": 0.3268,
            "f1": 0.3260957527789423,
            "f1_weighted": 0.3260957527789423
          },
          {
            "accuracy": 0.3032,
            "f1": 0.3023341523286273,
            "f1_weighted": 0.3023341523286273
          },
          {
            "accuracy": 0.3178,
            "f1": 0.321507179405704,
            "f1_weighted": 0.321507179405704
          },
          {
            "accuracy": 0.3336,
            "f1": 0.33272303200408493,
            "f1_weighted": 0.332723032004085
          },
          {
            "accuracy": 0.2976,
            "f1": 0.29254407401929206,
            "f1_weighted": 0.29254407401929206
          },
          {
            "accuracy": 0.2752,
            "f1": 0.27638938178228906,
            "f1_weighted": 0.276389381782289
          },
          {
            "accuracy": 0.3186,
            "f1": 0.3192273401556978,
            "f1_weighted": 0.31922734015569776
          },
          {
            "accuracy": 0.3004,
            "f1": 0.2997099045528217,
            "f1_weighted": 0.2997099045528217
          },
          {
            "accuracy": 0.3222,
            "f1": 0.32679435435003523,
            "f1_weighted": 0.3267943543500352
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.31082000000000004,
        "f1": 0.31096671317385355,
        "f1_weighted": 0.3109667131738536,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.31082000000000004,
        "scores_per_experiment": [
          {
            "accuracy": 0.3178,
            "f1": 0.3201594784172813,
            "f1_weighted": 0.3201594784172813
          },
          {
            "accuracy": 0.3346,
            "f1": 0.33538532506202257,
            "f1_weighted": 0.3353853250620225
          },
          {
            "accuracy": 0.2978,
            "f1": 0.2969078688174542,
            "f1_weighted": 0.29690786881745423
          },
          {
            "accuracy": 0.3006,
            "f1": 0.30402854345915464,
            "f1_weighted": 0.3040285434591547
          },
          {
            "accuracy": 0.3282,
            "f1": 0.3259432075915356,
            "f1_weighted": 0.3259432075915356
          },
          {
            "accuracy": 0.2988,
            "f1": 0.2906603533095461,
            "f1_weighted": 0.2906603533095461
          },
          {
            "accuracy": 0.2774,
            "f1": 0.2786763039811396,
            "f1_weighted": 0.27867630398113963
          },
          {
            "accuracy": 0.311,
            "f1": 0.31046180412008556,
            "f1_weighted": 0.31046180412008556
          },
          {
            "accuracy": 0.3088,
            "f1": 0.30965850799578976,
            "f1_weighted": 0.30965850799578976
          },
          {
            "accuracy": 0.3332,
            "f1": 0.33778573898452646,
            "f1_weighted": 0.3377857389845264
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}