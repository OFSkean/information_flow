{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 43.71704936027527,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.7190606475148199,
        "f1": 0.7135838924417008,
        "f1_weighted": 0.7223278072555437,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7190606475148199,
        "scores_per_experiment": [
          {
            "accuracy": 0.6880984952120383,
            "f1": 0.6850001558078231,
            "f1_weighted": 0.6909725609118464
          },
          {
            "accuracy": 0.7156862745098039,
            "f1": 0.7177171361202475,
            "f1_weighted": 0.7190658238351911
          },
          {
            "accuracy": 0.70953032375741,
            "f1": 0.7026981746898623,
            "f1_weighted": 0.7191627692061312
          },
          {
            "accuracy": 0.740766073871409,
            "f1": 0.7315239865724256,
            "f1_weighted": 0.7449671398376139
          },
          {
            "accuracy": 0.7560419516643867,
            "f1": 0.7417089811084956,
            "f1_weighted": 0.7565335717919656
          },
          {
            "accuracy": 0.7437300501595987,
            "f1": 0.7391899517289101,
            "f1_weighted": 0.7465192856948136
          },
          {
            "accuracy": 0.6716826265389877,
            "f1": 0.660329108064074,
            "f1_weighted": 0.6668310116299381
          },
          {
            "accuracy": 0.6965344277245782,
            "f1": 0.6983960654225064,
            "f1_weighted": 0.7042044918427848
          },
          {
            "accuracy": 0.7282261741906064,
            "f1": 0.7249181182465937,
            "f1_weighted": 0.7341039711110896
          },
          {
            "accuracy": 0.7403100775193798,
            "f1": 0.7343572466560709,
            "f1_weighted": 0.7409174466940639
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7082774049217002,
        "f1": 0.7050111774836075,
        "f1_weighted": 0.7107994179541125,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7082774049217002,
        "scores_per_experiment": [
          {
            "accuracy": 0.6823266219239373,
            "f1": 0.6806499695632753,
            "f1_weighted": 0.6843567060279495
          },
          {
            "accuracy": 0.7082774049217002,
            "f1": 0.7113932822786665,
            "f1_weighted": 0.7112488393398557
          },
          {
            "accuracy": 0.7118568232662192,
            "f1": 0.7051784899345439,
            "f1_weighted": 0.7192076038177757
          },
          {
            "accuracy": 0.7306487695749441,
            "f1": 0.7265426712190819,
            "f1_weighted": 0.7333474226809555
          },
          {
            "accuracy": 0.7570469798657719,
            "f1": 0.749082443682849,
            "f1_weighted": 0.7562805704069058
          },
          {
            "accuracy": 0.7194630872483222,
            "f1": 0.7192149103975688,
            "f1_weighted": 0.7199870058897114
          },
          {
            "accuracy": 0.6478747203579418,
            "f1": 0.6359750071962359,
            "f1_weighted": 0.6462246004383313
          },
          {
            "accuracy": 0.6774049217002237,
            "f1": 0.6788159801326142,
            "f1_weighted": 0.6835785892013959
          },
          {
            "accuracy": 0.7167785234899329,
            "f1": 0.7140856114811222,
            "f1_weighted": 0.7213784194294995
          },
          {
            "accuracy": 0.731096196868009,
            "f1": 0.7291734089501175,
            "f1_weighted": 0.7323844223087447
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}