{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 55.46421408653259,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.31589999999999996,
        "f1": 0.31480484193892333,
        "f1_weighted": 0.31480484193892333,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.31589999999999996,
        "scores_per_experiment": [
          {
            "accuracy": 0.3436,
            "f1": 0.3446337333398771,
            "f1_weighted": 0.3446337333398772
          },
          {
            "accuracy": 0.3152,
            "f1": 0.32217964521582443,
            "f1_weighted": 0.3221796452158244
          },
          {
            "accuracy": 0.3014,
            "f1": 0.30126686864621466,
            "f1_weighted": 0.30126686864621466
          },
          {
            "accuracy": 0.3104,
            "f1": 0.3083036957058663,
            "f1_weighted": 0.30830369570586635
          },
          {
            "accuracy": 0.366,
            "f1": 0.36115277028446574,
            "f1_weighted": 0.36115277028446574
          },
          {
            "accuracy": 0.282,
            "f1": 0.28014419003849234,
            "f1_weighted": 0.28014419003849234
          },
          {
            "accuracy": 0.265,
            "f1": 0.2619323901700804,
            "f1_weighted": 0.26193239017008035
          },
          {
            "accuracy": 0.3448,
            "f1": 0.33861355390648795,
            "f1_weighted": 0.3386135539064879
          },
          {
            "accuracy": 0.3034,
            "f1": 0.3031473737815178,
            "f1_weighted": 0.3031473737815178
          },
          {
            "accuracy": 0.3272,
            "f1": 0.3266741983004066,
            "f1_weighted": 0.3266741983004066
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.31123999999999996,
        "f1": 0.30951591155415514,
        "f1_weighted": 0.30951591155415514,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.31123999999999996,
        "scores_per_experiment": [
          {
            "accuracy": 0.321,
            "f1": 0.3229162830022535,
            "f1_weighted": 0.32291628300225345
          },
          {
            "accuracy": 0.306,
            "f1": 0.31394218612285335,
            "f1_weighted": 0.31394218612285335
          },
          {
            "accuracy": 0.3008,
            "f1": 0.30087913120532217,
            "f1_weighted": 0.30087913120532217
          },
          {
            "accuracy": 0.2876,
            "f1": 0.2842566101043828,
            "f1_weighted": 0.2842566101043828
          },
          {
            "accuracy": 0.3554,
            "f1": 0.34835004700632144,
            "f1_weighted": 0.34835004700632144
          },
          {
            "accuracy": 0.287,
            "f1": 0.28274393799019293,
            "f1_weighted": 0.2827439379901929
          },
          {
            "accuracy": 0.2764,
            "f1": 0.272575787297615,
            "f1_weighted": 0.272575787297615
          },
          {
            "accuracy": 0.3332,
            "f1": 0.32902657551896286,
            "f1_weighted": 0.32902657551896286
          },
          {
            "accuracy": 0.3024,
            "f1": 0.30106562710821716,
            "f1_weighted": 0.30106562710821716
          },
          {
            "accuracy": 0.3426,
            "f1": 0.3394029301854298,
            "f1_weighted": 0.3394029301854298
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}