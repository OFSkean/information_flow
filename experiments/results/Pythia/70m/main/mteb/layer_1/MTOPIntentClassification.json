{
  "dataset_revision": "ae001d0e6b1228650b7bd1c2c65fb50ad11a8aba",
  "evaluation_time": 83.53138852119446,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.6183994528043776,
        "f1": 0.39544912354553663,
        "f1_weighted": 0.6625827215017333,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6183994528043776,
        "scores_per_experiment": [
          {
            "accuracy": 0.606703146374829,
            "f1": 0.382194545021155,
            "f1_weighted": 0.6488986462793724
          },
          {
            "accuracy": 0.5957592339261286,
            "f1": 0.37012018724473156,
            "f1_weighted": 0.6416929025453799
          },
          {
            "accuracy": 0.6073871409028728,
            "f1": 0.3819060327174061,
            "f1_weighted": 0.650147473309728
          },
          {
            "accuracy": 0.6424988600091199,
            "f1": 0.42979953665234594,
            "f1_weighted": 0.6826018181261091
          },
          {
            "accuracy": 0.6165070679434564,
            "f1": 0.4049623022394175,
            "f1_weighted": 0.665163084273835
          },
          {
            "accuracy": 0.6242590059279526,
            "f1": 0.3937848825898613,
            "f1_weighted": 0.6697050625970475
          },
          {
            "accuracy": 0.6046511627906976,
            "f1": 0.38958384283478703,
            "f1_weighted": 0.6484952946825759
          },
          {
            "accuracy": 0.652530779753762,
            "f1": 0.4313328102193592,
            "f1_weighted": 0.6932567239352041
          },
          {
            "accuracy": 0.6158230734154126,
            "f1": 0.3948150647906122,
            "f1_weighted": 0.6621551401575044
          },
          {
            "accuracy": 0.617875056999544,
            "f1": 0.3759920311456908,
            "f1_weighted": 0.6637110691105772
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.6198657718120806,
        "f1": 0.39340650401343774,
        "f1_weighted": 0.6658584410881819,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6198657718120806,
        "scores_per_experiment": [
          {
            "accuracy": 0.5991051454138703,
            "f1": 0.38824807917896204,
            "f1_weighted": 0.6390474019193284
          },
          {
            "accuracy": 0.5982102908277405,
            "f1": 0.3856675125758448,
            "f1_weighted": 0.644881217854833
          },
          {
            "accuracy": 0.6223713646532438,
            "f1": 0.39828870833357316,
            "f1_weighted": 0.6658452714547137
          },
          {
            "accuracy": 0.6353467561521253,
            "f1": 0.38841073057867537,
            "f1_weighted": 0.6800049287048555
          },
          {
            "accuracy": 0.636241610738255,
            "f1": 0.4039678570130129,
            "f1_weighted": 0.6861696004796491
          },
          {
            "accuracy": 0.6201342281879194,
            "f1": 0.40806790003736365,
            "f1_weighted": 0.6658493714721558
          },
          {
            "accuracy": 0.6053691275167785,
            "f1": 0.38274584936981626,
            "f1_weighted": 0.65252321766919
          },
          {
            "accuracy": 0.6536912751677852,
            "f1": 0.423912387715753,
            "f1_weighted": 0.6989047537084346
          },
          {
            "accuracy": 0.6008948545861298,
            "f1": 0.3626466750244734,
            "f1_weighted": 0.6496808707064607
          },
          {
            "accuracy": 0.6272930648769575,
            "f1": 0.3921093403069026,
            "f1_weighted": 0.675677776912199
          }
        ]
      }
    ]
  },
  "task_name": "MTOPIntentClassification"
}