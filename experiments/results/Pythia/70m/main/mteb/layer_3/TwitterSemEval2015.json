{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "evaluation_time": 7.997602939605713,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "cosine_accuracy": 0.7863145973654407,
        "cosine_accuracy_threshold": 0.9479129314422607,
        "cosine_ap": 0.44582601396844795,
        "cosine_f1": 0.46629548618015515,
        "cosine_f1_threshold": 0.9085928201675415,
        "cosine_precision": 0.374122527121889,
        "cosine_recall": 0.6187335092348285,
        "dot_accuracy": 0.777373785539727,
        "dot_accuracy_threshold": 62195.58984375,
        "dot_ap": 0.31505092943142804,
        "dot_f1": 0.36990453098954384,
        "dot_f1_threshold": 55352.54296875,
        "dot_precision": 0.25946003401360546,
        "dot_recall": 0.6440633245382585,
        "euclidean_accuracy": 0.7870298623114979,
        "euclidean_accuracy_threshold": 79.90933227539062,
        "euclidean_ap": 0.4506296414714056,
        "euclidean_f1": 0.47135636057287283,
        "euclidean_f1_threshold": 105.15934753417969,
        "euclidean_precision": 0.3922187171398528,
        "euclidean_recall": 0.5905013192612137,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.4520654549550031,
        "manhattan_accuracy": 0.7870894677236693,
        "manhattan_accuracy_threshold": 1436.8233642578125,
        "manhattan_ap": 0.4520654549550031,
        "manhattan_f1": 0.47377509173321825,
        "manhattan_f1_threshold": 1792.1165771484375,
        "manhattan_precision": 0.4008400292184076,
        "manhattan_recall": 0.579155672823219,
        "max_accuracy": 0.7870894677236693,
        "max_ap": 0.4520654549550031,
        "max_f1": 0.47377509173321825,
        "max_precision": 0.4008400292184076,
        "max_recall": 0.6440633245382585,
        "similarity_accuracy": 0.7863145973654407,
        "similarity_accuracy_threshold": 0.9479129314422607,
        "similarity_ap": 0.44582601396844795,
        "similarity_f1": 0.46629548618015515,
        "similarity_f1_threshold": 0.9085928201675415,
        "similarity_precision": 0.374122527121889,
        "similarity_recall": 0.6187335092348285
      }
    ]
  },
  "task_name": "TwitterSemEval2015"
}