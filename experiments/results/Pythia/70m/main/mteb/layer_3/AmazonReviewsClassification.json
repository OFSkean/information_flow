{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 66.55880999565125,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.3136,
        "f1": 0.31323825139112227,
        "f1_weighted": 0.3132382513911223,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.3136,
        "scores_per_experiment": [
          {
            "accuracy": 0.3308,
            "f1": 0.3292614576325284,
            "f1_weighted": 0.3292614576325284
          },
          {
            "accuracy": 0.3246,
            "f1": 0.3282338286368313,
            "f1_weighted": 0.32823382863683137
          },
          {
            "accuracy": 0.2962,
            "f1": 0.2975508986424738,
            "f1_weighted": 0.29755089864247386
          },
          {
            "accuracy": 0.3254,
            "f1": 0.3248393177325458,
            "f1_weighted": 0.3248393177325459
          },
          {
            "accuracy": 0.365,
            "f1": 0.35861849126382656,
            "f1_weighted": 0.35861849126382656
          },
          {
            "accuracy": 0.2808,
            "f1": 0.28104768123248075,
            "f1_weighted": 0.28104768123248075
          },
          {
            "accuracy": 0.2808,
            "f1": 0.2830973684752897,
            "f1_weighted": 0.28309736847528977
          },
          {
            "accuracy": 0.3286,
            "f1": 0.3249973501885817,
            "f1_weighted": 0.3249973501885818
          },
          {
            "accuracy": 0.301,
            "f1": 0.29958810181174034,
            "f1_weighted": 0.2995881018117403
          },
          {
            "accuracy": 0.3028,
            "f1": 0.3051480182949242,
            "f1_weighted": 0.3051480182949243
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.30894,
        "f1": 0.3086030214776017,
        "f1_weighted": 0.3086030214776017,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.30894,
        "scores_per_experiment": [
          {
            "accuracy": 0.3154,
            "f1": 0.3140243028695119,
            "f1_weighted": 0.31402430286951183
          },
          {
            "accuracy": 0.3154,
            "f1": 0.32044624514341147,
            "f1_weighted": 0.3204462451434115
          },
          {
            "accuracy": 0.289,
            "f1": 0.29017398143415296,
            "f1_weighted": 0.29017398143415296
          },
          {
            "accuracy": 0.3066,
            "f1": 0.30614325915565116,
            "f1_weighted": 0.30614325915565116
          },
          {
            "accuracy": 0.3518,
            "f1": 0.3427611867111834,
            "f1_weighted": 0.3427611867111835
          },
          {
            "accuracy": 0.2784,
            "f1": 0.27795337557472755,
            "f1_weighted": 0.27795337557472755
          },
          {
            "accuracy": 0.294,
            "f1": 0.2954015848772922,
            "f1_weighted": 0.2954015848772922
          },
          {
            "accuracy": 0.3264,
            "f1": 0.3233040992957856,
            "f1_weighted": 0.3233040992957856
          },
          {
            "accuracy": 0.306,
            "f1": 0.3061581591645196,
            "f1_weighted": 0.30615815916451966
          },
          {
            "accuracy": 0.3064,
            "f1": 0.30966402054978115,
            "f1_weighted": 0.3096640205497811
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}