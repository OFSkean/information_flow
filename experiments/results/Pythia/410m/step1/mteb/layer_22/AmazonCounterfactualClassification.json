{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 35.26198148727417,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.6338830584707648,
        "ap": 0.14656684402198658,
        "ap_weighted": 0.14656684402198658,
        "f1": 0.511324160531054,
        "f1_weighted": 0.7037543724301044,
        "hf_subset": "en-ext",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6338830584707648,
        "scores_per_experiment": [
          {
            "accuracy": 0.6904047976011994,
            "ap": 0.16663012208397884,
            "ap_weighted": 0.16663012208397884,
            "f1": 0.5533270906046934,
            "f1_weighted": 0.7492053836876572
          },
          {
            "accuracy": 0.5997001499250375,
            "ap": 0.14040006313613612,
            "ap_weighted": 0.14040006313613612,
            "f1": 0.4912106278122992,
            "f1_weighted": 0.6771926657198507
          },
          {
            "accuracy": 0.7226386806596702,
            "ap": 0.16198534249591243,
            "ap_weighted": 0.16198534249591243,
            "f1": 0.5644139294350212,
            "f1_weighted": 0.7722315131330676
          },
          {
            "accuracy": 0.5944527736131934,
            "ap": 0.14874110663304072,
            "ap_weighted": 0.14874110663304072,
            "f1": 0.4945791287527829,
            "f1_weighted": 0.6724316902579995
          },
          {
            "accuracy": 0.5862068965517241,
            "ap": 0.12556771973725367,
            "ap_weighted": 0.12556771973725367,
            "f1": 0.4721966575780773,
            "f1_weighted": 0.6663818387977081
          },
          {
            "accuracy": 0.5839580209895052,
            "ap": 0.15601317363356387,
            "ap_weighted": 0.15601317363356387,
            "f1": 0.49379421531847334,
            "f1_weighted": 0.662911406772487
          },
          {
            "accuracy": 0.6086956521739131,
            "ap": 0.13560154591185838,
            "ap_weighted": 0.13560154591185838,
            "f1": 0.4917004633725463,
            "f1_weighted": 0.6847425248948015
          },
          {
            "accuracy": 0.636431784107946,
            "ap": 0.14623242637564188,
            "ap_weighted": 0.14623242637564188,
            "f1": 0.5132906797862057,
            "f1_weighted": 0.7070865160958298
          },
          {
            "accuracy": 0.6146926536731634,
            "ap": 0.14172871759725814,
            "ap_weighted": 0.14172871759725814,
            "f1": 0.49949049458522754,
            "f1_weighted": 0.6895740570803217
          },
          {
            "accuracy": 0.7016491754122939,
            "ap": 0.14276822261522185,
            "ap_weighted": 0.14276822261522185,
            "f1": 0.5392383180652127,
            "f1_weighted": 0.755786127861321
          }
        ]
      },
      {
        "accuracy": 0.6340298507462686,
        "ap": 0.27245294024550787,
        "ap_weighted": 0.27245294024550787,
        "f1": 0.5768469564158896,
        "f1_weighted": 0.6706162038935937,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6340298507462686,
        "scores_per_experiment": [
          {
            "accuracy": 0.6746268656716418,
            "ap": 0.2870456875925715,
            "ap_weighted": 0.2870456875925715,
            "f1": 0.6069598725566175,
            "f1_weighted": 0.7062697041786674
          },
          {
            "accuracy": 0.664179104477612,
            "ap": 0.2684617724026379,
            "ap_weighted": 0.2684617724026379,
            "f1": 0.5899911606717889,
            "f1_weighted": 0.6961970591727566
          },
          {
            "accuracy": 0.6447761194029851,
            "ap": 0.2660132370762427,
            "ap_weighted": 0.2660132370762427,
            "f1": 0.5794875581481209,
            "f1_weighted": 0.6803880619056384
          },
          {
            "accuracy": 0.5492537313432836,
            "ap": 0.225029176379296,
            "ap_weighted": 0.225029176379296,
            "f1": 0.5021945362934971,
            "f1_weighted": 0.5953991556154042
          },
          {
            "accuracy": 0.6895522388059702,
            "ap": 0.2880524340881588,
            "ap_weighted": 0.2880524340881588,
            "f1": 0.6142646782032972,
            "f1_weighted": 0.7180394238988735
          },
          {
            "accuracy": 0.5686567164179105,
            "ap": 0.2411686368632224,
            "ap_weighted": 0.2411686368632224,
            "f1": 0.5241044546850998,
            "f1_weighted": 0.6127743219386936
          },
          {
            "accuracy": 0.6179104477611941,
            "ap": 0.2936289974837022,
            "ap_weighted": 0.2936289974837022,
            "f1": 0.580533137686476,
            "f1_weighted": 0.656782850238901
          },
          {
            "accuracy": 0.6119402985074627,
            "ap": 0.2731129172044441,
            "ap_weighted": 0.2731129172044441,
            "f1": 0.5669295253627151,
            "f1_weighted": 0.6519498746361271
          },
          {
            "accuracy": 0.6701492537313433,
            "ap": 0.29210495010354603,
            "ap_weighted": 0.29210495010354603,
            "f1": 0.6078768891796054,
            "f1_weighted": 0.7030346597305756
          },
          {
            "accuracy": 0.6492537313432836,
            "ap": 0.28991159326125715,
            "ap_weighted": 0.28991159326125715,
            "f1": 0.5961277513716778,
            "f1_weighted": 0.6853269276202996
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}