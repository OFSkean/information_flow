{
  "dataset_revision": "edfaf9da55d3dd50d43143d90c1ac476895ae6de",
  "evaluation_time": 20.630815505981445,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.557958984375,
        "ap": 0.08112562253081074,
        "ap_weighted": 0.08112562253081074,
        "f1": 0.4158529941873857,
        "f1_weighted": 0.6483370972319746,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.557958984375,
        "scores_per_experiment": [
          {
            "accuracy": 0.39892578125,
            "ap": 0.07851231069948697,
            "ap_weighted": 0.07851231069948697,
            "f1": 0.33849556419163485,
            "f1_weighted": 0.5068020168711526
          },
          {
            "accuracy": 0.662109375,
            "ap": 0.08749265693185632,
            "ap_weighted": 0.08749265693185632,
            "f1": 0.47435136610724715,
            "f1_weighted": 0.7388079080444252
          },
          {
            "accuracy": 0.69677734375,
            "ap": 0.08081021439943184,
            "ap_weighted": 0.08081021439943184,
            "f1": 0.4738975310403882,
            "f1_weighted": 0.7621531927893536
          },
          {
            "accuracy": 0.58984375,
            "ap": 0.07594259058524473,
            "ap_weighted": 0.07594259058524473,
            "f1": 0.4243918760665173,
            "f1_weighted": 0.6841724140094356
          },
          {
            "accuracy": 0.52490234375,
            "ap": 0.08405482189438804,
            "ap_weighted": 0.08405482189438804,
            "f1": 0.41087886692192144,
            "f1_weighted": 0.6290547537716523
          },
          {
            "accuracy": 0.3212890625,
            "ap": 0.08062336540546629,
            "ap_weighted": 0.08062336540546629,
            "f1": 0.29149128500830285,
            "f1_weighted": 0.4138040669027931
          },
          {
            "accuracy": 0.6572265625,
            "ap": 0.08144803441926077,
            "ap_weighted": 0.08144803441926077,
            "f1": 0.4618490852494509,
            "f1_weighted": 0.7348075704844158
          },
          {
            "accuracy": 0.50830078125,
            "ap": 0.08108253725869255,
            "ap_weighted": 0.08108253725869255,
            "f1": 0.3991168865223947,
            "f1_weighted": 0.6147331918034847
          },
          {
            "accuracy": 0.63916015625,
            "ap": 0.08425189074587022,
            "ap_weighted": 0.08425189074587022,
            "f1": 0.460295985077006,
            "f1_weighted": 0.7218412192604171
          },
          {
            "accuracy": 0.5810546875,
            "ap": 0.07703780296840959,
            "ap_weighted": 0.07703780296840959,
            "f1": 0.42376149568899363,
            "f1_weighted": 0.6771946383826152
          }
        ]
      }
    ]
  },
  "task_name": "ToxicConversationsClassification"
}