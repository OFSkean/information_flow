{
  "dataset_revision": "edfaf9da55d3dd50d43143d90c1ac476895ae6de",
  "evaluation_time": 33.300522327423096,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.5333984375,
        "ap": 0.0806858308641354,
        "ap_weighted": 0.0806858308641354,
        "f1": 0.406789936977449,
        "f1_weighted": 0.631552498225629,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5333984375,
        "scores_per_experiment": [
          {
            "accuracy": 0.40283203125,
            "ap": 0.075446338638195,
            "ap_weighted": 0.075446338638195,
            "f1": 0.3370780717887694,
            "f1_weighted": 0.5128297401781671
          },
          {
            "accuracy": 0.609375,
            "ap": 0.08432754753284268,
            "ap_weighted": 0.08432754753284268,
            "f1": 0.4485484680929551,
            "f1_weighted": 0.699240096490555
          },
          {
            "accuracy": 0.63037109375,
            "ap": 0.08088471858003107,
            "ap_weighted": 0.08088471858003107,
            "f1": 0.45083195096956746,
            "f1_weighted": 0.715157725652288
          },
          {
            "accuracy": 0.48779296875,
            "ap": 0.07937082428251711,
            "ap_weighted": 0.07937082428251711,
            "f1": 0.3868408727466598,
            "f1_weighted": 0.5962769900869228
          },
          {
            "accuracy": 0.48291015625,
            "ap": 0.08158150533890438,
            "ap_weighted": 0.08158150533890438,
            "f1": 0.3873049584682624,
            "f1_weighted": 0.5910421166582693
          },
          {
            "accuracy": 0.3955078125,
            "ap": 0.0811931480522966,
            "ap_weighted": 0.0811931480522966,
            "f1": 0.3391654286235567,
            "f1_weighted": 0.5015973179262126
          },
          {
            "accuracy": 0.64453125,
            "ap": 0.07749654578964005,
            "ap_weighted": 0.07749654578964005,
            "f1": 0.44800704918882495,
            "f1_weighted": 0.7252637776654745
          },
          {
            "accuracy": 0.5087890625,
            "ap": 0.08204473030280937,
            "ap_weighted": 0.08204473030280937,
            "f1": 0.40062675204892995,
            "f1_weighted": 0.6149621810347285
          },
          {
            "accuracy": 0.62890625,
            "ap": 0.08169293810488698,
            "ap_weighted": 0.08169293810488698,
            "f1": 0.4518293954232714,
            "f1_weighted": 0.7140978638857115
          },
          {
            "accuracy": 0.54296875,
            "ap": 0.08282001201923077,
            "ap_weighted": 0.08282001201923077,
            "f1": 0.41766642242369234,
            "f1_weighted": 0.6450571726779603
          }
        ]
      }
    ]
  },
  "task_name": "ToxicConversationsClassification"
}