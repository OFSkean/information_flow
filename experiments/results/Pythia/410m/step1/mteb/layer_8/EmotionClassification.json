{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "evaluation_time": 12.863278150558472,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.18430000000000002,
        "f1": 0.166632239147189,
        "f1_weighted": 0.20081786735478127,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.18430000000000002,
        "scores_per_experiment": [
          {
            "accuracy": 0.168,
            "f1": 0.15248323126842575,
            "f1_weighted": 0.18732033138199827
          },
          {
            "accuracy": 0.2025,
            "f1": 0.18065410919308303,
            "f1_weighted": 0.22055548599775135
          },
          {
            "accuracy": 0.1655,
            "f1": 0.152892573537253,
            "f1_weighted": 0.17608345133852973
          },
          {
            "accuracy": 0.1565,
            "f1": 0.14632213260818233,
            "f1_weighted": 0.1712299573638176
          },
          {
            "accuracy": 0.1755,
            "f1": 0.16227787358689325,
            "f1_weighted": 0.191789058890067
          },
          {
            "accuracy": 0.202,
            "f1": 0.1845764043654702,
            "f1_weighted": 0.2158856552097229
          },
          {
            "accuracy": 0.1965,
            "f1": 0.16725978503447833,
            "f1_weighted": 0.21972686552798654
          },
          {
            "accuracy": 0.1915,
            "f1": 0.17388765214429625,
            "f1_weighted": 0.20872319906187348
          },
          {
            "accuracy": 0.205,
            "f1": 0.18449543312921524,
            "f1_weighted": 0.21963890500186412
          },
          {
            "accuracy": 0.18,
            "f1": 0.16147319660459236,
            "f1_weighted": 0.19722576377420176
          }
        ]
      }
    ]
  },
  "task_name": "EmotionClassification"
}