{
  "dataset_revision": "faeb762787bd10488a50c8b5be4a3b82e411949c",
  "evaluation_time": 18.783499240875244,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.4784186281691322,
        "cosine_spearman": 0.48807060727785756,
        "euclidean_pearson": 0.45104327499910646,
        "euclidean_spearman": 0.45328118181946386,
        "hf_subset": "en-en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.48807060727785756,
        "manhattan_pearson": 0.44911999932896884,
        "manhattan_spearman": 0.45325773362984834,
        "pearson": 0.4784186281691322,
        "spearman": 0.48807060727785756
      },
      {
        "cosine_pearson": 0.13261912059309186,
        "cosine_spearman": 0.1302931663412319,
        "euclidean_pearson": 0.004178061704110461,
        "euclidean_spearman": -0.016311583672437874,
        "hf_subset": "en-ar",
        "languages": [
          "eng-Latn",
          "ara-Arab"
        ],
        "main_score": 0.1302931663412319,
        "manhattan_pearson": 0.00223903967059363,
        "manhattan_spearman": -0.021126564515180878,
        "pearson": 0.13261912059309186,
        "spearman": 0.1302931663412319
      },
      {
        "cosine_pearson": 0.08114047767462317,
        "cosine_spearman": 0.09874878319503148,
        "euclidean_pearson": 0.002647025477958477,
        "euclidean_spearman": 0.01514599290541444,
        "hf_subset": "en-de",
        "languages": [
          "eng-Latn",
          "deu-Latn"
        ],
        "main_score": 0.09874878319503148,
        "manhattan_pearson": 0.004934761379083886,
        "manhattan_spearman": 0.013486552994428342,
        "pearson": 0.08114047767462317,
        "spearman": 0.09874878319503148
      },
      {
        "cosine_pearson": -0.09114566605010077,
        "cosine_spearman": -0.06793445669677961,
        "euclidean_pearson": -0.1847469869509443,
        "euclidean_spearman": -0.1569586759668215,
        "hf_subset": "en-tr",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ],
        "main_score": -0.06793445669677961,
        "manhattan_pearson": -0.1893933694550668,
        "manhattan_spearman": -0.15628623649585063,
        "pearson": -0.09114566605010077,
        "spearman": -0.06793445669677961
      },
      {
        "cosine_pearson": 0.04506196874104998,
        "cosine_spearman": 0.0642661061843948,
        "euclidean_pearson": -0.023814163801554468,
        "euclidean_spearman": -0.003906622148564208,
        "hf_subset": "fr-en",
        "languages": [
          "fra-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0642661061843948,
        "manhattan_pearson": -0.03149551695955109,
        "manhattan_spearman": -0.010586281016575647,
        "pearson": 0.04506196874104998,
        "spearman": 0.0642661061843948
      },
      {
        "cosine_pearson": 0.048218944912345255,
        "cosine_spearman": 0.042847594040565214,
        "euclidean_pearson": -0.0277805251225025,
        "euclidean_spearman": -0.06672271922686399,
        "hf_subset": "es-en",
        "languages": [
          "spa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.042847594040565214,
        "manhattan_pearson": -0.035126561640882174,
        "manhattan_spearman": -0.07013301204592295,
        "pearson": 0.048218944912345255,
        "spearman": 0.042847594040565214
      },
      {
        "cosine_pearson": 0.04037884326793574,
        "cosine_spearman": 0.03211440985947031,
        "euclidean_pearson": -0.043168636784444284,
        "euclidean_spearman": -0.023300196943345418,
        "hf_subset": "nl-en",
        "languages": [
          "nld-Latn",
          "eng-Latn"
        ],
        "main_score": 0.03211440985947031,
        "manhattan_pearson": -0.046651263846002156,
        "manhattan_spearman": -0.027767269263375395,
        "pearson": 0.04037884326793574,
        "spearman": 0.03211440985947031
      },
      {
        "cosine_pearson": 0.0238194753284213,
        "cosine_spearman": 0.05472115542467839,
        "euclidean_pearson": -0.04610833256607487,
        "euclidean_spearman": 0.009070221019140122,
        "hf_subset": "it-en",
        "languages": [
          "ita-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05472115542467839,
        "manhattan_pearson": -0.05719758450562042,
        "manhattan_spearman": -0.004023863096641753,
        "pearson": 0.0238194753284213,
        "spearman": 0.05472115542467839
      }
    ]
  },
  "task_name": "STS17"
}