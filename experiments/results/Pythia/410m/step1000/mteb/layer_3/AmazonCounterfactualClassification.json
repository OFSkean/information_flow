{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 26.728729009628296,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.684407796101949,
        "ap": 0.17167114751002513,
        "ap_weighted": 0.17167114751002513,
        "f1": 0.5533255454726825,
        "f1_weighted": 0.7441975177590745,
        "hf_subset": "en-ext",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.684407796101949,
        "scores_per_experiment": [
          {
            "accuracy": 0.6814092953523239,
            "ap": 0.18211606163929792,
            "ap_weighted": 0.18211606163929792,
            "f1": 0.558912885003038,
            "f1_weighted": 0.7429188726685371
          },
          {
            "accuracy": 0.6664167916041979,
            "ap": 0.16241399441251617,
            "ap_weighted": 0.16241399441251617,
            "f1": 0.5391626007739752,
            "f1_weighted": 0.7308607826808442
          },
          {
            "accuracy": 0.7653673163418291,
            "ap": 0.18395873363421064,
            "ap_weighted": 0.18395873363421064,
            "f1": 0.5991628866969064,
            "f1_weighted": 0.8034840481695937
          },
          {
            "accuracy": 0.6581709145427287,
            "ap": 0.1610467381353383,
            "ap_weighted": 0.1610467381353383,
            "f1": 0.5342991796124978,
            "f1_weighted": 0.724427889040294
          },
          {
            "accuracy": 0.6401799100449775,
            "ap": 0.14858073455711973,
            "ap_weighted": 0.14858073455711973,
            "f1": 0.5168417240130387,
            "f1_weighted": 0.7100837484191624
          },
          {
            "accuracy": 0.6551724137931034,
            "ap": 0.18106912694665067,
            "ap_weighted": 0.18106912694665067,
            "f1": 0.5451890722046813,
            "f1_weighted": 0.7222354269567755
          },
          {
            "accuracy": 0.6476761619190404,
            "ap": 0.14943727412629002,
            "ap_weighted": 0.14943727412629002,
            "f1": 0.5210090453489793,
            "f1_weighted": 0.7159951606521638
          },
          {
            "accuracy": 0.7038980509745127,
            "ap": 0.180229772061554,
            "ap_weighted": 0.180229772061554,
            "f1": 0.5686371461761193,
            "f1_weighted": 0.759849348943326
          },
          {
            "accuracy": 0.6746626686656672,
            "ap": 0.1730089250761839,
            "ap_weighted": 0.1730089250761839,
            "f1": 0.5500640372037503,
            "f1_weighted": 0.737494457180651
          },
          {
            "accuracy": 0.7511244377811095,
            "ap": 0.1948501145110898,
            "ap_weighted": 0.1948501145110898,
            "f1": 0.599976877693839,
            "f1_weighted": 0.7946254428793971
          }
        ]
      },
      {
        "accuracy": 0.6871641791044777,
        "ap": 0.3146968266707876,
        "ap_weighted": 0.3146968266707876,
        "f1": 0.6276931259402759,
        "f1_weighted": 0.7179717644688227,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6871641791044777,
        "scores_per_experiment": [
          {
            "accuracy": 0.6313432835820896,
            "ap": 0.27008612805582155,
            "ap_weighted": 0.27008612805582155,
            "f1": 0.5755044876119337,
            "f1_weighted": 0.6692585154136768
          },
          {
            "accuracy": 0.7074626865671642,
            "ap": 0.34484344412565904,
            "ap_weighted": 0.34484344412565904,
            "f1": 0.6536956361219819,
            "f1_weighted": 0.7367901686281727
          },
          {
            "accuracy": 0.7074626865671642,
            "ap": 0.33432857317904213,
            "ap_weighted": 0.33432857317904213,
            "f1": 0.6487116932032186,
            "f1_weighted": 0.7361949241977069
          },
          {
            "accuracy": 0.6298507462686567,
            "ap": 0.2746137801657572,
            "ap_weighted": 0.2746137801657572,
            "f1": 0.5774203721223589,
            "f1_weighted": 0.6680627138668058
          },
          {
            "accuracy": 0.7179104477611941,
            "ap": 0.33576383802543086,
            "ap_weighted": 0.33576383802543086,
            "f1": 0.6545176260670994,
            "f1_weighted": 0.7446370380921539
          },
          {
            "accuracy": 0.7029850746268657,
            "ap": 0.31051685674067486,
            "ap_weighted": 0.31051685674067486,
            "f1": 0.633929037200146,
            "f1_weighted": 0.7307498731798766
          },
          {
            "accuracy": 0.6686567164179105,
            "ap": 0.2855817404955666,
            "ap_weighted": 0.2855817404955666,
            "f1": 0.6032711327337323,
            "f1_weighted": 0.7013495082599994
          },
          {
            "accuracy": 0.7432835820895523,
            "ap": 0.34756620100894453,
            "ap_weighted": 0.34756620100894453,
            "f1": 0.6722001615674316,
            "f1_weighted": 0.7651554037886662
          },
          {
            "accuracy": 0.7074626865671642,
            "ap": 0.34484344412565904,
            "ap_weighted": 0.34484344412565904,
            "f1": 0.6536956361219819,
            "f1_weighted": 0.7367901686281727
          },
          {
            "accuracy": 0.655223880597015,
            "ap": 0.2988242607853198,
            "ap_weighted": 0.2988242607853198,
            "f1": 0.6039854766528752,
            "f1_weighted": 0.6907293306329957
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}