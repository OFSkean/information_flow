{
  "dataset_revision": "edfaf9da55d3dd50d43143d90c1ac476895ae6de",
  "evaluation_time": 20.83482265472412,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.56337890625,
        "ap": 0.08623792191211521,
        "ap_weighted": 0.08623792191211521,
        "f1": 0.42727415416376296,
        "f1_weighted": 0.6545928021827507,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.56337890625,
        "scores_per_experiment": [
          {
            "accuracy": 0.41064453125,
            "ap": 0.08493040654049373,
            "ap_weighted": 0.08493040654049373,
            "f1": 0.3513924825177119,
            "f1_weighted": 0.5164175746250862
          },
          {
            "accuracy": 0.5986328125,
            "ap": 0.08590144980006689,
            "ap_weighted": 0.08590144980006689,
            "f1": 0.44638236690796057,
            "f1_weighted": 0.6907769369272119
          },
          {
            "accuracy": 0.7138671875,
            "ap": 0.08656896146616541,
            "ap_weighted": 0.08656896146616541,
            "f1": 0.49168398992286283,
            "f1_weighted": 0.7745819460698234
          },
          {
            "accuracy": 0.62158203125,
            "ap": 0.08738723769487841,
            "ap_weighted": 0.08738723769487841,
            "f1": 0.45804917507176446,
            "f1_weighted": 0.7086541920062339
          },
          {
            "accuracy": 0.46630859375,
            "ap": 0.08913963736922406,
            "ap_weighted": 0.08913963736922406,
            "f1": 0.38641674499332956,
            "f1_weighted": 0.5727950227423144
          },
          {
            "accuracy": 0.37353515625,
            "ap": 0.07937527640011854,
            "ap_weighted": 0.07937527640011854,
            "f1": 0.32426710076777776,
            "f1_weighted": 0.4778622683109083
          },
          {
            "accuracy": 0.61279296875,
            "ap": 0.08998365521745408,
            "ap_weighted": 0.08998365521745408,
            "f1": 0.4577920788013404,
            "f1_weighted": 0.701830009642883
          },
          {
            "accuracy": 0.58251953125,
            "ap": 0.08123269562454613,
            "ap_weighted": 0.08123269562454613,
            "f1": 0.4324930035537248,
            "f1_weighted": 0.6781204809975789
          },
          {
            "accuracy": 0.5986328125,
            "ap": 0.08534740976508914,
            "ap_weighted": 0.08534740976508914,
            "f1": 0.4455983939552015,
            "f1_weighted": 0.690794804337388
          },
          {
            "accuracy": 0.6552734375,
            "ap": 0.09251248924311559,
            "ap_weighted": 0.09251248924311559,
            "f1": 0.4786662051459559,
            "f1_weighted": 0.7340947861680801
          }
        ]
      }
    ]
  },
  "task_name": "ToxicConversationsClassification"
}