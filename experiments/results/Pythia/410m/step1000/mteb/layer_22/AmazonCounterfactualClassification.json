{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 34.60733723640442,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.676311844077961,
        "ap": 0.1736348402982573,
        "ap_weighted": 0.1736348402982573,
        "f1": 0.5503421472210781,
        "f1_weighted": 0.7379257117443732,
        "hf_subset": "en-ext",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.676311844077961,
        "scores_per_experiment": [
          {
            "accuracy": 0.7368815592203898,
            "ap": 0.20196254741553596,
            "ap_weighted": 0.20196254741553596,
            "f1": 0.5975057829628885,
            "f1_weighted": 0.7849972730621515
          },
          {
            "accuracy": 0.5832083958020989,
            "ap": 0.14704551351664624,
            "ap_weighted": 0.14704551351664624,
            "f1": 0.48769564436585666,
            "f1_weighted": 0.6628023553323007
          },
          {
            "accuracy": 0.7376311844077961,
            "ap": 0.19862165906122348,
            "ap_weighted": 0.19862165906122348,
            "f1": 0.5959171097817658,
            "f1_weighted": 0.7853475690287127
          },
          {
            "accuracy": 0.6776611694152923,
            "ap": 0.1695054322787219,
            "ap_weighted": 0.1695054322787219,
            "f1": 0.549257747058805,
            "f1_weighted": 0.7396987779695502
          },
          {
            "accuracy": 0.6521739130434783,
            "ap": 0.14419609915736165,
            "ap_weighted": 0.14419609915736165,
            "f1": 0.5189624729551615,
            "f1_weighted": 0.7193489127461338
          },
          {
            "accuracy": 0.6544227886056971,
            "ap": 0.17457850968495306,
            "ap_weighted": 0.17457850968495306,
            "f1": 0.5410597266988411,
            "f1_weighted": 0.7216198976998064
          },
          {
            "accuracy": 0.6416791604197901,
            "ap": 0.14512717136320138,
            "ap_weighted": 0.14512717136320138,
            "f1": 0.5148839955204986,
            "f1_weighted": 0.7112119927839177
          },
          {
            "accuracy": 0.7406296851574213,
            "ap": 0.20985029461848398,
            "ap_weighted": 0.20985029461848398,
            "f1": 0.6037737144819298,
            "f1_weighted": 0.7881103280448368
          },
          {
            "accuracy": 0.6446776611694153,
            "ap": 0.1710222045600525,
            "ap_weighted": 0.1710222045600525,
            "f1": 0.5340531267685342,
            "f1_weighted": 0.7137754472721194
          },
          {
            "accuracy": 0.6941529235382309,
            "ap": 0.17443897132639305,
            "ap_weighted": 0.17443897132639305,
            "f1": 0.5603121516164995,
            "f1_weighted": 0.7523445635042011
          }
        ]
      },
      {
        "accuracy": 0.657910447761194,
        "ap": 0.2937636705120063,
        "ap_weighted": 0.2937636705120063,
        "f1": 0.6019200841365875,
        "f1_weighted": 0.6924764509171734,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.657910447761194,
        "scores_per_experiment": [
          {
            "accuracy": 0.6283582089552239,
            "ap": 0.2669624078904015,
            "ap_weighted": 0.2669624078904015,
            "f1": 0.5720672769853098,
            "f1_weighted": 0.666580446712573
          },
          {
            "accuracy": 0.6611940298507463,
            "ap": 0.298416708246082,
            "ap_weighted": 0.298416708246082,
            "f1": 0.606899991987573,
            "f1_weighted": 0.6958637166790377
          },
          {
            "accuracy": 0.6104477611940299,
            "ap": 0.26564964817424136,
            "ap_weighted": 0.26564964817424136,
            "f1": 0.5619170731340704,
            "f1_weighted": 0.650708645907449
          },
          {
            "accuracy": 0.6507462686567164,
            "ap": 0.29820224702201337,
            "ap_weighted": 0.29820224702201337,
            "f1": 0.6012756736960967,
            "f1_weighted": 0.6868011090517444
          },
          {
            "accuracy": 0.7149253731343284,
            "ap": 0.348376438418594,
            "ap_weighted": 0.348376438418594,
            "f1": 0.659163850114127,
            "f1_weighted": 0.7431147777607771
          },
          {
            "accuracy": 0.7164179104477612,
            "ap": 0.30949807779662303,
            "ap_weighted": 0.30949807779662303,
            "f1": 0.639172335600907,
            "f1_weighted": 0.7408374792703151
          },
          {
            "accuracy": 0.6238805970149254,
            "ap": 0.2666161596470994,
            "ap_weighted": 0.2666161596470994,
            "f1": 0.5695668135095447,
            "f1_weighted": 0.6626761566616257
          },
          {
            "accuracy": 0.6656716417910448,
            "ap": 0.2990849289110894,
            "ap_weighted": 0.2990849289110894,
            "f1": 0.6095571095571095,
            "f1_weighted": 0.6996938384998086
          },
          {
            "accuracy": 0.6611940298507463,
            "ap": 0.2965136151304546,
            "ap_weighted": 0.2965136151304546,
            "f1": 0.6058813316437721,
            "f1_weighted": 0.6957920123945508
          },
          {
            "accuracy": 0.6462686567164179,
            "ap": 0.2883164738834645,
            "ap_weighted": 0.2883164738834645,
            "f1": 0.5936993851373654,
            "f1_weighted": 0.6826963262338527
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}