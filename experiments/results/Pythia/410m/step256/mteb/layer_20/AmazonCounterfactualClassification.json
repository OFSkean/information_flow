{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 33.484179973602295,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.6348575712143928,
        "ap": 0.15293868614988035,
        "ap_weighted": 0.15293868614988035,
        "f1": 0.516576498263092,
        "f1_weighted": 0.7046735637989536,
        "hf_subset": "en-ext",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6348575712143928,
        "scores_per_experiment": [
          {
            "accuracy": 0.6416791604197901,
            "ap": 0.1438566184815067,
            "ap_weighted": 0.1438566184815067,
            "f1": 0.5138735991461462,
            "f1_weighted": 0.7111874481300174
          },
          {
            "accuracy": 0.6199400299850075,
            "ap": 0.14306992121751444,
            "ap_weighted": 0.14306992121751444,
            "f1": 0.5030386929101575,
            "f1_weighted": 0.6938390205006392
          },
          {
            "accuracy": 0.6416791604197901,
            "ap": 0.1516608471559645,
            "ap_weighted": 0.1516608471559645,
            "f1": 0.5198302373845232,
            "f1_weighted": 0.7113071164399426
          },
          {
            "accuracy": 0.6124437781109445,
            "ap": 0.1563425251699597,
            "ap_weighted": 0.1563425251699597,
            "f1": 0.5087018187232109,
            "f1_weighted": 0.687415536689682
          },
          {
            "accuracy": 0.5832083958020989,
            "ap": 0.13655033111414464,
            "ap_weighted": 0.13655033111414464,
            "f1": 0.48013345295502974,
            "f1_weighted": 0.6633777957942639
          },
          {
            "accuracy": 0.6004497751124438,
            "ap": 0.17474635412680778,
            "ap_weighted": 0.17474635412680778,
            "f1": 0.513109014326204,
            "f1_weighted": 0.6763512150169458
          },
          {
            "accuracy": 0.6004497751124438,
            "ap": 0.1503506113377437,
            "ap_weighted": 0.1503506113377437,
            "f1": 0.49869954983061365,
            "f1_weighted": 0.6774819756169908
          },
          {
            "accuracy": 0.6934032983508246,
            "ap": 0.16468128506404558,
            "ap_weighted": 0.16468128506404558,
            "f1": 0.5533483361671716,
            "f1_weighted": 0.7513376802982795
          },
          {
            "accuracy": 0.616191904047976,
            "ap": 0.14579406735545497,
            "ap_weighted": 0.14579406735545497,
            "f1": 0.50328858377089,
            "f1_weighted": 0.6907507004573724
          },
          {
            "accuracy": 0.7391304347826086,
            "ap": 0.16233430047566144,
            "ap_weighted": 0.16233430047566144,
            "f1": 0.5717416974169742,
            "f1_weighted": 0.7836871490454036
          }
        ]
      },
      {
        "accuracy": 0.6404477611940299,
        "ap": 0.27357238705658127,
        "ap_weighted": 0.27357238705658127,
        "f1": 0.5810426993996235,
        "f1_weighted": 0.6765496605668047,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6404477611940299,
        "scores_per_experiment": [
          {
            "accuracy": 0.5985074626865672,
            "ap": 0.25244185548650966,
            "ap_weighted": 0.25244185548650966,
            "f1": 0.5474734793798255,
            "f1_weighted": 0.6400151024427171
          },
          {
            "accuracy": 0.6582089552238806,
            "ap": 0.2873248666526067,
            "ap_weighted": 0.2873248666526067,
            "f1": 0.5992435699528015,
            "f1_weighted": 0.6928539870368493
          },
          {
            "accuracy": 0.6791044776119403,
            "ap": 0.2744764914309281,
            "ap_weighted": 0.2744764914309281,
            "f1": 0.6006276840841607,
            "f1_weighted": 0.7084341883243428
          },
          {
            "accuracy": 0.5716417910447761,
            "ap": 0.23212362499758157,
            "ap_weighted": 0.23212362499758157,
            "f1": 0.5193458964802691,
            "f1_weighted": 0.6158921633685897
          },
          {
            "accuracy": 0.6507462686567164,
            "ap": 0.2671354202624043,
            "ap_weighted": 0.2671354202624043,
            "f1": 0.583031914893617,
            "f1_weighted": 0.685355827246745
          },
          {
            "accuracy": 0.6,
            "ap": 0.2627635165335974,
            "ap_weighted": 0.2627635165335974,
            "f1": 0.5545566404699531,
            "f1_weighted": 0.6411963165833134
          },
          {
            "accuracy": 0.6611940298507463,
            "ap": 0.30608561271719176,
            "ap_weighted": 0.30608561271719176,
            "f1": 0.6108428709965482,
            "f1_weighted": 0.6960846668990909
          },
          {
            "accuracy": 0.6283582089552239,
            "ap": 0.2551493789780996,
            "ap_weighted": 0.2551493789780996,
            "f1": 0.564243008376627,
            "f1_weighted": 0.6660290077387575
          },
          {
            "accuracy": 0.6582089552238806,
            "ap": 0.2967203353721823,
            "ap_weighted": 0.2967203353721823,
            "f1": 0.6044507348713942,
            "f1_weighted": 0.6932497385305618
          },
          {
            "accuracy": 0.6985074626865672,
            "ap": 0.301502768134712,
            "ap_weighted": 0.301502768134712,
            "f1": 0.6266111944910391,
            "f1_weighted": 0.726385607497078
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}