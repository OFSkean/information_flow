{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 30.28705930709839,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.6412293853073463,
        "ap": 0.15471100638506635,
        "ap_weighted": 0.15471100638506635,
        "f1": 0.5210424048806243,
        "f1_weighted": 0.7099064305493809,
        "hf_subset": "en-ext",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6412293853073463,
        "scores_per_experiment": [
          {
            "accuracy": 0.6379310344827587,
            "ap": 0.14284764092773755,
            "ap_weighted": 0.14284764092773755,
            "f1": 0.5113275161829786,
            "f1_weighted": 0.7082248877950076
          },
          {
            "accuracy": 0.6319340329835083,
            "ap": 0.15411285047277462,
            "ap_weighted": 0.15411285047277462,
            "f1": 0.5168787870964887,
            "f1_weighted": 0.7035121813464007
          },
          {
            "accuracy": 0.651424287856072,
            "ap": 0.14527495622112357,
            "ap_weighted": 0.14527495622112357,
            "f1": 0.5194952573869731,
            "f1_weighted": 0.7188043506278433
          },
          {
            "accuracy": 0.6214392803598201,
            "ap": 0.1576908437563567,
            "ap_weighted": 0.1576908437563567,
            "f1": 0.5140963065491367,
            "f1_weighted": 0.6948844729671297
          },
          {
            "accuracy": 0.5854572713643178,
            "ap": 0.14164338515976005,
            "ap_weighted": 0.14164338515976005,
            "f1": 0.4850733089726274,
            "f1_weighted": 0.6650486303404121
          },
          {
            "accuracy": 0.6071964017991005,
            "ap": 0.16983937001580102,
            "ap_weighted": 0.16983937001580102,
            "f1": 0.5140660410149461,
            "f1_weighted": 0.6824661454465676
          },
          {
            "accuracy": 0.6146926536731634,
            "ap": 0.14790042427057942,
            "ap_weighted": 0.14790042427057942,
            "f1": 0.5040877846695057,
            "f1_weighted": 0.6894826127137319
          },
          {
            "accuracy": 0.6821589205397302,
            "ap": 0.16967415572789146,
            "ap_weighted": 0.16967415572789146,
            "f1": 0.5515098845820818,
            "f1_weighted": 0.7431284706532992
          },
          {
            "accuracy": 0.6296851574212894,
            "ap": 0.1508019093517751,
            "ap_weighted": 0.1508019093517751,
            "f1": 0.5134593178643466,
            "f1_weighted": 0.7017023954289656
          },
          {
            "accuracy": 0.7503748125937032,
            "ap": 0.1673245279468637,
            "ap_weighted": 0.1673245279468637,
            "f1": 0.5804298444871571,
            "f1_weighted": 0.791810158174451
          }
        ]
      },
      {
        "accuracy": 0.6419402985074627,
        "ap": 0.2765189449145446,
        "ap_weighted": 0.2765189449145446,
        "f1": 0.5834428989348908,
        "f1_weighted": 0.6779502892963228,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6419402985074627,
        "scores_per_experiment": [
          {
            "accuracy": 0.5925373134328358,
            "ap": 0.2532190642255981,
            "ap_weighted": 0.2532190642255981,
            "f1": 0.5447859814688996,
            "f1_weighted": 0.6345672876499411
          },
          {
            "accuracy": 0.6776119402985075,
            "ap": 0.3022948757596131,
            "ap_weighted": 0.3022948757596131,
            "f1": 0.6172886519421172,
            "f1_weighted": 0.7098145979925201
          },
          {
            "accuracy": 0.6746268656716418,
            "ap": 0.270226897741994,
            "ap_weighted": 0.270226897741994,
            "f1": 0.5957197108092249,
            "f1_weighted": 0.7044836269709346
          },
          {
            "accuracy": 0.5671641791044776,
            "ap": 0.23629401658728794,
            "ap_weighted": 0.23629401658728794,
            "f1": 0.5200098814229248,
            "f1_weighted": 0.6116239454899416
          },
          {
            "accuracy": 0.6432835820895523,
            "ap": 0.2601230488777486,
            "ap_weighted": 0.2601230488777486,
            "f1": 0.5747319666754307,
            "f1_weighted": 0.6787061640321652
          },
          {
            "accuracy": 0.6059701492537314,
            "ap": 0.2554881783183689,
            "ap_weighted": 0.2554881783183689,
            "f1": 0.5533333333333333,
            "f1_weighted": 0.6467064676616915
          },
          {
            "accuracy": 0.664179104477612,
            "ap": 0.3176107935103706,
            "ap_weighted": 0.3176107935103706,
            "f1": 0.6179782114538115,
            "f1_weighted": 0.698879346019093
          },
          {
            "accuracy": 0.6358208955223881,
            "ap": 0.2652624782875498,
            "ap_weighted": 0.2652624782875498,
            "f1": 0.5746961371961372,
            "f1_weighted": 0.6728807883658631
          },
          {
            "accuracy": 0.6671641791044776,
            "ap": 0.299954105400318,
            "ap_weighted": 0.299954105400318,
            "f1": 0.6107847606642788,
            "f1_weighted": 0.7009918301685969
          },
          {
            "accuracy": 0.691044776119403,
            "ap": 0.3047159904365974,
            "ap_weighted": 0.3047159904365974,
            "f1": 0.6251003543827496,
            "f1_weighted": 0.7208488386124812
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}