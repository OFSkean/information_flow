{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 27.10489821434021,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.6395052473763119,
        "ap": 0.15455555996288176,
        "ap_weighted": 0.15455555996288176,
        "f1": 0.52018868905344,
        "f1_weighted": 0.7085315008286956,
        "hf_subset": "en-ext",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6395052473763119,
        "scores_per_experiment": [
          {
            "accuracy": 0.6499250374812594,
            "ap": 0.1448540919797534,
            "ap_weighted": 0.1448540919797534,
            "f1": 0.5184699945197941,
            "f1_weighted": 0.7176328716608377
          },
          {
            "accuracy": 0.6281859070464768,
            "ap": 0.15037229916491823,
            "ap_weighted": 0.15037229916491823,
            "f1": 0.5124269005847953,
            "f1_weighted": 0.7004907633902346
          },
          {
            "accuracy": 0.651424287856072,
            "ap": 0.15462863151581213,
            "ap_weighted": 0.15462863151581213,
            "f1": 0.5266005307056003,
            "f1_weighted": 0.7190295636266194
          },
          {
            "accuracy": 0.6131934032983508,
            "ap": 0.15003180162240315,
            "ap_weighted": 0.15003180162240315,
            "f1": 0.50485260901466,
            "f1_weighted": 0.6881985685716753
          },
          {
            "accuracy": 0.5862068965517241,
            "ap": 0.1430009753043666,
            "ap_weighted": 0.1430009753043666,
            "f1": 0.48642639341838395,
            "f1_weighted": 0.6656240316986682
          },
          {
            "accuracy": 0.6086956521739131,
            "ap": 0.16470975419770453,
            "ap_weighted": 0.16470975419770453,
            "f1": 0.5119238533138948,
            "f1_weighted": 0.6839626068428162
          },
          {
            "accuracy": 0.6221889055472264,
            "ap": 0.14868493329538282,
            "ap_weighted": 0.14868493329538282,
            "f1": 0.5083077859165477,
            "f1_weighted": 0.6956262630660752
          },
          {
            "accuracy": 0.6761619190404797,
            "ap": 0.17359150722518565,
            "ap_weighted": 0.17359150722518565,
            "f1": 0.5511565961026217,
            "f1_weighted": 0.738664580509409
          },
          {
            "accuracy": 0.6086956521739131,
            "ap": 0.15006714594765835,
            "ap_weighted": 0.15006714594765835,
            "f1": 0.502644096850225,
            "f1_weighted": 0.6844467631194046
          },
          {
            "accuracy": 0.7503748125937032,
            "ap": 0.16561445937563257,
            "ap_weighted": 0.16561445937563257,
            "f1": 0.5790781301078783,
            "f1_weighted": 0.7916389958012168
          }
        ]
      },
      {
        "accuracy": 0.65,
        "ap": 0.2827938852965247,
        "ap_weighted": 0.2827938852965247,
        "f1": 0.591378014070276,
        "f1_weighted": 0.6850438269186204,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.65,
        "scores_per_experiment": [
          {
            "accuracy": 0.591044776119403,
            "ap": 0.25262455947521156,
            "ap_weighted": 0.25262455947521156,
            "f1": 0.543610345959169,
            "f1_weighted": 0.6332087140396109
          },
          {
            "accuracy": 0.6865671641791045,
            "ap": 0.31183712714420064,
            "ap_weighted": 0.31183712714420064,
            "f1": 0.6268656716417911,
            "f1_weighted": 0.7177545110269548
          },
          {
            "accuracy": 0.6835820895522388,
            "ap": 0.27506544002376754,
            "ap_weighted": 0.27506544002376754,
            "f1": 0.6029030237967437,
            "f1_weighted": 0.7118999073339689
          },
          {
            "accuracy": 0.5671641791044776,
            "ap": 0.23918102904089006,
            "ap_weighted": 0.23918102904089006,
            "f1": 0.5219748858447488,
            "f1_weighted": 0.6114760103591631
          },
          {
            "accuracy": 0.6582089552238806,
            "ap": 0.2780930607403038,
            "ap_weighted": 0.2780930607403038,
            "f1": 0.5936823874304509,
            "f1_weighted": 0.6922847831597367
          },
          {
            "accuracy": 0.6268656716417911,
            "ap": 0.2662746104468789,
            "ap_weighted": 0.2662746104468789,
            "f1": 0.570882521724873,
            "f1_weighted": 0.6652673364608341
          },
          {
            "accuracy": 0.6671641791044776,
            "ap": 0.31551479244996394,
            "ap_weighted": 0.31551479244996394,
            "f1": 0.6186370377176929,
            "f1_weighted": 0.7014783502106141
          },
          {
            "accuracy": 0.6686567164179105,
            "ap": 0.2912536553871862,
            "ap_weighted": 0.2912536553871862,
            "f1": 0.6066577811627316,
            "f1_weighted": 0.7017538923812014
          },
          {
            "accuracy": 0.6656716417910448,
            "ap": 0.2990849289110894,
            "ap_weighted": 0.2990849289110894,
            "f1": 0.6095571095571095,
            "f1_weighted": 0.6996938384998086
          },
          {
            "accuracy": 0.6850746268656717,
            "ap": 0.2990096493457551,
            "ap_weighted": 0.2990096493457551,
            "f1": 0.6190093758674496,
            "f1_weighted": 0.7156209257143119
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}