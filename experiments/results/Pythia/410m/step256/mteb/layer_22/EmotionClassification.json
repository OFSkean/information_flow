{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "evaluation_time": 19.617347240447998,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.1826,
        "f1": 0.16070291525729025,
        "f1_weighted": 0.2010964733951051,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.1826,
        "scores_per_experiment": [
          {
            "accuracy": 0.1635,
            "f1": 0.1533393392025856,
            "f1_weighted": 0.18199792116459426
          },
          {
            "accuracy": 0.1975,
            "f1": 0.16616307352283383,
            "f1_weighted": 0.2207922007542893
          },
          {
            "accuracy": 0.204,
            "f1": 0.17139827895423357,
            "f1_weighted": 0.22019391057037666
          },
          {
            "accuracy": 0.184,
            "f1": 0.15888525138570256,
            "f1_weighted": 0.20354629222216536
          },
          {
            "accuracy": 0.169,
            "f1": 0.1530177547485211,
            "f1_weighted": 0.18702977302843624
          },
          {
            "accuracy": 0.201,
            "f1": 0.17335580860638886,
            "f1_weighted": 0.21697633001394206
          },
          {
            "accuracy": 0.184,
            "f1": 0.16022028992175366,
            "f1_weighted": 0.20515657755784827
          },
          {
            "accuracy": 0.1865,
            "f1": 0.17020548439280878,
            "f1_weighted": 0.20278529147575142
          },
          {
            "accuracy": 0.1745,
            "f1": 0.1534949432251905,
            "f1_weighted": 0.19220755237384346
          },
          {
            "accuracy": 0.162,
            "f1": 0.14694892861288392,
            "f1_weighted": 0.18027888478980414
          }
        ]
      }
    ]
  },
  "task_name": "EmotionClassification"
}