{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 26.72504997253418,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.6451274362818591,
        "ap": 0.15690478833801258,
        "ap_weighted": 0.15690478833801258,
        "f1": 0.5245625435201577,
        "f1_weighted": 0.7132416193786594,
        "hf_subset": "en-ext",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6451274362818591,
        "scores_per_experiment": [
          {
            "accuracy": 0.6754122938530734,
            "ap": 0.14972064327548457,
            "ap_weighted": 0.14972064327548457,
            "f1": 0.5339243511216938,
            "f1_weighted": 0.7372049872092269
          },
          {
            "accuracy": 0.6274362818590704,
            "ap": 0.15278326173734585,
            "ap_weighted": 0.15278326173734585,
            "f1": 0.5137638968237612,
            "f1_weighted": 0.6998693830211047
          },
          {
            "accuracy": 0.6484257871064468,
            "ap": 0.14316229680946993,
            "ap_weighted": 0.14316229680946993,
            "f1": 0.5164077675155962,
            "f1_weighted": 0.7164235905972867
          },
          {
            "accuracy": 0.6229385307346327,
            "ap": 0.15814739883280515,
            "ap_weighted": 0.15814739883280515,
            "f1": 0.5151421872008035,
            "f1_weighted": 0.6961166526566439
          },
          {
            "accuracy": 0.610944527736132,
            "ap": 0.1506886694542417,
            "ap_weighted": 0.1506886694542417,
            "f1": 0.5041904332226913,
            "f1_weighted": 0.6863105039919859
          },
          {
            "accuracy": 0.6079460269865068,
            "ap": 0.16309449591750888,
            "ap_weighted": 0.16309449591750888,
            "f1": 0.5105809694773387,
            "f1_weighted": 0.6833834917120976
          },
          {
            "accuracy": 0.6506746626686657,
            "ap": 0.15856969306977808,
            "ap_weighted": 0.15856969306977808,
            "f1": 0.5290119041846482,
            "f1_weighted": 0.7185043421774541
          },
          {
            "accuracy": 0.6694152923538231,
            "ap": 0.17723009140645787,
            "ap_weighted": 0.17723009140645787,
            "f1": 0.5500918868113556,
            "f1_weighted": 0.7335060298285982
          },
          {
            "accuracy": 0.603448275862069,
            "ap": 0.14864167223972663,
            "ap_weighted": 0.14864167223972663,
            "f1": 0.49904271744724654,
            "f1_weighted": 0.6800809271123573
          },
          {
            "accuracy": 0.7346326836581709,
            "ap": 0.16700966063730727,
            "ap_weighted": 0.16700966063730727,
            "f1": 0.5734693213964428,
            "f1_weighted": 0.7810162854798389
          }
        ]
      },
      {
        "accuracy": 0.6597014925373135,
        "ap": 0.2918466763336801,
        "ap_weighted": 0.2918466763336801,
        "f1": 0.6015123125072197,
        "f1_weighted": 0.6937353996446577,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6597014925373135,
        "scores_per_experiment": [
          {
            "accuracy": 0.591044776119403,
            "ap": 0.2510530745005088,
            "ap_weighted": 0.2510530745005088,
            "f1": 0.5426233755879772,
            "f1_weighted": 0.6332469141972509
          },
          {
            "accuracy": 0.6865671641791045,
            "ap": 0.3098396323950779,
            "ap_weighted": 0.3098396323950779,
            "f1": 0.6257978723404256,
            "f1_weighted": 0.717627024452207
          },
          {
            "accuracy": 0.6940298507462687,
            "ap": 0.28684707527184883,
            "ap_weighted": 0.28684707527184883,
            "f1": 0.6153641508747071,
            "f1_weighted": 0.7212902417908693
          },
          {
            "accuracy": 0.6014925373134329,
            "ap": 0.2568651091820826,
            "ap_weighted": 0.2568651091820826,
            "f1": 0.551846201252095,
            "f1_weighted": 0.6426789596064711
          },
          {
            "accuracy": 0.6761194029850747,
            "ap": 0.28789712623026964,
            "ap_weighted": 0.28789712623026964,
            "f1": 0.6081755192570453,
            "f1_weighted": 0.7075343169668514
          },
          {
            "accuracy": 0.6343283582089553,
            "ap": 0.2732614265170948,
            "ap_weighted": 0.2732614265170948,
            "f1": 0.5789416982385579,
            "f1_weighted": 0.6719365841147807
          },
          {
            "accuracy": 0.6567164179104478,
            "ap": 0.31310440507508847,
            "ap_weighted": 0.31310440507508847,
            "f1": 0.6117566437231051,
            "f1_weighted": 0.6922109764794024
          },
          {
            "accuracy": 0.7059701492537314,
            "ap": 0.32907425462281276,
            "ap_weighted": 0.32907425462281276,
            "f1": 0.6453511960899694,
            "f1_weighted": 0.7346383184394816
          },
          {
            "accuracy": 0.6611940298507463,
            "ap": 0.29272522453852656,
            "ap_weighted": 0.29272522453852656,
            "f1": 0.6038033213936829,
            "f1_weighted": 0.6956284549249843
          },
          {
            "accuracy": 0.6895522388059702,
            "ap": 0.31779943500349106,
            "ap_weighted": 0.31779943500349106,
            "f1": 0.6314631463146314,
            "f1_weighted": 0.7205622054742786
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}