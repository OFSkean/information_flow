{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 35.77818942070007,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.6275862068965518,
        "ap": 0.150354166236923,
        "ap_weighted": 0.150354166236923,
        "f1": 0.5112768659177075,
        "f1_weighted": 0.6989034945795335,
        "hf_subset": "en-ext",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6275862068965518,
        "scores_per_experiment": [
          {
            "accuracy": 0.631184407796102,
            "ap": 0.14107991225353408,
            "ap_weighted": 0.14107991225353408,
            "f1": 0.5067635812711926,
            "f1_weighted": 0.7028656600925423
          },
          {
            "accuracy": 0.6146926536731634,
            "ap": 0.14172871759725814,
            "ap_weighted": 0.14172871759725814,
            "f1": 0.49949049458522754,
            "f1_weighted": 0.6895740570803217
          },
          {
            "accuracy": 0.638680659670165,
            "ap": 0.14685863271156507,
            "ap_weighted": 0.14685863271156507,
            "f1": 0.5148285645297598,
            "f1_weighted": 0.7088757640375756
          },
          {
            "accuracy": 0.6071964017991005,
            "ap": 0.15221392255357288,
            "ap_weighted": 0.15221392255357288,
            "f1": 0.5033478844098855,
            "f1_weighted": 0.6831249899230181
          },
          {
            "accuracy": 0.5832083958020989,
            "ap": 0.14110442209522167,
            "ap_weighted": 0.14110442209522167,
            "f1": 0.4835505793226381,
            "f1_weighted": 0.6631387264255572
          },
          {
            "accuracy": 0.5974512743628186,
            "ap": 0.17231772625662395,
            "ap_weighted": 0.17231772625662395,
            "f1": 0.5102117002270634,
            "f1_weighted": 0.6738440097960819
          },
          {
            "accuracy": 0.5869565217391305,
            "ap": 0.14083742444846317,
            "ap_weighted": 0.14083742444846317,
            "f1": 0.48523678362806544,
            "f1_weighted": 0.6663768231648018
          },
          {
            "accuracy": 0.6956521739130435,
            "ap": 0.16709714043562446,
            "ap_weighted": 0.16709714043562446,
            "f1": 0.5560812162104566,
            "f1_weighted": 0.7531225682611674
          },
          {
            "accuracy": 0.6026986506746627,
            "ap": 0.14473575876903857,
            "ap_weighted": 0.14473575876903857,
            "f1": 0.4959074834588182,
            "f1_weighted": 0.6795743769114758
          },
          {
            "accuracy": 0.7181409295352323,
            "ap": 0.155568005248328,
            "ap_weighted": 0.155568005248328,
            "f1": 0.5573503715339676,
            "f1_weighted": 0.7685379701027931
          }
        ]
      },
      {
        "accuracy": 0.6422388059701493,
        "ap": 0.2715839036888032,
        "ap_weighted": 0.2715839036888032,
        "f1": 0.5807757738091873,
        "f1_weighted": 0.6780496851063618,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6422388059701493,
        "scores_per_experiment": [
          {
            "accuracy": 0.608955223880597,
            "ap": 0.2487050444439074,
            "ap_weighted": 0.2487050444439074,
            "f1": 0.5502848827676668,
            "f1_weighted": 0.6492001686109541
          },
          {
            "accuracy": 0.6746268656716418,
            "ap": 0.3024430031066592,
            "ap_weighted": 0.3024430031066592,
            "f1": 0.6158903475553312,
            "f1_weighted": 0.7073579024845478
          },
          {
            "accuracy": 0.6791044776119403,
            "ap": 0.276344656395161,
            "ap_weighted": 0.276344656395161,
            "f1": 0.6019343696027635,
            "f1_weighted": 0.7086645528832523
          },
          {
            "accuracy": 0.5761194029850746,
            "ap": 0.23079914728900844,
            "ap_weighted": 0.23079914728900844,
            "f1": 0.5206038557276603,
            "f1_weighted": 0.6199474666093492
          },
          {
            "accuracy": 0.6432835820895523,
            "ap": 0.2635680182693819,
            "ap_weighted": 0.2635680182693819,
            "f1": 0.5771307849739222,
            "f1_weighted": 0.6789811292123262
          },
          {
            "accuracy": 0.5940298507462687,
            "ap": 0.2538172730554263,
            "ap_weighted": 0.2538172730554263,
            "f1": 0.5459618910946344,
            "f1_weighted": 0.6359239440206288
          },
          {
            "accuracy": 0.6597014925373135,
            "ap": 0.2956683735762667,
            "ap_weighted": 0.2956683735762667,
            "f1": 0.6046583850931677,
            "f1_weighted": 0.6944887364420137
          },
          {
            "accuracy": 0.655223880597015,
            "ap": 0.26578705447182827,
            "ap_weighted": 0.26578705447182827,
            "f1": 0.5841427730801164,
            "f1_weighted": 0.6888398556320825
          },
          {
            "accuracy": 0.6358208955223881,
            "ap": 0.281101408534382,
            "ap_weighted": 0.281101408534382,
            "f1": 0.5842361725719982,
            "f1_weighted": 0.6734165410625026
          },
          {
            "accuracy": 0.6955223880597015,
            "ap": 0.29760505774601054,
            "ap_weighted": 0.29760505774601054,
            "f1": 0.6229142756246138,
            "f1_weighted": 0.72367655410596
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}