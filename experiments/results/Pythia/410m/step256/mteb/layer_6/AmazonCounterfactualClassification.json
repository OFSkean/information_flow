{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 25.024731636047363,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.6532983508245876,
        "ap": 0.1604439194178171,
        "ap_weighted": 0.1604439194178171,
        "f1": 0.530962913803789,
        "f1_weighted": 0.7196736793366784,
        "hf_subset": "en-ext",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6532983508245876,
        "scores_per_experiment": [
          {
            "accuracy": 0.6896551724137931,
            "ap": 0.15581762442260041,
            "ap_weighted": 0.15581762442260041,
            "f1": 0.5450969151238991,
            "f1_weighted": 0.7480936168501332
          },
          {
            "accuracy": 0.6319340329835083,
            "ap": 0.15145229144021116,
            "ap_weighted": 0.15145229144021116,
            "f1": 0.5150100219839455,
            "f1_weighted": 0.7035165191069046
          },
          {
            "accuracy": 0.6634182908545727,
            "ap": 0.1528651031088062,
            "ap_weighted": 0.1528651031088062,
            "f1": 0.5309125795398923,
            "f1_weighted": 0.7282694640932103
          },
          {
            "accuracy": 0.6296851574212894,
            "ap": 0.1630359559573116,
            "ap_weighted": 0.1630359559573116,
            "f1": 0.5216347270615562,
            "f1_weighted": 0.7016051599635722
          },
          {
            "accuracy": 0.6326836581709145,
            "ap": 0.15167069433076202,
            "ap_weighted": 0.15167069433076202,
            "f1": 0.5155274899571605,
            "f1_weighted": 0.7041203461061306
          },
          {
            "accuracy": 0.6124437781109445,
            "ap": 0.1673082938331609,
            "ap_weighted": 0.1673082938331609,
            "f1": 0.5153852694064632,
            "f1_weighted": 0.6870666516375055
          },
          {
            "accuracy": 0.6499250374812594,
            "ap": 0.16115982775998094,
            "ap_weighted": 0.16115982775998094,
            "f1": 0.5304045522969155,
            "f1_weighted": 0.7179433819472383
          },
          {
            "accuracy": 0.6776611694152923,
            "ap": 0.1773467899989912,
            "ap_weighted": 0.1773467899989912,
            "f1": 0.5542109124368955,
            "f1_weighted": 0.7399138631052534
          },
          {
            "accuracy": 0.5974512743628186,
            "ap": 0.1470536986430119,
            "ap_weighted": 0.1470536986430119,
            "f1": 0.4949374451389109,
            "f1_weighted": 0.6750615776854109
          },
          {
            "accuracy": 0.7481259370314842,
            "ap": 0.1767289146833347,
            "ap_weighted": 0.1767289146833347,
            "f1": 0.5865092250922509,
            "f1_weighted": 0.7911462128714241
          }
        ]
      },
      {
        "accuracy": 0.6661194029850747,
        "ap": 0.29803173304124775,
        "ap_weighted": 0.29803173304124775,
        "f1": 0.6082511988445864,
        "f1_weighted": 0.6994625965976964,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6661194029850747,
        "scores_per_experiment": [
          {
            "accuracy": 0.6,
            "ap": 0.25464100797358175,
            "ap_weighted": 0.25464100797358175,
            "f1": 0.5496634263299927,
            "f1_weighted": 0.6413478998003631
          },
          {
            "accuracy": 0.7014925373134329,
            "ap": 0.31972798332602365,
            "ap_weighted": 0.31972798332602365,
            "f1": 0.6383265856950068,
            "f1_weighted": 0.7303684009104277
          },
          {
            "accuracy": 0.7119402985074627,
            "ap": 0.3043344512089403,
            "ap_weighted": 0.3043344512089403,
            "f1": 0.6341170112529321,
            "f1_weighted": 0.7368739730647396
          },
          {
            "accuracy": 0.6,
            "ap": 0.25464100797358175,
            "ap_weighted": 0.25464100797358175,
            "f1": 0.5496634263299927,
            "f1_weighted": 0.6413478998003631
          },
          {
            "accuracy": 0.6835820895522388,
            "ap": 0.3000579201343297,
            "ap_weighted": 0.3000579201343297,
            "f1": 0.6189137270473595,
            "f1_weighted": 0.7145104368371812
          },
          {
            "accuracy": 0.6492537313432836,
            "ap": 0.29549892215279705,
            "ap_weighted": 0.29549892215279705,
            "f1": 0.5990894530862092,
            "f1_weighted": 0.6854482105920588
          },
          {
            "accuracy": 0.6656716417910448,
            "ap": 0.3146004526327304,
            "ap_weighted": 0.3146004526327304,
            "f1": 0.6173927231195953,
            "f1_weighted": 0.7001565836992228
          },
          {
            "accuracy": 0.7059701492537314,
            "ap": 0.3353366754016178,
            "ap_weighted": 0.3353366754016178,
            "f1": 0.6484569553533142,
            "f1_weighted": 0.7350450849155659
          },
          {
            "accuracy": 0.664179104477612,
            "ap": 0.296312786139189,
            "ap_weighted": 0.296312786139189,
            "f1": 0.6072940410289808,
            "f1_weighted": 0.6983101425467906
          },
          {
            "accuracy": 0.6791044776119403,
            "ap": 0.30516612346968564,
            "ap_weighted": 0.30516612346968564,
            "f1": 0.6195946392024824,
            "f1_weighted": 0.7112173338102517
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}