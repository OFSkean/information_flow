{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 36.438265800476074,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.6359070464767617,
        "ap": 0.14704758208020557,
        "ap_weighted": 0.14704758208020557,
        "f1": 0.5125925846084778,
        "f1_weighted": 0.7051061994532521,
        "hf_subset": "en-ext",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6359070464767617,
        "scores_per_experiment": [
          {
            "accuracy": 0.6911544227886057,
            "ap": 0.1623115754615682,
            "ap_weighted": 0.1623115754615682,
            "f1": 0.5506214024071167,
            "f1_weighted": 0.7495528628935139
          },
          {
            "accuracy": 0.6071964017991005,
            "ap": 0.1398703621385971,
            "ap_weighted": 0.1398703621385971,
            "f1": 0.4944396870949824,
            "f1_weighted": 0.6834414184085518
          },
          {
            "accuracy": 0.6874062968515742,
            "ap": 0.1565030129462504,
            "ap_weighted": 0.1565030129462504,
            "f1": 0.5446118733049158,
            "f1_weighted": 0.7464738696439669
          },
          {
            "accuracy": 0.6634182908545727,
            "ap": 0.15425505344980536,
            "ap_weighted": 0.15425505344980536,
            "f1": 0.5319506730837605,
            "f1_weighted": 0.7283153185801928
          },
          {
            "accuracy": 0.5787106446776612,
            "ap": 0.12132261859527613,
            "ap_weighted": 0.12132261859527613,
            "f1": 0.46453253339047207,
            "f1_weighted": 0.6602664384542247
          },
          {
            "accuracy": 0.6521739130434783,
            "ap": 0.16190939752812494,
            "ap_weighted": 0.16190939752812494,
            "f1": 0.5319935278017209,
            "f1_weighted": 0.7197309343332234
          },
          {
            "accuracy": 0.6124437781109445,
            "ap": 0.1423669010818332,
            "ap_weighted": 0.1423669010818332,
            "f1": 0.49890106377027044,
            "f1_weighted": 0.6877217036816907
          },
          {
            "accuracy": 0.6154422788605697,
            "ap": 0.14684406817303602,
            "ap_weighted": 0.14684406817303602,
            "f1": 0.5036925243696455,
            "f1_weighted": 0.6901186550843628
          },
          {
            "accuracy": 0.5194902548725637,
            "ap": 0.1258611701343573,
            "ap_weighted": 0.1258611701343573,
            "f1": 0.4391101263273754,
            "f1_weighted": 0.607192137701076
          },
          {
            "accuracy": 0.7316341829085458,
            "ap": 0.15923166129320687,
            "ap_weighted": 0.15923166129320687,
            "f1": 0.5660724345345182,
            "f1_weighted": 0.7782486557517184
          }
        ]
      },
      {
        "accuracy": 0.6482089552238806,
        "ap": 0.2786631480658075,
        "ap_weighted": 0.2786631480658075,
        "f1": 0.5879220215200828,
        "f1_weighted": 0.6827729645057249,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6482089552238806,
        "scores_per_experiment": [
          {
            "accuracy": 0.6597014925373135,
            "ap": 0.27704527675197044,
            "ap_weighted": 0.27704527675197044,
            "f1": 0.5937234042553192,
            "f1_weighted": 0.6934236265481105
          },
          {
            "accuracy": 0.6850746268656717,
            "ap": 0.2721395654001642,
            "ap_weighted": 0.2721395654001642,
            "f1": 0.6013827678478278,
            "f1_weighted": 0.7126084306467863
          },
          {
            "accuracy": 0.682089552238806,
            "ap": 0.2913693994246326,
            "ap_weighted": 0.2913693994246326,
            "f1": 0.6130538405850151,
            "f1_weighted": 0.7125823577395969
          },
          {
            "accuracy": 0.6059701492537314,
            "ap": 0.2670227667231869,
            "ap_weighted": 0.2670227667231869,
            "f1": 0.5602669026759877,
            "f1_weighted": 0.6465952573228367
          },
          {
            "accuracy": 0.6895522388059702,
            "ap": 0.27842957671753277,
            "ap_weighted": 0.27842957671753277,
            "f1": 0.607728337236534,
            "f1_weighted": 0.7168268726624489
          },
          {
            "accuracy": 0.5746268656716418,
            "ap": 0.25713830164785445,
            "ap_weighted": 0.25713830164785445,
            "f1": 0.5369999927258444,
            "f1_weighted": 0.6173757213221028
          },
          {
            "accuracy": 0.673134328358209,
            "ap": 0.317249319689138,
            "ap_weighted": 0.317249319689138,
            "f1": 0.6226808100289296,
            "f1_weighted": 0.7067013630017703
          },
          {
            "accuracy": 0.6671641791044776,
            "ap": 0.2904085745008728,
            "ap_weighted": 0.2904085745008728,
            "f1": 0.6054400211262956,
            "f1_weighted": 0.7004719322776097
          },
          {
            "accuracy": 0.6507462686567164,
            "ap": 0.2706811550835705,
            "ap_weighted": 0.2706811550835705,
            "f1": 0.5853960396039604,
            "f1_weighted": 0.6856324811585636
          },
          {
            "accuracy": 0.5940298507462687,
            "ap": 0.26514754471915236,
            "ap_weighted": 0.26514754471915236,
            "f1": 0.5525480991151137,
            "f1_weighted": 0.6355116023774234
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}