{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 26.9255268573761,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.6495502248875562,
        "ap": 0.15566589210447923,
        "ap_weighted": 0.15566589210447923,
        "f1": 0.5256149984736015,
        "f1_weighted": 0.7164421588965467,
        "hf_subset": "en-ext",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6495502248875562,
        "scores_per_experiment": [
          {
            "accuracy": 0.7061469265367316,
            "ap": 0.18461776226017512,
            "ap_weighted": 0.18461776226017512,
            "f1": 0.5724358974358974,
            "f1_weighted": 0.761710490908392
          },
          {
            "accuracy": 0.6101949025487257,
            "ap": 0.14794445596140499,
            "ap_weighted": 0.14794445596140499,
            "f1": 0.5019071252958343,
            "f1_weighted": 0.6857526120788783
          },
          {
            "accuracy": 0.697151424287856,
            "ap": 0.15846400407884184,
            "ap_weighted": 0.15846400407884184,
            "f1": 0.5504791010516201,
            "f1_weighted": 0.753741533253018
          },
          {
            "accuracy": 0.6431784107946027,
            "ap": 0.15077110257612908,
            "ap_weighted": 0.15077110257612908,
            "f1": 0.5198899121414206,
            "f1_weighted": 0.7124825964280482
          },
          {
            "accuracy": 0.5997001499250375,
            "ap": 0.13468039974525386,
            "ap_weighted": 0.13468039974525386,
            "f1": 0.486656866136285,
            "f1_weighted": 0.6773496899077268
          },
          {
            "accuracy": 0.6409295352323838,
            "ap": 0.16823131520938053,
            "ap_weighted": 0.16823131520938053,
            "f1": 0.5304842877790245,
            "f1_weighted": 0.7107473191712154
          },
          {
            "accuracy": 0.6431784107946027,
            "ap": 0.14683172318506488,
            "ap_weighted": 0.14683172318506488,
            "f1": 0.5169137695978187,
            "f1_weighted": 0.7124203108057423
          },
          {
            "accuracy": 0.643928035982009,
            "ap": 0.16202768795862357,
            "ap_weighted": 0.16202768795862357,
            "f1": 0.5280549069553526,
            "f1_weighted": 0.7131714338118563
          },
          {
            "accuracy": 0.5719640179910045,
            "ap": 0.14075616959425707,
            "ap_weighted": 0.14075616959425707,
            "f1": 0.47758642092578735,
            "f1_weighted": 0.6533584535551865
          },
          {
            "accuracy": 0.7391304347826086,
            "ap": 0.16233430047566144,
            "ap_weighted": 0.16233430047566144,
            "f1": 0.5717416974169742,
            "f1_weighted": 0.7836871490454036
          }
        ]
      },
      {
        "accuracy": 0.6613432835820896,
        "ap": 0.2934359188859273,
        "ap_weighted": 0.2934359188859273,
        "f1": 0.6035347275141987,
        "f1_weighted": 0.6951136154694155,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6613432835820896,
        "scores_per_experiment": [
          {
            "accuracy": 0.6611940298507463,
            "ap": 0.298416708246082,
            "ap_weighted": 0.298416708246082,
            "f1": 0.606899991987573,
            "f1_weighted": 0.6958637166790377
          },
          {
            "accuracy": 0.7059701492537314,
            "ap": 0.3166517033154836,
            "ap_weighted": 0.3166517033154836,
            "f1": 0.6387586588172829,
            "f1_weighted": 0.7336454688452101
          },
          {
            "accuracy": 0.6970149253731344,
            "ap": 0.3045491625840264,
            "ap_weighted": 0.3045491625840264,
            "f1": 0.6277563844665403,
            "f1_weighted": 0.7255331480993791
          },
          {
            "accuracy": 0.6268656716417911,
            "ap": 0.26456725300911665,
            "ap_weighted": 0.26456725300911665,
            "f1": 0.5698112819880627,
            "f1_weighted": 0.6652137040320021
          },
          {
            "accuracy": 0.7074626865671642,
            "ap": 0.2992945454150877,
            "ap_weighted": 0.2992945454150877,
            "f1": 0.629077268978296,
            "f1_weighted": 0.7329124974726409
          },
          {
            "accuracy": 0.6044776119402985,
            "ap": 0.27481918923915866,
            "ap_weighted": 0.27481918923915866,
            "f1": 0.5636251920122888,
            "f1_weighted": 0.6449314716738888
          },
          {
            "accuracy": 0.6507462686567164,
            "ap": 0.3000883456575214,
            "ap_weighted": 0.3000883456575214,
            "f1": 0.6022265973857269,
            "f1_weighted": 0.68682499857617
          },
          {
            "accuracy": 0.6746268656716418,
            "ap": 0.30439344768401283,
            "ap_weighted": 0.30439344768401283,
            "f1": 0.6169420403881458,
            "f1_weighted": 0.7074628431407087
          },
          {
            "accuracy": 0.6328358208955224,
            "ap": 0.2725423695003278,
            "ap_weighted": 0.2725423695003278,
            "f1": 0.5777484013772749,
            "f1_weighted": 0.6706230590774607
          },
          {
            "accuracy": 0.6522388059701493,
            "ap": 0.29903646420845575,
            "ap_weighted": 0.29903646420845575,
            "f1": 0.6025014577407946,
            "f1_weighted": 0.6881252470976583
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}