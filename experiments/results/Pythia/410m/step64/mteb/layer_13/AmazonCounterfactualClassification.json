{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 30.245177030563354,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.6347826086956523,
        "ap": 0.14670645248531483,
        "ap_weighted": 0.14670645248531483,
        "f1": 0.5115952383591532,
        "f1_weighted": 0.704168343262723,
        "hf_subset": "en-ext",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6347826086956523,
        "scores_per_experiment": [
          {
            "accuracy": 0.6746626686656672,
            "ap": 0.1608783183631025,
            "ap_weighted": 0.1608783183631025,
            "f1": 0.541976785397838,
            "f1_weighted": 0.7371248254129182
          },
          {
            "accuracy": 0.6071964017991005,
            "ap": 0.13753967282122798,
            "ap_weighted": 0.13753967282122798,
            "f1": 0.4925842044134727,
            "f1_weighted": 0.6834840158318054
          },
          {
            "accuracy": 0.6896551724137931,
            "ap": 0.15728519217878734,
            "ap_weighted": 0.15728519217878734,
            "f1": 0.5462197302342702,
            "f1_weighted": 0.7481768328230384
          },
          {
            "accuracy": 0.6664167916041979,
            "ap": 0.15806303270112793,
            "ap_weighted": 0.15806303270112793,
            "f1": 0.5361203775551748,
            "f1_weighted": 0.7307356720895007
          },
          {
            "accuracy": 0.5637181409295352,
            "ap": 0.11706496972177716,
            "ap_weighted": 0.11706496972177716,
            "f1": 0.45307687755889864,
            "f1_weighted": 0.6478055010912189
          },
          {
            "accuracy": 0.6446776611694153,
            "ap": 0.16514961039636125,
            "ap_weighted": 0.16514961039636125,
            "f1": 0.5304323804092108,
            "f1_weighted": 0.7137804297751317
          },
          {
            "accuracy": 0.6296851574212894,
            "ap": 0.140695283117591,
            "ap_weighted": 0.140695283117591,
            "f1": 0.5057525057525057,
            "f1_weighted": 0.7016699910253134
          },
          {
            "accuracy": 0.6116941529235382,
            "ap": 0.14709257248833196,
            "ap_weighted": 0.14709257248833196,
            "f1": 0.5020379338175949,
            "f1_weighted": 0.6870171149292182
          },
          {
            "accuracy": 0.5239880059970015,
            "ap": 0.12860329915350172,
            "ap_weighted": 0.12860329915350172,
            "f1": 0.4436216056806307,
            "f1_weighted": 0.6110119779372137
          },
          {
            "accuracy": 0.7361319340329835,
            "ap": 0.15469257391133948,
            "ap_weighted": 0.15469257391133948,
            "f1": 0.564129982771936,
            "f1_weighted": 0.7808770717118717
          }
        ]
      },
      {
        "accuracy": 0.6505970149253731,
        "ap": 0.28239906528040765,
        "ap_weighted": 0.28239906528040765,
        "f1": 0.591287511962237,
        "f1_weighted": 0.6849204832531023,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6505970149253731,
        "scores_per_experiment": [
          {
            "accuracy": 0.6417910447761194,
            "ap": 0.2769308411902869,
            "ap_weighted": 0.2769308411902869,
            "f1": 0.5849208561781742,
            "f1_weighted": 0.6784814890328581
          },
          {
            "accuracy": 0.7208955223880597,
            "ap": 0.3126950870184644,
            "ap_weighted": 0.3126950870184644,
            "f1": 0.6429782492854721,
            "f1_weighted": 0.7445445349910815
          },
          {
            "accuracy": 0.6701492537313433,
            "ap": 0.28453007343573594,
            "ap_weighted": 0.28453007343573594,
            "f1": 0.6033219476257451,
            "f1_weighted": 0.7024693690478689
          },
          {
            "accuracy": 0.6029850746268657,
            "ap": 0.26905759838594445,
            "ap_weighted": 0.26905759838594445,
            "f1": 0.5597332015810277,
            "f1_weighted": 0.6437654120700844
          },
          {
            "accuracy": 0.6925373134328359,
            "ap": 0.2744217842087273,
            "ap_weighted": 0.2744217842087273,
            "f1": 0.6059993605554033,
            "f1_weighted": 0.718443579580857
          },
          {
            "accuracy": 0.5776119402985075,
            "ap": 0.256747948522963,
            "ap_weighted": 0.256747948522963,
            "f1": 0.538521448128993,
            "f1_weighted": 0.6203107855913618
          },
          {
            "accuracy": 0.6671641791044776,
            "ap": 0.31551479244996394,
            "ap_weighted": 0.31551479244996394,
            "f1": 0.6186370377176929,
            "f1_weighted": 0.7014783502106141
          },
          {
            "accuracy": 0.664179104477612,
            "ap": 0.2849867467780094,
            "ap_weighted": 0.2849867467780094,
            "f1": 0.6007796383050281,
            "f1_weighted": 0.6976597214451561
          },
          {
            "accuracy": 0.6656716417910448,
            "ap": 0.2783626926754207,
            "ap_weighted": 0.2783626926754207,
            "f1": 0.5973428059368326,
            "f1_weighted": 0.6983506502430593
          },
          {
            "accuracy": 0.6029850746268657,
            "ap": 0.2707430881385604,
            "ap_weighted": 0.2707430881385604,
            "f1": 0.5606405743080002,
            "f1_weighted": 0.6437009403180823
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}