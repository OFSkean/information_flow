{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 29.709558963775635,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.636056971514243,
        "ap": 0.14842634087201975,
        "ap_weighted": 0.14842634087201975,
        "f1": 0.513604440258031,
        "f1_weighted": 0.7053508926672565,
        "hf_subset": "en-ext",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.636056971514243,
        "scores_per_experiment": [
          {
            "accuracy": 0.6761619190404797,
            "ap": 0.16140419756043978,
            "ap_weighted": 0.16140419756043978,
            "f1": 0.5430478069326872,
            "f1_weighted": 0.7382818380241164
          },
          {
            "accuracy": 0.6079460269865068,
            "ap": 0.14243676115129184,
            "ap_weighted": 0.14243676115129184,
            "f1": 0.49677696698059115,
            "f1_weighted": 0.684009068043186
          },
          {
            "accuracy": 0.6911544227886057,
            "ap": 0.15633729897641108,
            "ap_weighted": 0.15633729897641108,
            "f1": 0.5461685823754789,
            "f1_weighted": 0.7492256745190622
          },
          {
            "accuracy": 0.6694152923538231,
            "ap": 0.16198895038858682,
            "ap_weighted": 0.16198895038858682,
            "f1": 0.5402900820265889,
            "f1_weighted": 0.7331560255988085
          },
          {
            "accuracy": 0.5697151424287856,
            "ap": 0.11889556681272659,
            "ap_weighted": 0.11889556681272659,
            "f1": 0.4578310864393339,
            "f1_weighted": 0.652797362222933
          },
          {
            "accuracy": 0.643928035982009,
            "ap": 0.1663452446438651,
            "ap_weighted": 0.1663452446438651,
            "f1": 0.5308141760537152,
            "f1_weighted": 0.7131778952663538
          },
          {
            "accuracy": 0.6259370314842578,
            "ap": 0.13974636255194195,
            "ap_weighted": 0.13974636255194195,
            "f1": 0.5032295089429972,
            "f1_weighted": 0.6986731647553218
          },
          {
            "accuracy": 0.6116941529235382,
            "ap": 0.14709257248833196,
            "ap_weighted": 0.14709257248833196,
            "f1": 0.5020379338175949,
            "f1_weighted": 0.6870171149292182
          },
          {
            "accuracy": 0.5292353823088456,
            "ap": 0.12763024617145324,
            "ap_weighted": 0.12763024617145324,
            "f1": 0.44564964214627545,
            "f1_weighted": 0.6160483711263414
          },
          {
            "accuracy": 0.7353823088455772,
            "ap": 0.16238620797514913,
            "ap_weighted": 0.16238620797514913,
            "f1": 0.5701986168650464,
            "f1_weighted": 0.7811224121872239
          }
        ]
      },
      {
        "accuracy": 0.6535820895522388,
        "ap": 0.28571040820573523,
        "ap_weighted": 0.28571040820573523,
        "f1": 0.5946975727919833,
        "f1_weighted": 0.687642840309773,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6535820895522388,
        "scores_per_experiment": [
          {
            "accuracy": 0.6507462686567164,
            "ap": 0.27786681219963044,
            "ap_weighted": 0.27786681219963044,
            "f1": 0.5899418312688316,
            "f1_weighted": 0.6860976857426959
          },
          {
            "accuracy": 0.7223880597014926,
            "ap": 0.31587790274842287,
            "ap_weighted": 0.31587790274842287,
            "f1": 0.6455187793694319,
            "f1_weighted": 0.7460401459575112
          },
          {
            "accuracy": 0.6716417910447762,
            "ap": 0.2834784138446139,
            "ap_weighted": 0.2834784138446139,
            "f1": 0.6033539998277792,
            "f1_weighted": 0.7035749308225084
          },
          {
            "accuracy": 0.6044776119402985,
            "ap": 0.2697231817082897,
            "ap_weighted": 0.2697231817082897,
            "f1": 0.5609317002119298,
            "f1_weighted": 0.6451342214686806
          },
          {
            "accuracy": 0.6895522388059702,
            "ap": 0.2746293035638501,
            "ap_weighted": 0.2746293035638501,
            "f1": 0.6049886621315193,
            "f1_weighted": 0.716285240464345
          },
          {
            "accuracy": 0.5865671641791045,
            "ap": 0.26525187395173966,
            "ap_weighted": 0.26525187395173966,
            "f1": 0.5483054456951628,
            "f1_weighted": 0.6283607336000254
          },
          {
            "accuracy": 0.6716417910447762,
            "ap": 0.32425966306326426,
            "ap_weighted": 0.32425966306326426,
            "f1": 0.6251309752698344,
            "f1_weighted": 0.7055395042366828
          },
          {
            "accuracy": 0.6671641791044776,
            "ap": 0.2904085745008728,
            "ap_weighted": 0.2904085745008728,
            "f1": 0.6054400211262956,
            "f1_weighted": 0.7004719322776097
          },
          {
            "accuracy": 0.664179104477612,
            "ap": 0.27941235680062637,
            "ap_weighted": 0.27941235680062637,
            "f1": 0.5973245790940003,
            "f1_weighted": 0.6972390346123648
          },
          {
            "accuracy": 0.6074626865671642,
            "ap": 0.2761959996760427,
            "ap_weighted": 0.2761959996760427,
            "f1": 0.5660397339250488,
            "f1_weighted": 0.6476849739153051
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}