{
  "dataset_revision": "edfaf9da55d3dd50d43143d90c1ac476895ae6de",
  "evaluation_time": 34.390199422836304,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.548779296875,
        "ap": 0.08020037885471668,
        "ap_weighted": 0.08020037885471668,
        "f1": 0.4141706777618991,
        "f1_weighted": 0.6475398202046101,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.548779296875,
        "scores_per_experiment": [
          {
            "accuracy": 0.48193359375,
            "ap": 0.07890651440305113,
            "ap_weighted": 0.07890651440305113,
            "f1": 0.3833116269618393,
            "f1_weighted": 0.590911469138627
          },
          {
            "accuracy": 0.57080078125,
            "ap": 0.08065860416981058,
            "ap_weighted": 0.08065860416981058,
            "f1": 0.42661283772485137,
            "f1_weighted": 0.6686576426297748
          },
          {
            "accuracy": 0.642578125,
            "ap": 0.08059051890432098,
            "ap_weighted": 0.08059051890432098,
            "f1": 0.45476050190943806,
            "f1_weighted": 0.7241428498363338
          },
          {
            "accuracy": 0.51416015625,
            "ap": 0.07535479444173705,
            "ap_weighted": 0.07535479444173705,
            "f1": 0.39233289050117565,
            "f1_weighted": 0.6213734642754103
          },
          {
            "accuracy": 0.5009765625,
            "ap": 0.08227419197471281,
            "ap_weighted": 0.08227419197471281,
            "f1": 0.39712725718387326,
            "f1_weighted": 0.6077580834956409
          },
          {
            "accuracy": 0.47265625,
            "ap": 0.08396871912192469,
            "ap_weighted": 0.08396871912192469,
            "f1": 0.3847844976730266,
            "f1_weighted": 0.5805091759827193
          },
          {
            "accuracy": 0.67919921875,
            "ap": 0.07849642761752137,
            "ap_weighted": 0.07849642761752137,
            "f1": 0.4621519820698141,
            "f1_weighted": 0.7497687661102758
          },
          {
            "accuracy": 0.568359375,
            "ap": 0.07875806985188069,
            "ap_weighted": 0.07875806985188069,
            "f1": 0.42221558407406135,
            "f1_weighted": 0.6668290749054383
          },
          {
            "accuracy": 0.53369140625,
            "ap": 0.08149359853305999,
            "ap_weighted": 0.08149359853305999,
            "f1": 0.4115677316577487,
            "f1_weighted": 0.6372281978925196
          },
          {
            "accuracy": 0.5234375,
            "ap": 0.08150234952914742,
            "ap_weighted": 0.08150234952914742,
            "f1": 0.4068418678631627,
            "f1_weighted": 0.6282194777793606
          }
        ]
      }
    ]
  },
  "task_name": "ToxicConversationsClassification"
}