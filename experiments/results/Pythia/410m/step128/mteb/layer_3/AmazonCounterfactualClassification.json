{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 27.45888090133667,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.6583208395802098,
        "ap": 0.16161249522382876,
        "ap_weighted": 0.16161249522382876,
        "f1": 0.5341154138938243,
        "f1_weighted": 0.723449755876997,
        "hf_subset": "en-ext",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6583208395802098,
        "scores_per_experiment": [
          {
            "accuracy": 0.6979010494752623,
            "ap": 0.1759968508757379,
            "ap_weighted": 0.1759968508757379,
            "f1": 0.5630939271419574,
            "f1_weighted": 0.7552077209124973
          },
          {
            "accuracy": 0.6394302848575713,
            "ap": 0.15916125941201525,
            "ap_weighted": 0.15916125941201525,
            "f1": 0.5239627066259023,
            "f1_weighted": 0.7095544305416441
          },
          {
            "accuracy": 0.699400299850075,
            "ap": 0.162330672014389,
            "ap_weighted": 0.162330672014389,
            "f1": 0.5543832027556679,
            "f1_weighted": 0.7556158631126904
          },
          {
            "accuracy": 0.6491754122938531,
            "ap": 0.15949330392868438,
            "ap_weighted": 0.15949330392868438,
            "f1": 0.5289206809127128,
            "f1_weighted": 0.7173316547086833
          },
          {
            "accuracy": 0.616191904047976,
            "ap": 0.15086811586403515,
            "ap_weighted": 0.15086811586403515,
            "f1": 0.5069146647492153,
            "f1_weighted": 0.6906674747802525
          },
          {
            "accuracy": 0.6259370314842578,
            "ap": 0.17036906728980983,
            "ap_weighted": 0.17036906728980983,
            "f1": 0.5241391783493357,
            "f1_weighted": 0.6983669464376305
          },
          {
            "accuracy": 0.6244377811094453,
            "ap": 0.14301016957548404,
            "ap_weighted": 0.14301016957548404,
            "f1": 0.5051324256903396,
            "f1_weighted": 0.697478159007249
          },
          {
            "accuracy": 0.6881559220389805,
            "ap": 0.17360309046440103,
            "ap_weighted": 0.17360309046440103,
            "f1": 0.5569238630556975,
            "f1_weighted": 0.7478068579404729
          },
          {
            "accuracy": 0.5869565217391305,
            "ap": 0.1443752990978952,
            "ap_weighted": 0.1443752990978952,
            "f1": 0.48777654431712625,
            "f1_weighted": 0.6661991272091814
          },
          {
            "accuracy": 0.7556221889055472,
            "ap": 0.1769171237158358,
            "ap_weighted": 0.1769171237158358,
            "f1": 0.5899069453402889,
            "f1_weighted": 0.7962693241196672
          }
        ]
      },
      {
        "accuracy": 0.677910447761194,
        "ap": 0.3055881013067706,
        "ap_weighted": 0.3055881013067706,
        "f1": 0.6184370036609526,
        "f1_weighted": 0.7095501508753943,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.677910447761194,
        "scores_per_experiment": [
          {
            "accuracy": 0.6567164179104478,
            "ap": 0.293995318128802,
            "ap_weighted": 0.293995318128802,
            "f1": 0.6022158205040837,
            "f1_weighted": 0.6918780936564892
          },
          {
            "accuracy": 0.6925373134328359,
            "ap": 0.31168921017644197,
            "ap_weighted": 0.31168921017644197,
            "f1": 0.6296991876026228,
            "f1_weighted": 0.7225903301342419
          },
          {
            "accuracy": 0.7432835820895523,
            "ap": 0.3387854203831829,
            "ap_weighted": 0.3387854203831829,
            "f1": 0.6674170274170275,
            "f1_weighted": 0.7641468846244966
          },
          {
            "accuracy": 0.6313432835820896,
            "ap": 0.2718281383695794,
            "ap_weighted": 0.2718281383695794,
            "f1": 0.5765558992781825,
            "f1_weighted": 0.6693079855686144
          },
          {
            "accuracy": 0.7298507462686568,
            "ap": 0.321479563190854,
            "ap_weighted": 0.321479563190854,
            "f1": 0.651934066375631,
            "f1_weighted": 0.7522179950707556
          },
          {
            "accuracy": 0.6686567164179105,
            "ap": 0.2989026236073984,
            "ap_weighted": 0.2989026236073984,
            "f1": 0.6109704553063273,
            "f1_weighted": 0.7021952403199936
          },
          {
            "accuracy": 0.6567164179104478,
            "ap": 0.31698920880873716,
            "ap_weighted": 0.31698920880873716,
            "f1": 0.6135171196115609,
            "f1_weighted": 0.6922015557988191
          },
          {
            "accuracy": 0.6850746268656717,
            "ap": 0.3128792156673589,
            "ap_weighted": 0.3128792156673589,
            "f1": 0.6266719482405757,
            "f1_weighted": 0.7165900345765726
          },
          {
            "accuracy": 0.6776119402985075,
            "ap": 0.2983973828183072,
            "ap_weighted": 0.2983973828183072,
            "f1": 0.6151063829787233,
            "f1_weighted": 0.7095592251508415
          },
          {
            "accuracy": 0.6373134328358209,
            "ap": 0.2909349319170443,
            "ap_weighted": 0.2909349319170443,
            "f1": 0.5902821292947901,
            "f1_weighted": 0.6748141638531187
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}