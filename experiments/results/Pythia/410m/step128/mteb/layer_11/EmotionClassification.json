{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "evaluation_time": 14.399819135665894,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.19069999999999998,
        "f1": 0.16949581764038962,
        "f1_weighted": 0.2073749108280502,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.19069999999999998,
        "scores_per_experiment": [
          {
            "accuracy": 0.1905,
            "f1": 0.16513159940903646,
            "f1_weighted": 0.20861140573049944
          },
          {
            "accuracy": 0.1705,
            "f1": 0.1532597293131955,
            "f1_weighted": 0.18669544058041707
          },
          {
            "accuracy": 0.1915,
            "f1": 0.17131702239476576,
            "f1_weighted": 0.20850694490846122
          },
          {
            "accuracy": 0.1765,
            "f1": 0.16411047974809964,
            "f1_weighted": 0.18485149305980597
          },
          {
            "accuracy": 0.195,
            "f1": 0.17742118987086775,
            "f1_weighted": 0.20713344793358773
          },
          {
            "accuracy": 0.1835,
            "f1": 0.1691401550254604,
            "f1_weighted": 0.19820547221387466
          },
          {
            "accuracy": 0.2025,
            "f1": 0.17849470184548036,
            "f1_weighted": 0.22154494328863839
          },
          {
            "accuracy": 0.1855,
            "f1": 0.16450914984869539,
            "f1_weighted": 0.20657718056988666
          },
          {
            "accuracy": 0.2065,
            "f1": 0.1797171373386204,
            "f1_weighted": 0.22647051770828555
          },
          {
            "accuracy": 0.205,
            "f1": 0.17185701160967473,
            "f1_weighted": 0.22515226228704546
          }
        ]
      }
    ]
  },
  "task_name": "EmotionClassification"
}