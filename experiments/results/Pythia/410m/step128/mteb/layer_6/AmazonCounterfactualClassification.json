{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 25.10992169380188,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.6425787106446776,
        "ap": 0.15369265457321482,
        "ap_weighted": 0.15369265457321482,
        "f1": 0.5210904154900469,
        "f1_weighted": 0.7112983595530167,
        "hf_subset": "en-ext",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6425787106446776,
        "scores_per_experiment": [
          {
            "accuracy": 0.6596701649175413,
            "ap": 0.16011155356000503,
            "ap_weighted": 0.16011155356000503,
            "f1": 0.5343740101422935,
            "f1_weighted": 0.7255773908397813
          },
          {
            "accuracy": 0.5989505247376312,
            "ap": 0.13790069893110998,
            "ap_weighted": 0.13790069893110998,
            "f1": 0.4889053598731018,
            "f1_weighted": 0.6766399222268061
          },
          {
            "accuracy": 0.6544227886056971,
            "ap": 0.15145248239189757,
            "ap_weighted": 0.15145248239189757,
            "f1": 0.5256773652153324,
            "f1_weighted": 0.7212963106832824
          },
          {
            "accuracy": 0.6536731634182908,
            "ap": 0.15672838059069713,
            "ap_weighted": 0.15672838059069713,
            "f1": 0.5291620828749543,
            "f1_weighted": 0.7208292855772336
          },
          {
            "accuracy": 0.6341829085457271,
            "ap": 0.13702512831261596,
            "ap_weighted": 0.13702512831261596,
            "f1": 0.5047351251338982,
            "f1_weighted": 0.7051704026747947
          },
          {
            "accuracy": 0.631184407796102,
            "ap": 0.16925591865100525,
            "ap_weighted": 0.16925591865100525,
            "f1": 0.526175810657449,
            "f1_weighted": 0.7027507765466487
          },
          {
            "accuracy": 0.6401799100449775,
            "ap": 0.15800883260380166,
            "ap_weighted": 0.15800883260380166,
            "f1": 0.5235558306968382,
            "f1_weighted": 0.7101543576538609
          },
          {
            "accuracy": 0.638680659670165,
            "ap": 0.16172607483769544,
            "ap_weighted": 0.16172607483769544,
            "f1": 0.5252781198595446,
            "f1_weighted": 0.7089484910865615
          },
          {
            "accuracy": 0.5832083958020989,
            "ap": 0.1422709149611044,
            "ap_weighted": 0.1422709149611044,
            "f1": 0.48439068474104974,
            "f1_weighted": 0.6630747650158236
          },
          {
            "accuracy": 0.7316341829085458,
            "ap": 0.16244656089221576,
            "ap_weighted": 0.16244656089221576,
            "f1": 0.5686497657060071,
            "f1_weighted": 0.7785418932253739
          }
        ]
      },
      {
        "accuracy": 0.6710447761194029,
        "ap": 0.3010710976924313,
        "ap_weighted": 0.3010710976924313,
        "f1": 0.6126497765749521,
        "f1_weighted": 0.7037195297787188,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6710447761194029,
        "scores_per_experiment": [
          {
            "accuracy": 0.6432835820895523,
            "ap": 0.28857549872597477,
            "ap_weighted": 0.28857549872597477,
            "f1": 0.5922654437770383,
            "f1_weighted": 0.6800941375808598
          },
          {
            "accuracy": 0.7208955223880597,
            "ap": 0.33378471633639656,
            "ap_weighted": 0.33378471633639656,
            "f1": 0.6548969703980982,
            "f1_weighted": 0.7467993909165429
          },
          {
            "accuracy": 0.7014925373134329,
            "ap": 0.30142980261972896,
            "ap_weighted": 0.30142980261972896,
            "f1": 0.6278770105749578,
            "f1_weighted": 0.7286660538947491
          },
          {
            "accuracy": 0.6119402985074627,
            "ap": 0.2646328754248415,
            "ap_weighted": 0.2646328754248415,
            "f1": 0.5621179214929215,
            "f1_weighted": 0.6520627437138631
          },
          {
            "accuracy": 0.7104477611940299,
            "ap": 0.3094633124838653,
            "ap_weighted": 0.3094633124838653,
            "f1": 0.6366188047951333,
            "f1_weighted": 0.7363612359565566
          },
          {
            "accuracy": 0.655223880597015,
            "ap": 0.28942659476156113,
            "ap_weighted": 0.28942659476156113,
            "f1": 0.5989365092938825,
            "f1_weighted": 0.6904315192208865
          },
          {
            "accuracy": 0.6507462686567164,
            "ap": 0.3096022974910978,
            "ap_weighted": 0.3096022974910978,
            "f1": 0.6067956782135011,
            "f1_weighted": 0.6868485393779291
          },
          {
            "accuracy": 0.6940298507462687,
            "ap": 0.31874786373476127,
            "ap_weighted": 0.31874786373476127,
            "f1": 0.6341810956722305,
            "f1_weighted": 0.7242854944552842
          },
          {
            "accuracy": 0.6671641791044776,
            "ap": 0.3018806304781011,
            "ap_weighted": 0.3018806304781011,
            "f1": 0.6118121753951118,
            "f1_weighted": 0.70107548572484
          },
          {
            "accuracy": 0.655223880597015,
            "ap": 0.29316738486798466,
            "ap_weighted": 0.29316738486798466,
            "f1": 0.6009961561366467,
            "f1_weighted": 0.6905706969456761
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}