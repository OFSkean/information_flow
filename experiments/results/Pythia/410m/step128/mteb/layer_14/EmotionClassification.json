{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "evaluation_time": 14.622710704803467,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.1884,
        "f1": 0.1684219768004404,
        "f1_weighted": 0.20622716074092332,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.1884,
        "scores_per_experiment": [
          {
            "accuracy": 0.1925,
            "f1": 0.17065820500690607,
            "f1_weighted": 0.21457950324045208
          },
          {
            "accuracy": 0.1605,
            "f1": 0.14546353871611897,
            "f1_weighted": 0.18107154473332582
          },
          {
            "accuracy": 0.171,
            "f1": 0.15508864160889865,
            "f1_weighted": 0.1885801351417285
          },
          {
            "accuracy": 0.192,
            "f1": 0.17038189639584064,
            "f1_weighted": 0.21185807830385864
          },
          {
            "accuracy": 0.164,
            "f1": 0.15461820537564558,
            "f1_weighted": 0.1760260229739224
          },
          {
            "accuracy": 0.2025,
            "f1": 0.17545914833810058,
            "f1_weighted": 0.2216956706280463
          },
          {
            "accuracy": 0.184,
            "f1": 0.17239072951272394,
            "f1_weighted": 0.19550798392734373
          },
          {
            "accuracy": 0.222,
            "f1": 0.1835496619282001,
            "f1_weighted": 0.24309503776621813
          },
          {
            "accuracy": 0.198,
            "f1": 0.17903120181986584,
            "f1_weighted": 0.21256881815854284
          },
          {
            "accuracy": 0.1975,
            "f1": 0.17757853930210385,
            "f1_weighted": 0.2172888125357948
          }
        ]
      }
    ]
  },
  "task_name": "EmotionClassification"
}