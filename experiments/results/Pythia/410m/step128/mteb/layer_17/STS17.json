{
  "dataset_revision": "faeb762787bd10488a50c8b5be4a3b82e411949c",
  "evaluation_time": 18.529252290725708,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.026842505389750002,
        "cosine_spearman": 0.036244750800759534,
        "euclidean_pearson": -0.055508953559826955,
        "euclidean_spearman": -0.04743222802321479,
        "hf_subset": "fr-en",
        "languages": [
          "fra-Latn",
          "eng-Latn"
        ],
        "main_score": 0.036244750800759534,
        "manhattan_pearson": -0.05185333239975045,
        "manhattan_spearman": -0.044009176735901566,
        "pearson": 0.026842505389750002,
        "spearman": 0.036244750800759534
      },
      {
        "cosine_pearson": 0.15938880916993556,
        "cosine_spearman": 0.1482430582007822,
        "euclidean_pearson": 0.13498948141253722,
        "euclidean_spearman": 0.12450219664652301,
        "hf_subset": "en-ar",
        "languages": [
          "eng-Latn",
          "ara-Arab"
        ],
        "main_score": 0.1482430582007822,
        "manhattan_pearson": 0.1247172079820036,
        "manhattan_spearman": 0.11189314334908917,
        "pearson": 0.15938880916993556,
        "spearman": 0.1482430582007822
      },
      {
        "cosine_pearson": 0.05208020792563936,
        "cosine_spearman": 0.04727039707521267,
        "euclidean_pearson": -0.04336136630280104,
        "euclidean_spearman": -0.03843927071084053,
        "hf_subset": "nl-en",
        "languages": [
          "nld-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04727039707521267,
        "manhattan_pearson": -0.03797155527395508,
        "manhattan_spearman": -0.031758458653175864,
        "pearson": 0.05208020792563936,
        "spearman": 0.04727039707521267
      },
      {
        "cosine_pearson": 0.07107273498754446,
        "cosine_spearman": 0.08974825055338143,
        "euclidean_pearson": 0.017422941174311837,
        "euclidean_spearman": 0.02740266964663977,
        "hf_subset": "es-en",
        "languages": [
          "spa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08974825055338143,
        "manhattan_pearson": 0.019063129942446293,
        "manhattan_spearman": 0.02612827885696776,
        "pearson": 0.07107273498754446,
        "spearman": 0.08974825055338143
      },
      {
        "cosine_pearson": 0.020894873657101073,
        "cosine_spearman": 0.005186126943353897,
        "euclidean_pearson": -0.09611172176196753,
        "euclidean_spearman": -0.07051041121679379,
        "hf_subset": "en-tr",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ],
        "main_score": 0.005186126943353897,
        "manhattan_pearson": -0.09741199227812967,
        "manhattan_spearman": -0.07137124139146717,
        "pearson": 0.020894873657101073,
        "spearman": 0.005186126943353897
      },
      {
        "cosine_pearson": 0.2757259967371167,
        "cosine_spearman": 0.31910487489125594,
        "euclidean_pearson": 0.28019045002675513,
        "euclidean_spearman": 0.28472752253561356,
        "hf_subset": "en-en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.31910487489125594,
        "manhattan_pearson": 0.27966473436863654,
        "manhattan_spearman": 0.28348361529633836,
        "pearson": 0.2757259967371167,
        "spearman": 0.31910487489125594
      },
      {
        "cosine_pearson": 0.08670420765686972,
        "cosine_spearman": 0.07576033185460702,
        "euclidean_pearson": -0.008256286901097986,
        "euclidean_spearman": -0.0053261986116801795,
        "hf_subset": "it-en",
        "languages": [
          "ita-Latn",
          "eng-Latn"
        ],
        "main_score": 0.07576033185460702,
        "manhattan_pearson": -0.0056831114651749795,
        "manhattan_spearman": -0.005075187663828913,
        "pearson": 0.08670420765686972,
        "spearman": 0.07576033185460702
      },
      {
        "cosine_pearson": 0.1283107407615452,
        "cosine_spearman": 0.12885664305789596,
        "euclidean_pearson": 0.06998493244492639,
        "euclidean_spearman": 0.08837353588499544,
        "hf_subset": "en-de",
        "languages": [
          "eng-Latn",
          "deu-Latn"
        ],
        "main_score": 0.12885664305789596,
        "manhattan_pearson": 0.07153329055205447,
        "manhattan_spearman": 0.08861954967768275,
        "pearson": 0.1283107407615452,
        "spearman": 0.12885664305789596
      }
    ]
  },
  "task_name": "STS17"
}