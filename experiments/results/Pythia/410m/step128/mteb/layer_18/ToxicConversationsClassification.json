{
  "dataset_revision": "edfaf9da55d3dd50d43143d90c1ac476895ae6de",
  "evaluation_time": 44.46957492828369,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.5583984375,
        "ap": 0.08042043763829676,
        "ap_weighted": 0.08042043763829676,
        "f1": 0.41694246805198676,
        "f1_weighted": 0.6523623648319117,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5583984375,
        "scores_per_experiment": [
          {
            "accuracy": 0.37353515625,
            "ap": 0.08065075552023114,
            "ap_weighted": 0.08065075552023114,
            "f1": 0.32541208879372646,
            "f1_weighted": 0.47708332882044596
          },
          {
            "accuracy": 0.6044921875,
            "ap": 0.07873987268518517,
            "ap_weighted": 0.07873987268518517,
            "f1": 0.43659446131273816,
            "f1_weighted": 0.6954993628752063
          },
          {
            "accuracy": 0.67578125,
            "ap": 0.07987742734053498,
            "ap_weighted": 0.07987742734053498,
            "f1": 0.46472437795905386,
            "f1_weighted": 0.7476653168382073
          },
          {
            "accuracy": 0.58935546875,
            "ap": 0.07960091649546383,
            "ap_weighted": 0.07960091649546383,
            "f1": 0.4323812976313079,
            "f1_weighted": 0.683656572476828
          },
          {
            "accuracy": 0.57568359375,
            "ap": 0.08063251677124783,
            "ap_weighted": 0.08063251677124783,
            "f1": 0.4286240807144511,
            "f1_weighted": 0.6726381331430231
          },
          {
            "accuracy": 0.4384765625,
            "ap": 0.08177352313448567,
            "ap_weighted": 0.08177352313448567,
            "f1": 0.36419905061787583,
            "f1_weighted": 0.5471339513104215
          },
          {
            "accuracy": 0.67578125,
            "ap": 0.07903120695324799,
            "ap_weighted": 0.07903120695324799,
            "f1": 0.46254452210177516,
            "f1_weighted": 0.7475213584556818
          },
          {
            "accuracy": 0.580078125,
            "ap": 0.08056432956206805,
            "ap_weighted": 0.08056432956206805,
            "f1": 0.4303390512464567,
            "f1_weighted": 0.6761963494856077
          },
          {
            "accuracy": 0.56494140625,
            "ap": 0.08246247238950546,
            "ap_weighted": 0.08246247238950546,
            "f1": 0.42694468669359686,
            "f1_weighted": 0.6636674175545312
          },
          {
            "accuracy": 0.505859375,
            "ap": 0.0808713555309976,
            "ap_weighted": 0.0808713555309976,
            "f1": 0.39766106344888513,
            "f1_weighted": 0.6125618573591639
          }
        ]
      }
    ]
  },
  "task_name": "ToxicConversationsClassification"
}