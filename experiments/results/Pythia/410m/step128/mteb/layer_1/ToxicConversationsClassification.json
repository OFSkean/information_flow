{
  "dataset_revision": "edfaf9da55d3dd50d43143d90c1ac476895ae6de",
  "evaluation_time": 20.25600576400757,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.58701171875,
        "ap": 0.08192656643133986,
        "ap_weighted": 0.08192656643133986,
        "f1": 0.4297958186083754,
        "f1_weighted": 0.6722578320114735,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.58701171875,
        "scores_per_experiment": [
          {
            "accuracy": 0.43798828125,
            "ap": 0.08127865030994427,
            "ap_weighted": 0.08127865030994427,
            "f1": 0.363405414616586,
            "f1_weighted": 0.5468303248533989
          },
          {
            "accuracy": 0.66943359375,
            "ap": 0.08114456635119083,
            "ap_weighted": 0.08114456635119083,
            "f1": 0.46551512116631766,
            "f1_weighted": 0.7434245652250279
          },
          {
            "accuracy": 0.69189453125,
            "ap": 0.08507627152127026,
            "ap_weighted": 0.08507627152127026,
            "f1": 0.48127528068915604,
            "f1_weighted": 0.7595186431158956
          },
          {
            "accuracy": 0.60888671875,
            "ap": 0.08081629602970528,
            "ap_weighted": 0.08081629602970528,
            "f1": 0.44243090835489646,
            "f1_weighted": 0.6988829343791669
          },
          {
            "accuracy": 0.54052734375,
            "ap": 0.08259010112247608,
            "ap_weighted": 0.08259010112247608,
            "f1": 0.41623594976371286,
            "f1_weighted": 0.6429855404857862
          },
          {
            "accuracy": 0.33544921875,
            "ap": 0.08273746546920649,
            "ap_weighted": 0.08273746546920649,
            "f1": 0.30251916845645666,
            "f1_weighted": 0.43009536330155507
          },
          {
            "accuracy": 0.72998046875,
            "ap": 0.08548454945924537,
            "ap_weighted": 0.08548454945924537,
            "f1": 0.49500756901852455,
            "f1_weighted": 0.7849812835046116
          },
          {
            "accuracy": 0.5625,
            "ap": 0.08039178174829156,
            "ap_weighted": 0.08039178174829156,
            "f1": 0.42263391059202576,
            "f1_weighted": 0.6618493254128072
          },
          {
            "accuracy": 0.63623046875,
            "ap": 0.08094582798108081,
            "ap_weighted": 0.08094582798108081,
            "f1": 0.4531481008243852,
            "f1_weighted": 0.7195059086756593
          },
          {
            "accuracy": 0.6572265625,
            "ap": 0.07880015432098765,
            "ap_weighted": 0.07880015432098765,
            "f1": 0.45578676260169243,
            "f1_weighted": 0.7345044311608273
          }
        ]
      }
    ]
  },
  "task_name": "ToxicConversationsClassification"
}