{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 21.493168354034424,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.6757121439280359,
        "ap": 0.17620129055959252,
        "ap_weighted": 0.17620129055959252,
        "f1": 0.5517810717589786,
        "f1_weighted": 0.7369218915525257,
        "hf_subset": "en-ext",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6757121439280359,
        "scores_per_experiment": [
          {
            "accuracy": 0.7188905547226386,
            "ap": 0.18890436829435375,
            "ap_weighted": 0.18890436829435375,
            "f1": 0.5811462651476014,
            "f1_weighted": 0.7712874021296136
          },
          {
            "accuracy": 0.664167916041979,
            "ap": 0.18147731092017577,
            "ap_weighted": 0.18147731092017577,
            "f1": 0.5499664149545321,
            "f1_weighted": 0.7294259166633772
          },
          {
            "accuracy": 0.7338830584707646,
            "ap": 0.19108052284848387,
            "ap_weighted": 0.19108052284848387,
            "f1": 0.5895829270934894,
            "f1_weighted": 0.7822263388942512
          },
          {
            "accuracy": 0.6469265367316341,
            "ap": 0.15597995136355453,
            "ap_weighted": 0.15597995136355453,
            "f1": 0.5254178654325641,
            "f1_weighted": 0.7155114311982202
          },
          {
            "accuracy": 0.5884557721139431,
            "ap": 0.15214780330725886,
            "ap_weighted": 0.15214780330725886,
            "f1": 0.4937423399397357,
            "f1_weighted": 0.6670826941441776
          },
          {
            "accuracy": 0.6701649175412294,
            "ap": 0.18230981904815188,
            "ap_weighted": 0.18230981904815188,
            "f1": 0.5534497029895802,
            "f1_weighted": 0.7341700351985853
          },
          {
            "accuracy": 0.6656671664167916,
            "ap": 0.18529793684863632,
            "ap_weighted": 0.18529793684863632,
            "f1": 0.5528791813962437,
            "f1_weighted": 0.7306465130107191
          },
          {
            "accuracy": 0.7233883058470765,
            "ap": 0.19292600634529222,
            "ap_weighted": 0.19292600634529222,
            "f1": 0.5857195157360534,
            "f1_weighted": 0.7747679453293437
          },
          {
            "accuracy": 0.5794602698650675,
            "ap": 0.14371209034610102,
            "ap_weighted": 0.14371209034610102,
            "f1": 0.48349921424829756,
            "f1_weighted": 0.6597337789984002
          },
          {
            "accuracy": 0.7661169415292354,
            "ap": 0.1881770962739169,
            "ap_weighted": 0.1881770962739169,
            "f1": 0.602407290651688,
            "f1_weighted": 0.8043668599585688
          }
        ]
      },
      {
        "accuracy": 0.7037313432835821,
        "ap": 0.325976139087278,
        "ap_weighted": 0.325976139087278,
        "f1": 0.6416114104087348,
        "f1_weighted": 0.7319347395930766,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7037313432835821,
        "scores_per_experiment": [
          {
            "accuracy": 0.664179104477612,
            "ap": 0.30979313688231824,
            "ap_weighted": 0.30979313688231824,
            "f1": 0.6142715681683848,
            "f1_weighted": 0.6987623350321385
          },
          {
            "accuracy": 0.7208955223880597,
            "ap": 0.3380439785803806,
            "ap_weighted": 0.3380439785803806,
            "f1": 0.6570957827351873,
            "f1_weighted": 0.7471660034215954
          },
          {
            "accuracy": 0.7388059701492538,
            "ap": 0.32637948163157954,
            "ap_weighted": 0.32637948163157954,
            "f1": 0.6584371131017406,
            "f1_weighted": 0.7593309397952341
          },
          {
            "accuracy": 0.655223880597015,
            "ap": 0.29316738486798466,
            "ap_weighted": 0.29316738486798466,
            "f1": 0.6009961561366467,
            "f1_weighted": 0.6905706969456761
          },
          {
            "accuracy": 0.7343283582089553,
            "ap": 0.3206729533585401,
            "ap_weighted": 0.3206729533585401,
            "f1": 0.6532373431339482,
            "f1_weighted": 0.755351954709883
          },
          {
            "accuracy": 0.6716417910447762,
            "ap": 0.2967996934135706,
            "ap_weighted": 0.2967996934135706,
            "f1": 0.6112910201369184,
            "f1_weighted": 0.7045603933581531
          },
          {
            "accuracy": 0.7074626865671642,
            "ap": 0.34695600455572057,
            "ap_weighted": 0.34695600455572057,
            "f1": 0.6546537069763528,
            "f1_weighted": 0.7368905912246393
          },
          {
            "accuracy": 0.7761194029850746,
            "ap": 0.3971300968130918,
            "ap_weighted": 0.3971300968130918,
            "f1": 0.711020887007729,
            "f1_weighted": 0.7945435112805497
          },
          {
            "accuracy": 0.6835820895522388,
            "ap": 0.3199359392179447,
            "ap_weighted": 0.3199359392179447,
            "f1": 0.6294905103243915,
            "f1_weighted": 0.7156989647187733
          },
          {
            "accuracy": 0.6850746268656717,
            "ap": 0.31088272155164903,
            "ap_weighted": 0.31088272155164903,
            "f1": 0.6256200163660487,
            "f1_weighted": 0.7164720054441243
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}