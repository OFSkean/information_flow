{
  "dataset_revision": "edfaf9da55d3dd50d43143d90c1ac476895ae6de",
  "evaluation_time": 27.921321868896484,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.565283203125,
        "ap": 0.08043839941920242,
        "ap_weighted": 0.08043839941920242,
        "f1": 0.42079869652087415,
        "f1_weighted": 0.6596917153019307,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.565283203125,
        "scores_per_experiment": [
          {
            "accuracy": 0.451171875,
            "ap": 0.07893908712784589,
            "ap_weighted": 0.07893908712784589,
            "f1": 0.36772900662717317,
            "f1_weighted": 0.561083180114745
          },
          {
            "accuracy": 0.63427734375,
            "ap": 0.07987945358317483,
            "ap_weighted": 0.07987945358317483,
            "f1": 0.4502119832449189,
            "f1_weighted": 0.7179999001316362
          },
          {
            "accuracy": 0.64599609375,
            "ap": 0.08043636759830819,
            "ap_weighted": 0.08043636759830819,
            "f1": 0.45567517650780875,
            "f1_weighted": 0.7266192403604412
          },
          {
            "accuracy": 0.5693359375,
            "ap": 0.07883388097858299,
            "ap_weighted": 0.07883388097858299,
            "f1": 0.42276306370794564,
            "f1_weighted": 0.6676192986086257
          },
          {
            "accuracy": 0.58154296875,
            "ap": 0.08161075498132292,
            "ap_weighted": 0.08161075498132292,
            "f1": 0.4327113681327436,
            "f1_weighted": 0.6773116345428006
          },
          {
            "accuracy": 0.41650390625,
            "ap": 0.08550438004924746,
            "ap_weighted": 0.08550438004924746,
            "f1": 0.35530352781757696,
            "f1_weighted": 0.5225134365616297
          },
          {
            "accuracy": 0.68359375,
            "ap": 0.07923877101221753,
            "ap_weighted": 0.07923877101221753,
            "f1": 0.4656186579905292,
            "f1_weighted": 0.7529191615259478
          },
          {
            "accuracy": 0.541015625,
            "ap": 0.07787058260375482,
            "ap_weighted": 0.07787058260375482,
            "f1": 0.40897927104823656,
            "f1_weighted": 0.6441349262267905
          },
          {
            "accuracy": 0.58447265625,
            "ap": 0.08140789861911571,
            "ap_weighted": 0.08140789861911571,
            "f1": 0.4335986844564039,
            "f1_weighted": 0.679678842802818
          },
          {
            "accuracy": 0.544921875,
            "ap": 0.0806628176384537,
            "ap_weighted": 0.0806628176384537,
            "f1": 0.41539622567540413,
            "f1_weighted": 0.6470375321438723
          }
        ]
      }
    ]
  },
  "task_name": "ToxicConversationsClassification"
}