{
  "dataset_revision": "faeb762787bd10488a50c8b5be4a3b82e411949c",
  "evaluation_time": 18.755056381225586,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.020103525037676893,
        "cosine_spearman": 0.0042721832686355024,
        "euclidean_pearson": -0.13594478774572963,
        "euclidean_spearman": -0.14434974604893017,
        "hf_subset": "nl-en",
        "languages": [
          "nld-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0042721832686355024,
        "manhattan_pearson": -0.1273621759889529,
        "manhattan_spearman": -0.13792071373221892,
        "pearson": 0.020103525037676893,
        "spearman": 0.0042721832686355024
      },
      {
        "cosine_pearson": 0.3398528610678227,
        "cosine_spearman": 0.38717035658646537,
        "euclidean_pearson": 0.3165067234347188,
        "euclidean_spearman": 0.3256711367767006,
        "hf_subset": "en-en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.38717035658646537,
        "manhattan_pearson": 0.3163902879610782,
        "manhattan_spearman": 0.3246763185025213,
        "pearson": 0.3398528610678227,
        "spearman": 0.38717035658646537
      },
      {
        "cosine_pearson": 0.06854151081736805,
        "cosine_spearman": 0.06749734359272212,
        "euclidean_pearson": -0.13228698949546397,
        "euclidean_spearman": -0.1253417209948761,
        "hf_subset": "fr-en",
        "languages": [
          "fra-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06749734359272212,
        "manhattan_pearson": -0.12987051468013736,
        "manhattan_spearman": -0.1227712612578448,
        "pearson": 0.06854151081736805,
        "spearman": 0.06749734359272212
      },
      {
        "cosine_pearson": 0.11901928642967921,
        "cosine_spearman": 0.11181941912119787,
        "euclidean_pearson": -0.07549446317529143,
        "euclidean_spearman": -0.07056867203580271,
        "hf_subset": "it-en",
        "languages": [
          "ita-Latn",
          "eng-Latn"
        ],
        "main_score": 0.11181941912119787,
        "manhattan_pearson": -0.061796891994906296,
        "manhattan_spearman": -0.05690837180028896,
        "pearson": 0.11901928642967921,
        "spearman": 0.11181941912119787
      },
      {
        "cosine_pearson": 0.04059012803748979,
        "cosine_spearman": 0.04489059802751405,
        "euclidean_pearson": -0.11250461561830978,
        "euclidean_spearman": -0.08352437339319799,
        "hf_subset": "en-de",
        "languages": [
          "eng-Latn",
          "deu-Latn"
        ],
        "main_score": 0.04489059802751405,
        "manhattan_pearson": -0.10789244067267446,
        "manhattan_spearman": -0.0799975350370948,
        "pearson": 0.04059012803748979,
        "spearman": 0.04489059802751405
      },
      {
        "cosine_pearson": 0.10817040642772897,
        "cosine_spearman": 0.10762278272731506,
        "euclidean_pearson": -0.02405433842988676,
        "euclidean_spearman": -0.05004376936239641,
        "hf_subset": "es-en",
        "languages": [
          "spa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.10762278272731506,
        "manhattan_pearson": -0.022225829523179797,
        "manhattan_spearman": -0.048445302724853055,
        "pearson": 0.10817040642772897,
        "spearman": 0.10762278272731506
      },
      {
        "cosine_pearson": 0.11407139407894104,
        "cosine_spearman": 0.10641199918202288,
        "euclidean_pearson": 0.006002003323350685,
        "euclidean_spearman": -0.032726955052646826,
        "hf_subset": "en-ar",
        "languages": [
          "eng-Latn",
          "ara-Arab"
        ],
        "main_score": 0.10641199918202288,
        "manhattan_pearson": -0.0037685922591607995,
        "manhattan_spearman": -0.04080855789775532,
        "pearson": 0.11407139407894104,
        "spearman": 0.10641199918202288
      },
      {
        "cosine_pearson": 0.05285742121491458,
        "cosine_spearman": 0.04723839224717325,
        "euclidean_pearson": -0.1421193687851223,
        "euclidean_spearman": -0.11673072472232562,
        "hf_subset": "en-tr",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ],
        "main_score": 0.04723839224717325,
        "manhattan_pearson": -0.1455801434420193,
        "manhattan_spearman": -0.11343196505341197,
        "pearson": 0.05285742121491458,
        "spearman": 0.04723839224717325
      }
    ]
  },
  "task_name": "STS17"
}