{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 23.777660131454468,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.7227136431784108,
        "ap": 0.21135898218871335,
        "ap_weighted": 0.21135898218871335,
        "f1": 0.5953784137616547,
        "f1_weighted": 0.7744188683790036,
        "hf_subset": "en-ext",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7227136431784108,
        "scores_per_experiment": [
          {
            "accuracy": 0.7391304347826086,
            "ap": 0.21870882508641082,
            "ap_weighted": 0.21870882508641082,
            "f1": 0.6077703764536505,
            "f1_weighted": 0.7874546013181323
          },
          {
            "accuracy": 0.7278860569715142,
            "ap": 0.21204030388471873,
            "ap_weighted": 0.21204030388471873,
            "f1": 0.5986413671864316,
            "f1_weighted": 0.7789351484454108
          },
          {
            "accuracy": 0.7556221889055472,
            "ap": 0.21916559705758631,
            "ap_weighted": 0.21916559705758631,
            "f1": 0.6162133540427485,
            "f1_weighted": 0.7993174953550811
          },
          {
            "accuracy": 0.7218890554722639,
            "ap": 0.20866716849659822,
            "ap_weighted": 0.20866716849659822,
            "f1": 0.5938517342261941,
            "f1_weighted": 0.7743689721912803
          },
          {
            "accuracy": 0.6686656671664168,
            "ap": 0.18492175087654744,
            "ap_weighted": 0.18492175087654744,
            "f1": 0.5541834898456048,
            "f1_weighted": 0.7330195538260449
          },
          {
            "accuracy": 0.7436281859070465,
            "ap": 0.22753194299324647,
            "ap_weighted": 0.22753194299324647,
            "f1": 0.6145329561699668,
            "f1_weighted": 0.7911191771574747
          },
          {
            "accuracy": 0.6956521739130435,
            "ap": 0.19005361764403675,
            "ap_weighted": 0.19005361764403675,
            "f1": 0.5705495592932198,
            "f1_weighted": 0.7540333940689611
          },
          {
            "accuracy": 0.7623688155922039,
            "ap": 0.24045862719918012,
            "ap_weighted": 0.24045862719918012,
            "f1": 0.6304634870367117,
            "f1_weighted": 0.8052339098153813
          },
          {
            "accuracy": 0.6289355322338831,
            "ap": 0.17286822715740452,
            "ap_weighted": 0.17286822715740452,
            "f1": 0.5271180432470755,
            "f1_weighted": 0.7008163766397553
          },
          {
            "accuracy": 0.7833583208395802,
            "ap": 0.23917376149140404,
            "ap_weighted": 0.23917376149140404,
            "f1": 0.6404597701149425,
            "f1_weighted": 0.8198900549725135
          }
        ]
      },
      {
        "accuracy": 0.7150746268656716,
        "ap": 0.34254555276458476,
        "ap_weighted": 0.34254555276458476,
        "f1": 0.655341874180557,
        "f1_weighted": 0.7419529356489946,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7150746268656716,
        "scores_per_experiment": [
          {
            "accuracy": 0.6402985074626866,
            "ap": 0.29993651216766515,
            "ap_weighted": 0.29993651216766515,
            "f1": 0.596384533281341,
            "f1_weighted": 0.6774564856161328
          },
          {
            "accuracy": 0.7567164179104477,
            "ap": 0.3820630314333777,
            "ap_weighted": 0.3820630314333777,
            "f1": 0.6951987027594272,
            "f1_weighted": 0.7785848415687839
          },
          {
            "accuracy": 0.7044776119402985,
            "ap": 0.3363457493524462,
            "ap_weighted": 0.3363457493524462,
            "f1": 0.64818763326226,
            "f1_weighted": 0.7338828246825574
          },
          {
            "accuracy": 0.673134328358209,
            "ap": 0.3034928953921776,
            "ap_weighted": 0.3034928953921776,
            "f1": 0.6157079663400721,
            "f1_weighted": 0.7061711157740482
          },
          {
            "accuracy": 0.7686567164179104,
            "ap": 0.377938551517223,
            "ap_weighted": 0.377938551517223,
            "f1": 0.6986107362488427,
            "f1_weighted": 0.787089869093981
          },
          {
            "accuracy": 0.7597014925373134,
            "ap": 0.3533868020438033,
            "ap_weighted": 0.3533868020438033,
            "f1": 0.6821172927367618,
            "f1_weighted": 0.7777497807084387
          },
          {
            "accuracy": 0.7686567164179104,
            "ap": 0.377938551517223,
            "ap_weighted": 0.377938551517223,
            "f1": 0.6986107362488427,
            "f1_weighted": 0.787089869093981
          },
          {
            "accuracy": 0.7149253731343284,
            "ap": 0.348376438418594,
            "ap_weighted": 0.348376438418594,
            "f1": 0.659163850114127,
            "f1_weighted": 0.7431147777607771
          },
          {
            "accuracy": 0.673134328358209,
            "ap": 0.33324892405737877,
            "ap_weighted": 0.33324892405737877,
            "f1": 0.6298986780474147,
            "f1_weighted": 0.706929880347869
          },
          {
            "accuracy": 0.691044776119403,
            "ap": 0.3127280717459594,
            "ap_weighted": 0.3127280717459594,
            "f1": 0.6295386127664804,
            "f1_weighted": 0.7214599118433758
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}