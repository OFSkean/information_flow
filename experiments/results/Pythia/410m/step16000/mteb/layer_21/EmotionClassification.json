{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "evaluation_time": 17.154944896697998,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.3163,
        "f1": 0.2844214409170637,
        "f1_weighted": 0.3366578907641593,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.3163,
        "scores_per_experiment": [
          {
            "accuracy": 0.286,
            "f1": 0.2581047432211002,
            "f1_weighted": 0.29604562721746247
          },
          {
            "accuracy": 0.296,
            "f1": 0.2696249278557834,
            "f1_weighted": 0.3189478729235118
          },
          {
            "accuracy": 0.3135,
            "f1": 0.2766595140788915,
            "f1_weighted": 0.33396800194578086
          },
          {
            "accuracy": 0.3175,
            "f1": 0.2882178119167675,
            "f1_weighted": 0.3332425154162197
          },
          {
            "accuracy": 0.306,
            "f1": 0.2823768662618837,
            "f1_weighted": 0.3310343187010434
          },
          {
            "accuracy": 0.332,
            "f1": 0.3017105940899614,
            "f1_weighted": 0.35199899688872316
          },
          {
            "accuracy": 0.3485,
            "f1": 0.30005321005380264,
            "f1_weighted": 0.37274821208539266
          },
          {
            "accuracy": 0.3355,
            "f1": 0.3043768098516902,
            "f1_weighted": 0.3585393386249735
          },
          {
            "accuracy": 0.331,
            "f1": 0.2994106698004012,
            "f1_weighted": 0.3599861028417448
          },
          {
            "accuracy": 0.297,
            "f1": 0.2636792620403547,
            "f1_weighted": 0.31006792099674085
          }
        ]
      }
    ]
  },
  "task_name": "EmotionClassification"
}