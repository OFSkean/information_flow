{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "evaluation_time": 12.569233417510986,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.31625000000000003,
        "f1": 0.2830789034225051,
        "f1_weighted": 0.33958821324669153,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.31625000000000003,
        "scores_per_experiment": [
          {
            "accuracy": 0.353,
            "f1": 0.31350887365134955,
            "f1_weighted": 0.38070818255456423
          },
          {
            "accuracy": 0.316,
            "f1": 0.27342378256339006,
            "f1_weighted": 0.338654806743426
          },
          {
            "accuracy": 0.3265,
            "f1": 0.2929894375698111,
            "f1_weighted": 0.34817179883319993
          },
          {
            "accuracy": 0.352,
            "f1": 0.30294073689134976,
            "f1_weighted": 0.3783242824853542
          },
          {
            "accuracy": 0.303,
            "f1": 0.26975475854230074,
            "f1_weighted": 0.3337649643288423
          },
          {
            "accuracy": 0.337,
            "f1": 0.3022160869191446,
            "f1_weighted": 0.3606663654458135
          },
          {
            "accuracy": 0.311,
            "f1": 0.281900133187669,
            "f1_weighted": 0.3395765272379871
          },
          {
            "accuracy": 0.319,
            "f1": 0.2917817973109416,
            "f1_weighted": 0.3330832916752513
          },
          {
            "accuracy": 0.2575,
            "f1": 0.24306227138132686,
            "f1_weighted": 0.2763165346185389
          },
          {
            "accuracy": 0.2875,
            "f1": 0.25921115620776775,
            "f1_weighted": 0.3066153785439377
          }
        ]
      }
    ]
  },
  "task_name": "EmotionClassification"
}