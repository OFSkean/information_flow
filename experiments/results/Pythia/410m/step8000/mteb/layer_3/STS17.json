{
  "dataset_revision": "faeb762787bd10488a50c8b5be4a3b82e411949c",
  "evaluation_time": 17.73432183265686,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.024268701202928306,
        "cosine_spearman": 0.004888401036018108,
        "euclidean_pearson": -0.15893757090890046,
        "euclidean_spearman": -0.17648753747447116,
        "hf_subset": "en-ar",
        "languages": [
          "eng-Latn",
          "ara-Arab"
        ],
        "main_score": 0.004888401036018108,
        "manhattan_pearson": -0.15966777424433432,
        "manhattan_spearman": -0.18050143097278848,
        "pearson": 0.024268701202928306,
        "spearman": 0.004888401036018108
      },
      {
        "cosine_pearson": -0.04300764450609682,
        "cosine_spearman": 0.007279955050219145,
        "euclidean_pearson": -0.19712279770488245,
        "euclidean_spearman": -0.1624204684908993,
        "hf_subset": "en-tr",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ],
        "main_score": 0.007279955050219145,
        "manhattan_pearson": -0.19044308044187064,
        "manhattan_spearman": -0.1518809697958025,
        "pearson": -0.04300764450609682,
        "spearman": 0.007279955050219145
      },
      {
        "cosine_pearson": 0.029224367922739847,
        "cosine_spearman": 0.05777249524710312,
        "euclidean_pearson": -0.042625539301535814,
        "euclidean_spearman": -0.007268169987705603,
        "hf_subset": "it-en",
        "languages": [
          "ita-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05777249524710312,
        "manhattan_pearson": -0.07760746168419515,
        "manhattan_spearman": -0.04081176622406873,
        "pearson": 0.029224367922739847,
        "spearman": 0.05777249524710312
      },
      {
        "cosine_pearson": 0.07949182925402838,
        "cosine_spearman": 0.0639270684263476,
        "euclidean_pearson": -0.013031202470658436,
        "euclidean_spearman": -0.004900671629641354,
        "hf_subset": "nl-en",
        "languages": [
          "nld-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0639270684263476,
        "manhattan_pearson": -0.03654897130485502,
        "manhattan_spearman": -0.02524216831937084,
        "pearson": 0.07949182925402838,
        "spearman": 0.0639270684263476
      },
      {
        "cosine_pearson": 0.019074160989120306,
        "cosine_spearman": 0.02912418908866632,
        "euclidean_pearson": -0.0634427914305769,
        "euclidean_spearman": -0.050806845345092694,
        "hf_subset": "fr-en",
        "languages": [
          "fra-Latn",
          "eng-Latn"
        ],
        "main_score": 0.02912418908866632,
        "manhattan_pearson": -0.10131225637768744,
        "manhattan_spearman": -0.09263072768813906,
        "pearson": 0.019074160989120306,
        "spearman": 0.02912418908866632
      },
      {
        "cosine_pearson": 0.017344607337561005,
        "cosine_spearman": -0.025264076595977503,
        "euclidean_pearson": -0.05012089992120449,
        "euclidean_spearman": -0.1430466179324787,
        "hf_subset": "es-en",
        "languages": [
          "spa-Latn",
          "eng-Latn"
        ],
        "main_score": -0.025264076595977503,
        "manhattan_pearson": -0.05136691022227352,
        "manhattan_spearman": -0.13084591190176353,
        "pearson": 0.017344607337561005,
        "spearman": -0.025264076595977503
      },
      {
        "cosine_pearson": 0.5254847760857041,
        "cosine_spearman": 0.5621222964629411,
        "euclidean_pearson": 0.5294875805824268,
        "euclidean_spearman": 0.5465019582135014,
        "hf_subset": "en-en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5621222964629411,
        "manhattan_pearson": 0.530161142698825,
        "manhattan_spearman": 0.545709716921738,
        "pearson": 0.5254847760857041,
        "spearman": 0.5621222964629411
      },
      {
        "cosine_pearson": 0.15168537294913953,
        "cosine_spearman": 0.16407543946383923,
        "euclidean_pearson": 0.005636964000880186,
        "euclidean_spearman": 0.011262818946465738,
        "hf_subset": "en-de",
        "languages": [
          "eng-Latn",
          "deu-Latn"
        ],
        "main_score": 0.16407543946383923,
        "manhattan_pearson": -0.021150778408883488,
        "manhattan_spearman": -0.011556113514935138,
        "pearson": 0.15168537294913953,
        "spearman": 0.16407543946383923
      }
    ]
  },
  "task_name": "STS17"
}