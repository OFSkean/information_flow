{
  "dataset_revision": "edfaf9da55d3dd50d43143d90c1ac476895ae6de",
  "evaluation_time": 19.554349184036255,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.574853515625,
        "ap": 0.09275410289403532,
        "ap_weighted": 0.09275410289403532,
        "f1": 0.4414520741464045,
        "f1_weighted": 0.6660516891011269,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.574853515625,
        "scores_per_experiment": [
          {
            "accuracy": 0.49462890625,
            "ap": 0.08950150785656873,
            "ap_weighted": 0.08950150785656873,
            "f1": 0.40173663688539973,
            "f1_weighted": 0.6001830710670241
          },
          {
            "accuracy": 0.55810546875,
            "ap": 0.0937236034629992,
            "ap_weighted": 0.0937236034629992,
            "f1": 0.4372777387639384,
            "f1_weighted": 0.6567793262201769
          },
          {
            "accuracy": 0.64404296875,
            "ap": 0.08895234484880449,
            "ap_weighted": 0.08895234484880449,
            "f1": 0.46938083555373583,
            "f1_weighted": 0.7256510633242544
          },
          {
            "accuracy": 0.66455078125,
            "ap": 0.09040595557179987,
            "ap_weighted": 0.09040595557179987,
            "f1": 0.47956528349010136,
            "f1_weighted": 0.7407569281568215
          },
          {
            "accuracy": 0.587890625,
            "ap": 0.09249925418999425,
            "ap_weighted": 0.09249925418999425,
            "f1": 0.4498037323324085,
            "f1_weighted": 0.6818327800506616
          },
          {
            "accuracy": 0.37060546875,
            "ap": 0.08358067877671944,
            "ap_weighted": 0.08358067877671944,
            "f1": 0.32597435259123086,
            "f1_weighted": 0.4719782316381341
          },
          {
            "accuracy": 0.6005859375,
            "ap": 0.09782778125182845,
            "ap_weighted": 0.09782778125182845,
            "f1": 0.4610769042701719,
            "f1_weighted": 0.6918960724930353
          },
          {
            "accuracy": 0.57373046875,
            "ap": 0.09255612725446583,
            "ap_weighted": 0.09255612725446583,
            "f1": 0.4434060150867484,
            "f1_weighted": 0.6701258517320016
          },
          {
            "accuracy": 0.56591796875,
            "ap": 0.0997271917500165,
            "ap_weighted": 0.0997271917500165,
            "f1": 0.44658793891491627,
            "f1_weighted": 0.6629128300144791
          },
          {
            "accuracy": 0.6884765625,
            "ap": 0.09876658397715657,
            "ap_weighted": 0.09876658397715657,
            "f1": 0.4997113035753942,
            "f1_weighted": 0.7584007363146791
          }
        ]
      }
    ]
  },
  "task_name": "ToxicConversationsClassification"
}