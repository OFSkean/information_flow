{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 25.131129026412964,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.7499250374812594,
        "ap": 0.22414987014705115,
        "ap_weighted": 0.22414987014705115,
        "f1": 0.6153391104710935,
        "f1_weighted": 0.7950956741951603,
        "hf_subset": "en-ext",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7499250374812594,
        "scores_per_experiment": [
          {
            "accuracy": 0.787856071964018,
            "ap": 0.2723864186477146,
            "ap_weighted": 0.2723864186477146,
            "f1": 0.6585102870607816,
            "f1_weighted": 0.824879530492959
          },
          {
            "accuracy": 0.7698650674662668,
            "ap": 0.22263744292495813,
            "ap_weighted": 0.22263744292495813,
            "f1": 0.625073353382495,
            "f1_weighted": 0.8095124970163469
          },
          {
            "accuracy": 0.7773613193403298,
            "ap": 0.24540442125189438,
            "ap_weighted": 0.24540442125189438,
            "f1": 0.6405477274644877,
            "f1_weighted": 0.8160946934679983
          },
          {
            "accuracy": 0.7331334332833583,
            "ap": 0.21316311457391998,
            "ap_weighted": 0.21316311457391998,
            "f1": 0.6018578135479544,
            "f1_weighted": 0.7828330804416705
          },
          {
            "accuracy": 0.7413793103448276,
            "ap": 0.19136593850280173,
            "ap_weighted": 0.19136593850280173,
            "f1": 0.5932678821879382,
            "f1_weighted": 0.7875606376334974
          },
          {
            "accuracy": 0.7518740629685158,
            "ap": 0.24767019165460336,
            "ap_weighted": 0.24767019165460336,
            "f1": 0.6283825466358637,
            "f1_weighted": 0.7979625742656173
          },
          {
            "accuracy": 0.7593703148425787,
            "ap": 0.22369717944558093,
            "ap_weighted": 0.22369717944558093,
            "f1": 0.6204809506632503,
            "f1_weighted": 0.8022246539759774
          },
          {
            "accuracy": 0.7713643178410795,
            "ap": 0.247258197046778,
            "ap_weighted": 0.247258197046778,
            "f1": 0.6383618869853122,
            "f1_weighted": 0.8119719821443855
          },
          {
            "accuracy": 0.658920539730135,
            "ap": 0.18097084145761813,
            "ap_weighted": 0.18097084145761813,
            "f1": 0.5470329189760796,
            "f1_weighted": 0.725243066059462
          },
          {
            "accuracy": 0.7481259370314842,
            "ap": 0.19694495596464218,
            "ap_weighted": 0.19694495596464218,
            "f1": 0.5998757378067723,
            "f1_weighted": 0.7926740264536883
          }
        ]
      },
      {
        "accuracy": 0.7349253731343283,
        "ap": 0.3598400245319311,
        "ap_weighted": 0.3598400245319311,
        "f1": 0.6739782318672101,
        "f1_weighted": 0.7595414035462673,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7349253731343283,
        "scores_per_experiment": [
          {
            "accuracy": 0.7179104477611941,
            "ap": 0.3273020767766722,
            "ap_weighted": 0.3273020767766722,
            "f1": 0.6500725388601037,
            "f1_weighted": 0.7438958162555102
          },
          {
            "accuracy": 0.7656716417910447,
            "ap": 0.38176473819560863,
            "ap_weighted": 0.38176473819560863,
            "f1": 0.6991778079645385,
            "f1_weighted": 0.785303154635061
          },
          {
            "accuracy": 0.7194029850746269,
            "ap": 0.35186411310866095,
            "ap_weighted": 0.35186411310866095,
            "f1": 0.663049991439822,
            "f1_weighted": 0.7469624783120862
          },
          {
            "accuracy": 0.7104477611940299,
            "ap": 0.342849531112281,
            "ap_weighted": 0.342849531112281,
            "f1": 0.6543085106382978,
            "f1_weighted": 0.739141155922515
          },
          {
            "accuracy": 0.7492537313432835,
            "ap": 0.3572253070324471,
            "ap_weighted": 0.3572253070324471,
            "f1": 0.6798234136240029,
            "f1_weighted": 0.7706169060261391
          },
          {
            "accuracy": 0.7432835820895523,
            "ap": 0.35638213027763566,
            "ap_weighted": 0.35638213027763566,
            "f1": 0.6767316345193612,
            "f1_weighted": 0.7660513536267227
          },
          {
            "accuracy": 0.7791044776119403,
            "ap": 0.39574628190487293,
            "ap_weighted": 0.39574628190487293,
            "f1": 0.7116804875495748,
            "f1_weighted": 0.7965847713318127
          },
          {
            "accuracy": 0.7417910447761195,
            "ap": 0.37499450514453037,
            "ap_weighted": 0.37499450514453037,
            "f1": 0.6847487590943089,
            "f1_weighted": 0.766409294386164
          },
          {
            "accuracy": 0.7029850746268657,
            "ap": 0.358407448657941,
            "ap_weighted": 0.358407448657941,
            "f1": 0.6571391835422693,
            "f1_weighted": 0.7334866266545766
          },
          {
            "accuracy": 0.7194029850746269,
            "ap": 0.35186411310866095,
            "ap_weighted": 0.35186411310866095,
            "f1": 0.663049991439822,
            "f1_weighted": 0.7469624783120862
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}