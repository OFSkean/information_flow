{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 33.66622257232666,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.7563718140929536,
        "ap": 0.24663741627685773,
        "ap_weighted": 0.24663741627685773,
        "f1": 0.6299649000427616,
        "f1_weighted": 0.800698638349455,
        "hf_subset": "en-ext",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7563718140929536,
        "scores_per_experiment": [
          {
            "accuracy": 0.8328335832083958,
            "ap": 0.31840858762649665,
            "ap_weighted": 0.31840858762649665,
            "f1": 0.7024784296311409,
            "f1_weighted": 0.858373154634064
          },
          {
            "accuracy": 0.7661169415292354,
            "ap": 0.25408004889498764,
            "ap_weighted": 0.25408004889498764,
            "f1": 0.6387998875285084,
            "f1_weighted": 0.8085559595294777
          },
          {
            "accuracy": 0.7706146926536732,
            "ap": 0.24450127547643538,
            "ap_weighted": 0.24450127547643538,
            "f1": 0.6366533268770651,
            "f1_weighted": 0.8112992555932357
          },
          {
            "accuracy": 0.780359820089955,
            "ap": 0.2680334917343952,
            "ap_weighted": 0.2680334917343952,
            "f1": 0.6525902717596604,
            "f1_weighted": 0.819369805797721
          },
          {
            "accuracy": 0.7286356821589205,
            "ap": 0.2300012812788799,
            "ap_weighted": 0.2300012812788799,
            "f1": 0.6080152213228394,
            "f1_weighted": 0.7801438789483821
          },
          {
            "accuracy": 0.7188905547226386,
            "ap": 0.23385085850259904,
            "ap_weighted": 0.23385085850259904,
            "f1": 0.6046913906091584,
            "f1_weighted": 0.7728843017721082
          },
          {
            "accuracy": 0.7211394302848576,
            "ap": 0.21201163842459445,
            "ap_weighted": 0.21201163842459445,
            "f1": 0.5952366193047421,
            "f1_weighted": 0.773937383276519
          },
          {
            "accuracy": 0.8095952023988006,
            "ap": 0.27193803599817146,
            "ap_weighted": 0.27193803599817146,
            "f1": 0.6697929701052106,
            "f1_weighted": 0.8398749485637718
          },
          {
            "accuracy": 0.699400299850075,
            "ap": 0.22248320426973905,
            "ap_weighted": 0.22248320426973905,
            "f1": 0.5891680586755755,
            "f1_weighted": 0.7576271710927555
          },
          {
            "accuracy": 0.7361319340329835,
            "ap": 0.21106574056227922,
            "ap_weighted": 0.21106574056227922,
            "f1": 0.6022228246137165,
            "f1_weighted": 0.784920524286515
          }
        ]
      },
      {
        "accuracy": 0.7337313432835821,
        "ap": 0.3586531081598875,
        "ap_weighted": 0.3586531081598875,
        "f1": 0.67241747773462,
        "f1_weighted": 0.7583561355199924,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7337313432835821,
        "scores_per_experiment": [
          {
            "accuracy": 0.6761194029850747,
            "ap": 0.3112006091465049,
            "ap_weighted": 0.3112006091465049,
            "f1": 0.6212569195701726,
            "f1_weighted": 0.7090368930340158
          },
          {
            "accuracy": 0.753731343283582,
            "ap": 0.3635270583514233,
            "ap_weighted": 0.3635270583514233,
            "f1": 0.6849808081930635,
            "f1_weighted": 0.7745981191097778
          },
          {
            "accuracy": 0.7313432835820896,
            "ap": 0.36156265336223214,
            "ap_weighted": 0.36156265336223214,
            "f1": 0.6735034219873517,
            "f1_weighted": 0.7571866259967597
          },
          {
            "accuracy": 0.7283582089552239,
            "ap": 0.3482302458094884,
            "ap_weighted": 0.3482302458094884,
            "f1": 0.6657346491228071,
            "f1_weighted": 0.7538395195077245
          },
          {
            "accuracy": 0.7,
            "ap": 0.33729449845615134,
            "ap_weighted": 0.33729449845615134,
            "f1": 0.6463302860714484,
            "f1_weighted": 0.730227769913782
          },
          {
            "accuracy": 0.7238805970149254,
            "ap": 0.3339444660490369,
            "ap_weighted": 0.3339444660490369,
            "f1": 0.6563540537468359,
            "f1_weighted": 0.7491177899535042
          },
          {
            "accuracy": 0.8,
            "ap": 0.43857180135135343,
            "ap_weighted": 0.43857180135135343,
            "f1": 0.7399309417871709,
            "f1_weighted": 0.8160432888394512
          },
          {
            "accuracy": 0.7791044776119403,
            "ap": 0.3819523822619688,
            "ap_weighted": 0.3819523822619688,
            "f1": 0.7048844656611231,
            "f1_weighted": 0.7950087658871154
          },
          {
            "accuracy": 0.753731343283582,
            "ap": 0.3792274315445672,
            "ap_weighted": 0.3792274315445672,
            "f1": 0.6924887134595645,
            "f1_weighted": 0.7760572518147457
          },
          {
            "accuracy": 0.691044776119403,
            "ap": 0.3310199352661486,
            "ap_weighted": 0.3310199352661486,
            "f1": 0.6387105177466623,
            "f1_weighted": 0.7224453311430473
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}