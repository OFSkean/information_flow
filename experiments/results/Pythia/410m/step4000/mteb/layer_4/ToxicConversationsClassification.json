{
  "dataset_revision": "edfaf9da55d3dd50d43143d90c1ac476895ae6de",
  "evaluation_time": 22.92237663269043,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.604248046875,
        "ap": 0.0944626296976998,
        "ap_weighted": 0.0944626296976998,
        "f1": 0.457355813926312,
        "f1_weighted": 0.6917854220161805,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.604248046875,
        "scores_per_experiment": [
          {
            "accuracy": 0.55224609375,
            "ap": 0.09042773875678947,
            "ap_weighted": 0.09042773875678947,
            "f1": 0.4311247246900368,
            "f1_weighted": 0.652091116498901
          },
          {
            "accuracy": 0.62060546875,
            "ap": 0.10685876188337716,
            "ap_weighted": 0.10685876188337716,
            "f1": 0.47852742039027474,
            "f1_weighted": 0.7076598388862209
          },
          {
            "accuracy": 0.65576171875,
            "ap": 0.09934550930809502,
            "ap_weighted": 0.09934550930809502,
            "f1": 0.4868497792392096,
            "f1_weighted": 0.7346831270831268
          },
          {
            "accuracy": 0.6748046875,
            "ap": 0.08915312718378757,
            "ap_weighted": 0.08915312718378757,
            "f1": 0.4817364818960682,
            "f1_weighted": 0.7480161510650108
          },
          {
            "accuracy": 0.56884765625,
            "ap": 0.09003280903464411,
            "ap_weighted": 0.09003280903464411,
            "f1": 0.4384136068829413,
            "f1_weighted": 0.6662436991917653
          },
          {
            "accuracy": 0.4267578125,
            "ap": 0.08706139159824604,
            "ap_weighted": 0.08706139159824604,
            "f1": 0.36254587990256126,
            "f1_weighted": 0.5328556826686912
          },
          {
            "accuracy": 0.6650390625,
            "ap": 0.09255413830730606,
            "ap_weighted": 0.09255413830730606,
            "f1": 0.48265460030165913,
            "f1_weighted": 0.7412325713789121
          },
          {
            "accuracy": 0.591796875,
            "ap": 0.09237101148329702,
            "ap_weighted": 0.09237101148329702,
            "f1": 0.4514182597417245,
            "f1_weighted": 0.6850212835885073
          },
          {
            "accuracy": 0.62451171875,
            "ap": 0.10181093616546316,
            "ap_weighted": 0.10181093616546316,
            "f1": 0.4757323762168266,
            "f1_weighted": 0.7108337387532071
          },
          {
            "accuracy": 0.662109375,
            "ap": 0.09501087325599233,
            "ap_weighted": 0.09501087325599233,
            "f1": 0.48455501000181855,
            "f1_weighted": 0.7392170110474633
          }
        ]
      }
    ]
  },
  "task_name": "ToxicConversationsClassification"
}