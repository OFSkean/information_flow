{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 26.557469367980957,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.7494752623688156,
        "ap": 0.22555999838641796,
        "ap_weighted": 0.22555999838641796,
        "f1": 0.6158419715123309,
        "f1_weighted": 0.7948787843541696,
        "hf_subset": "en-ext",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7494752623688156,
        "scores_per_experiment": [
          {
            "accuracy": 0.7998500749625187,
            "ap": 0.2789911287497332,
            "ap_weighted": 0.2789911287497332,
            "f1": 0.6678296146044624,
            "f1_weighted": 0.8336008466355057
          },
          {
            "accuracy": 0.7661169415292354,
            "ap": 0.22836840914027903,
            "ap_weighted": 0.22836840914027903,
            "f1": 0.6262835593068151,
            "f1_weighted": 0.8072444068887709
          },
          {
            "accuracy": 0.7736131934032984,
            "ap": 0.24683211557989204,
            "ap_weighted": 0.24683211557989204,
            "f1": 0.6393174330325169,
            "f1_weighted": 0.8135389600000171
          },
          {
            "accuracy": 0.7788605697151424,
            "ap": 0.24219913277233301,
            "ap_weighted": 0.24219913277233301,
            "f1": 0.639728466605329,
            "f1_weighted": 0.8169582626052843
          },
          {
            "accuracy": 0.7503748125937032,
            "ap": 0.1925428141159674,
            "ap_weighted": 0.1925428141159674,
            "f1": 0.5981764155167502,
            "f1_weighted": 0.7939395182125629
          },
          {
            "accuracy": 0.7338830584707646,
            "ap": 0.2353406749862479,
            "ap_weighted": 0.2353406749862479,
            "f1": 0.6132641803269987,
            "f1_weighted": 0.7842353686757461
          },
          {
            "accuracy": 0.7458770614692654,
            "ap": 0.22697397127741592,
            "ap_weighted": 0.22697397127741592,
            "f1": 0.6153975032041279,
            "f1_weighted": 0.7927287947459365
          },
          {
            "accuracy": 0.7593703148425787,
            "ap": 0.23617580598190116,
            "ap_weighted": 0.23617580598190116,
            "f1": 0.6268388392121869,
            "f1_weighted": 0.8028806483514244
          },
          {
            "accuracy": 0.671664167916042,
            "ap": 0.1845472778777425,
            "ap_weighted": 0.1845472778777425,
            "f1": 0.5554794770669004,
            "f1_weighted": 0.73537835322041
          },
          {
            "accuracy": 0.7151424287856072,
            "ap": 0.18362865338266787,
            "ap_weighted": 0.18362865338266787,
            "f1": 0.5761042262472196,
            "f1_weighted": 0.7682826842060381
          }
        ]
      },
      {
        "accuracy": 0.7391044776119402,
        "ap": 0.36178069753870756,
        "ap_weighted": 0.36178069753870756,
        "f1": 0.6766073478525065,
        "f1_weighted": 0.762806336349714,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7391044776119402,
        "scores_per_experiment": [
          {
            "accuracy": 0.7,
            "ap": 0.3207546267265154,
            "ap_weighted": 0.3207546267265154,
            "f1": 0.6381502051476338,
            "f1_weighted": 0.7292502639915523
          },
          {
            "accuracy": 0.753731343283582,
            "ap": 0.36800580568779073,
            "ap_weighted": 0.36800580568779073,
            "f1": 0.687198481122973,
            "f1_weighted": 0.7750476971796996
          },
          {
            "accuracy": 0.7238805970149254,
            "ap": 0.3554316582114774,
            "ap_weighted": 0.3554316582114774,
            "f1": 0.6669541689169762,
            "f1_weighted": 0.7508024817832694
          },
          {
            "accuracy": 0.7208955223880597,
            "ap": 0.34445567961718127,
            "ap_weighted": 0.34445567961718127,
            "f1": 0.6602867051145438,
            "f1_weighted": 0.7476662013957963
          },
          {
            "accuracy": 0.7567164179104477,
            "ap": 0.35957376086163484,
            "ap_weighted": 0.35957376086163484,
            "f1": 0.6842354832460628,
            "f1_weighted": 0.7763607833802344
          },
          {
            "accuracy": 0.735820895522388,
            "ap": 0.3456513846860921,
            "ap_weighted": 0.3456513846860921,
            "f1": 0.6678997790479178,
            "f1_weighted": 0.7593579160828481
          },
          {
            "accuracy": 0.808955223880597,
            "ap": 0.43143706014846495,
            "ap_weighted": 0.43143706014846495,
            "f1": 0.7405646107864134,
            "f1_weighted": 0.8216790588748637
          },
          {
            "accuracy": 0.7716417910447761,
            "ap": 0.39012396240378466,
            "ap_weighted": 0.39012396240378466,
            "f1": 0.7057785201959754,
            "f1_weighted": 0.7905489129603626
          },
          {
            "accuracy": 0.691044776119403,
            "ap": 0.3454663003441729,
            "ap_weighted": 0.3454663003441729,
            "f1": 0.6451298427149141,
            "f1_weighted": 0.7228613482295675
          },
          {
            "accuracy": 0.7283582089552239,
            "ap": 0.35690673669996176,
            "ap_weighted": 0.35690673669996176,
            "f1": 0.6698756822316556,
            "f1_weighted": 0.7544886996189459
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}