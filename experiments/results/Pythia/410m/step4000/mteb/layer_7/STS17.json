{
  "dataset_revision": "faeb762787bd10488a50c8b5be4a3b82e411949c",
  "evaluation_time": 16.476200819015503,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.23072583976044073,
        "cosine_spearman": 0.22930407461212313,
        "euclidean_pearson": 0.03990020535039991,
        "euclidean_spearman": 0.04969094215732512,
        "hf_subset": "nl-en",
        "languages": [
          "nld-Latn",
          "eng-Latn"
        ],
        "main_score": 0.22930407461212313,
        "manhattan_pearson": 0.03712070182068861,
        "manhattan_spearman": 0.05060311517302352,
        "pearson": 0.23072583976044073,
        "spearman": 0.22930407461212313
      },
      {
        "cosine_pearson": 0.6315792065575895,
        "cosine_spearman": 0.6383442885753879,
        "euclidean_pearson": 0.5800635281954389,
        "euclidean_spearman": 0.5852994865099428,
        "hf_subset": "en-en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6383442885753879,
        "manhattan_pearson": 0.5836136414779023,
        "manhattan_spearman": 0.5892103370205688,
        "pearson": 0.6315792065575895,
        "spearman": 0.6383442885753879
      },
      {
        "cosine_pearson": 0.27538485869111784,
        "cosine_spearman": 0.2830938371935494,
        "euclidean_pearson": 0.06995270343784117,
        "euclidean_spearman": 0.09386271863433095,
        "hf_subset": "en-de",
        "languages": [
          "eng-Latn",
          "deu-Latn"
        ],
        "main_score": 0.2830938371935494,
        "manhattan_pearson": 0.0698825456844329,
        "manhattan_spearman": 0.08880751959115789,
        "pearson": 0.27538485869111784,
        "spearman": 0.2830938371935494
      },
      {
        "cosine_pearson": 0.19843398669160658,
        "cosine_spearman": 0.1953004049041922,
        "euclidean_pearson": -0.05670118970720964,
        "euclidean_spearman": -0.05926393433404261,
        "hf_subset": "en-ar",
        "languages": [
          "eng-Latn",
          "ara-Arab"
        ],
        "main_score": 0.1953004049041922,
        "manhattan_pearson": -0.04835801736455821,
        "manhattan_spearman": -0.0501582927722594,
        "pearson": 0.19843398669160658,
        "spearman": 0.1953004049041922
      },
      {
        "cosine_pearson": 0.17599946049437812,
        "cosine_spearman": 0.16856288480107612,
        "euclidean_pearson": -0.02126233099358169,
        "euclidean_spearman": -0.015416223680819399,
        "hf_subset": "it-en",
        "languages": [
          "ita-Latn",
          "eng-Latn"
        ],
        "main_score": 0.16856288480107612,
        "manhattan_pearson": -0.015527618252485846,
        "manhattan_spearman": -0.024519502803351877,
        "pearson": 0.17599946049437812,
        "spearman": 0.16856288480107612
      },
      {
        "cosine_pearson": 0.07200452367382719,
        "cosine_spearman": 0.08570931182652514,
        "euclidean_pearson": -0.13392679756027426,
        "euclidean_spearman": -0.12444897651177107,
        "hf_subset": "en-tr",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ],
        "main_score": 0.08570931182652514,
        "manhattan_pearson": -0.12450687397340315,
        "manhattan_spearman": -0.11536277753095091,
        "pearson": 0.07200452367382719,
        "spearman": 0.08570931182652514
      },
      {
        "cosine_pearson": 0.24908434477809954,
        "cosine_spearman": 0.26048393968251665,
        "euclidean_pearson": 0.04433049794250812,
        "euclidean_spearman": -0.008876910324077369,
        "hf_subset": "es-en",
        "languages": [
          "spa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.26048393968251665,
        "manhattan_pearson": 0.04834646090312545,
        "manhattan_spearman": 0.0005843360483563987,
        "pearson": 0.24908434477809954,
        "spearman": 0.26048393968251665
      },
      {
        "cosine_pearson": 0.2544278608412554,
        "cosine_spearman": 0.2704779423873035,
        "euclidean_pearson": 0.031779656946899285,
        "euclidean_spearman": 0.05153527680937777,
        "hf_subset": "fr-en",
        "languages": [
          "fra-Latn",
          "eng-Latn"
        ],
        "main_score": 0.2704779423873035,
        "manhattan_pearson": 0.042317400753128405,
        "manhattan_spearman": 0.06342197135823646,
        "pearson": 0.2544278608412554,
        "spearman": 0.2704779423873035
      }
    ]
  },
  "task_name": "STS17"
}