{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 34.18870735168457,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.7598950524737631,
        "ap": 0.24629500458346346,
        "ap_weighted": 0.24629500458346346,
        "f1": 0.6315945879681594,
        "f1_weighted": 0.8032285347748467,
        "hf_subset": "en-ext",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7598950524737631,
        "scores_per_experiment": [
          {
            "accuracy": 0.828335832083958,
            "ap": 0.3050929916889923,
            "ap_weighted": 0.3050929916889923,
            "f1": 0.6944733649575394,
            "f1_weighted": 0.8545625668663707
          },
          {
            "accuracy": 0.7608695652173914,
            "ap": 0.24361761351676894,
            "ap_weighted": 0.24361761351676894,
            "f1": 0.6312026865995017,
            "f1_weighted": 0.8043104284711724
          },
          {
            "accuracy": 0.7916041979010495,
            "ap": 0.2573220186735458,
            "ap_weighted": 0.2573220186735458,
            "f1": 0.6536009983261597,
            "f1_weighted": 0.8266786452989431
          },
          {
            "accuracy": 0.7811094452773614,
            "ap": 0.2596154883266723,
            "ap_weighted": 0.2596154883266723,
            "f1": 0.6492103973948877,
            "f1_weighted": 0.8194859408715284
          },
          {
            "accuracy": 0.7263868065967016,
            "ap": 0.23058308975008895,
            "ap_weighted": 0.23058308975008895,
            "f1": 0.6071186793520053,
            "f1_weighted": 0.778475335638263
          },
          {
            "accuracy": 0.7428785607196402,
            "ap": 0.24966126963295138,
            "ap_weighted": 0.24966126963295138,
            "f1": 0.6245044335298776,
            "f1_weighted": 0.7913977290070329
          },
          {
            "accuracy": 0.7241379310344828,
            "ap": 0.21561520997204367,
            "ap_weighted": 0.21561520997204367,
            "f1": 0.5986132914704343,
            "f1_weighted": 0.7762996445262456
          },
          {
            "accuracy": 0.8223388305847077,
            "ap": 0.2904793650922328,
            "ap_weighted": 0.2904793650922328,
            "f1": 0.6849117246946617,
            "f1_weighted": 0.849637063877282
          },
          {
            "accuracy": 0.7038980509745127,
            "ap": 0.21747545695658999,
            "ap_weighted": 0.21747545695658999,
            "f1": 0.5891483324769538,
            "f1_weighted": 0.7610287618860634
          },
          {
            "accuracy": 0.717391304347826,
            "ap": 0.19348754222474848,
            "ap_weighted": 0.19348754222474848,
            "f1": 0.5831619708795722,
            "f1_weighted": 0.7704092313055645
          }
        ]
      },
      {
        "accuracy": 0.7349253731343284,
        "ap": 0.3609108401921831,
        "ap_weighted": 0.3609108401921831,
        "f1": 0.6741992697171715,
        "f1_weighted": 0.7595411116892399,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7349253731343284,
        "scores_per_experiment": [
          {
            "accuracy": 0.682089552238806,
            "ap": 0.31696325906604705,
            "ap_weighted": 0.31696325906604705,
            "f1": 0.6272440192137412,
            "f1_weighted": 0.7143139704753227
          },
          {
            "accuracy": 0.755223880597015,
            "ap": 0.3693977361434436,
            "ap_weighted": 0.3693977361434436,
            "f1": 0.6885487528344671,
            "f1_weighted": 0.776301824212272
          },
          {
            "accuracy": 0.7343283582089553,
            "ap": 0.36847556552467114,
            "ap_weighted": 0.36847556552467114,
            "f1": 0.678110661268556,
            "f1_weighted": 0.7600278768102806
          },
          {
            "accuracy": 0.7417910447761195,
            "ap": 0.36612848992794356,
            "ap_weighted": 0.36612848992794356,
            "f1": 0.6807335608495776,
            "f1_weighted": 0.7657555862489941
          },
          {
            "accuracy": 0.7059701492537314,
            "ap": 0.3353366754016178,
            "ap_weighted": 0.3353366754016178,
            "f1": 0.6484569553533142,
            "f1_weighted": 0.7350450849155659
          },
          {
            "accuracy": 0.7343283582089553,
            "ap": 0.3400765070235756,
            "ap_weighted": 0.3400765070235756,
            "f1": 0.6643059809043416,
            "f1_weighted": 0.7576691506438265
          },
          {
            "accuracy": 0.7985074626865671,
            "ap": 0.4390473033859157,
            "ap_weighted": 0.4390473033859157,
            "f1": 0.7394415493505484,
            "f1_weighted": 0.8149866673477136
          },
          {
            "accuracy": 0.7656716417910447,
            "ap": 0.3704125800334136,
            "ap_weighted": 0.3704125800334136,
            "f1": 0.6935692957541331,
            "f1_weighted": 0.7840854717020099
          },
          {
            "accuracy": 0.735820895522388,
            "ap": 0.3587689783047334,
            "ap_weighted": 0.3587689783047334,
            "f1": 0.6743991938915872,
            "f1_weighted": 0.7605162188584833
          },
          {
            "accuracy": 0.6955223880597015,
            "ap": 0.34450130711046956,
            "ap_weighted": 0.34450130711046956,
            "f1": 0.6471827277514481,
            "f1_weighted": 0.7267092656779295
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}