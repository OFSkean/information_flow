{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "evaluation_time": 14.61184310913086,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.29699999999999993,
        "f1": 0.26281167487497414,
        "f1_weighted": 0.3206866011050003,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.29699999999999993,
        "scores_per_experiment": [
          {
            "accuracy": 0.2885,
            "f1": 0.264594276322504,
            "f1_weighted": 0.3093070424852829
          },
          {
            "accuracy": 0.288,
            "f1": 0.25050322731731445,
            "f1_weighted": 0.3172168773057581
          },
          {
            "accuracy": 0.297,
            "f1": 0.25300728176697446,
            "f1_weighted": 0.31694653334261635
          },
          {
            "accuracy": 0.319,
            "f1": 0.2745285799221862,
            "f1_weighted": 0.34968453868951127
          },
          {
            "accuracy": 0.295,
            "f1": 0.2649291893623179,
            "f1_weighted": 0.3177703965399788
          },
          {
            "accuracy": 0.291,
            "f1": 0.25169430872578474,
            "f1_weighted": 0.3114908174725302
          },
          {
            "accuracy": 0.2895,
            "f1": 0.26616826425137935,
            "f1_weighted": 0.31326153424453096
          },
          {
            "accuracy": 0.298,
            "f1": 0.27259492527471024,
            "f1_weighted": 0.3218841224312246
          },
          {
            "accuracy": 0.32,
            "f1": 0.2751870414146485,
            "f1_weighted": 0.33819769478897005
          },
          {
            "accuracy": 0.284,
            "f1": 0.2549096543919221,
            "f1_weighted": 0.3111064537495993
          }
        ]
      }
    ]
  },
  "task_name": "EmotionClassification"
}