{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "evaluation_time": 12.036140441894531,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.28895,
        "f1": 0.2588906242186796,
        "f1_weighted": 0.30868551405536404,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.28895,
        "scores_per_experiment": [
          {
            "accuracy": 0.2995,
            "f1": 0.2707885640529499,
            "f1_weighted": 0.31681722376098426
          },
          {
            "accuracy": 0.2995,
            "f1": 0.26590654650063067,
            "f1_weighted": 0.3241618068949122
          },
          {
            "accuracy": 0.309,
            "f1": 0.2741087999402713,
            "f1_weighted": 0.3316790710439151
          },
          {
            "accuracy": 0.2835,
            "f1": 0.2469799765192633,
            "f1_weighted": 0.3024345166780052
          },
          {
            "accuracy": 0.2685,
            "f1": 0.25214074863231706,
            "f1_weighted": 0.2862644149908161
          },
          {
            "accuracy": 0.3005,
            "f1": 0.2673594582192589,
            "f1_weighted": 0.31782411588378584
          },
          {
            "accuracy": 0.301,
            "f1": 0.26163858377867627,
            "f1_weighted": 0.3256354196743044
          },
          {
            "accuracy": 0.235,
            "f1": 0.22467176968281366,
            "f1_weighted": 0.2438656051759455
          },
          {
            "accuracy": 0.2915,
            "f1": 0.2555027424068035,
            "f1_weighted": 0.31398687127432506
          },
          {
            "accuracy": 0.3015,
            "f1": 0.2698090524538113,
            "f1_weighted": 0.32418609517664637
          }
        ]
      }
    ]
  },
  "task_name": "EmotionClassification"
}