{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 27.40581488609314,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.8180659670164918,
        "ap": 0.31015319443262207,
        "ap_weighted": 0.31015319443262207,
        "f1": 0.6907469493330393,
        "f1_weighted": 0.8475625778404956,
        "hf_subset": "en-ext",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8180659670164918,
        "scores_per_experiment": [
          {
            "accuracy": 0.8455772113943029,
            "ap": 0.341006447523333,
            "ap_weighted": 0.341006447523333,
            "f1": 0.7186518418412269,
            "f1_weighted": 0.868242455957352
          },
          {
            "accuracy": 0.8478260869565217,
            "ap": 0.3362602871226258,
            "ap_weighted": 0.3362602871226258,
            "f1": 0.7180705255738753,
            "f1_weighted": 0.8694759099054494
          },
          {
            "accuracy": 0.8350824587706147,
            "ap": 0.33174421685510197,
            "ap_weighted": 0.33174421685510197,
            "f1": 0.7090431775641637,
            "f1_weighted": 0.8606348415208974
          },
          {
            "accuracy": 0.8073463268365817,
            "ap": 0.29382925186944037,
            "ap_weighted": 0.29382925186944037,
            "f1": 0.6782468083988171,
            "f1_weighted": 0.8395830113222247
          },
          {
            "accuracy": 0.775112443778111,
            "ap": 0.27713655828627126,
            "ap_weighted": 0.27713655828627126,
            "f1": 0.6536432369557993,
            "f1_weighted": 0.8160122020246108
          },
          {
            "accuracy": 0.8215892053973014,
            "ap": 0.31476500019076686,
            "ap_weighted": 0.31476500019076686,
            "f1": 0.6947063144979211,
            "f1_weighted": 0.8505067014627414
          },
          {
            "accuracy": 0.7623688155922039,
            "ap": 0.2620828840682753,
            "ap_weighted": 0.2620828840682753,
            "f1": 0.6403569572734764,
            "f1_weighted": 0.8061800234054922
          },
          {
            "accuracy": 0.8725637181409296,
            "ap": 0.3657611256779515,
            "ap_weighted": 0.3657611256779515,
            "f1": 0.7436471332971604,
            "f1_weighted": 0.8875540187041584
          },
          {
            "accuracy": 0.8035982008995503,
            "ap": 0.30940800324497914,
            "ap_weighted": 0.30940800324497914,
            "f1": 0.682432899016882,
            "f1_weighted": 0.8377127033713694
          },
          {
            "accuracy": 0.8095952023988006,
            "ap": 0.26953816948747544,
            "ap_weighted": 0.26953816948747544,
            "f1": 0.6686705989110708,
            "f1_weighted": 0.8397239107306601
          }
        ]
      },
      {
        "accuracy": 0.8008955223880598,
        "ap": 0.4461446108138699,
        "ap_weighted": 0.4461446108138699,
        "f1": 0.7422593036088606,
        "f1_weighted": 0.8168376733686717,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8008955223880598,
        "scores_per_experiment": [
          {
            "accuracy": 0.7895522388059701,
            "ap": 0.3981969921385439,
            "ap_weighted": 0.3981969921385439,
            "f1": 0.7171379038801842,
            "f1_weighted": 0.8042914397200683
          },
          {
            "accuracy": 0.835820895522388,
            "ap": 0.48865481554770146,
            "ap_weighted": 0.48865481554770146,
            "f1": 0.7761130553125304,
            "f1_weighted": 0.8465199882767556
          },
          {
            "accuracy": 0.7835820895522388,
            "ap": 0.41683109817392805,
            "ap_weighted": 0.41683109817392805,
            "f1": 0.7231649526545104,
            "f1_weighted": 0.8019195592176834
          },
          {
            "accuracy": 0.7731343283582089,
            "ap": 0.40313629631164094,
            "ap_weighted": 0.40313629631164094,
            "f1": 0.7123456371668417,
            "f1_weighted": 0.7928709164073542
          },
          {
            "accuracy": 0.8253731343283582,
            "ap": 0.46358652823667923,
            "ap_weighted": 0.46358652823667923,
            "f1": 0.7613633250226034,
            "f1_weighted": 0.8366255791919059
          },
          {
            "accuracy": 0.8014925373134328,
            "ap": 0.4474082034638033,
            "ap_weighted": 0.4474082034638033,
            "f1": 0.7442388443533643,
            "f1_weighted": 0.8179281400243674
          },
          {
            "accuracy": 0.8223880597014925,
            "ap": 0.4869732505620925,
            "ap_weighted": 0.4869732505620925,
            "f1": 0.7694725307133832,
            "f1_weighted": 0.8367296516702325
          },
          {
            "accuracy": 0.8656716417910447,
            "ap": 0.5431178892885626,
            "ap_weighted": 0.5431178892885626,
            "f1": 0.809420866992832,
            "f1_weighted": 0.8724711859974222
          },
          {
            "accuracy": 0.7880597014925373,
            "ap": 0.4450940566229263,
            "ap_weighted": 0.4450940566229263,
            "f1": 0.736661463004174,
            "f1_weighted": 0.8075076836232694
          },
          {
            "accuracy": 0.7238805970149254,
            "ap": 0.36844697779282115,
            "ap_weighted": 0.36844697779282115,
            "f1": 0.6726744569881825,
            "f1_weighted": 0.7515125895576584
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}