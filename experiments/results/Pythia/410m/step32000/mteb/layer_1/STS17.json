{
  "dataset_revision": "faeb762787bd10488a50c8b5be4a3b82e411949c",
  "evaluation_time": 18.77881407737732,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.4796773777876089,
        "cosine_spearman": 0.5409900960676525,
        "euclidean_pearson": 0.5244689577853189,
        "euclidean_spearman": 0.5371603532293031,
        "hf_subset": "en-en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5409900960676525,
        "manhattan_pearson": 0.5294705008825102,
        "manhattan_spearman": 0.5405737946028395,
        "pearson": 0.4796773777876089,
        "spearman": 0.5409900960676525
      },
      {
        "cosine_pearson": -0.03912475877349212,
        "cosine_spearman": -0.099015358962381,
        "euclidean_pearson": -0.07276234285727967,
        "euclidean_spearman": -0.13604842489018928,
        "hf_subset": "es-en",
        "languages": [
          "spa-Latn",
          "eng-Latn"
        ],
        "main_score": -0.099015358962381,
        "manhattan_pearson": -0.07871250535695616,
        "manhattan_spearman": -0.14221163247390625,
        "pearson": -0.03912475877349212,
        "spearman": -0.099015358962381
      },
      {
        "cosine_pearson": -0.09797650336862923,
        "cosine_spearman": -0.08663452588793705,
        "euclidean_pearson": -0.1055947412167697,
        "euclidean_spearman": -0.09820294009250655,
        "hf_subset": "fr-en",
        "languages": [
          "fra-Latn",
          "eng-Latn"
        ],
        "main_score": -0.08663452588793705,
        "manhattan_pearson": -0.11664111651976236,
        "manhattan_spearman": -0.1073992431803989,
        "pearson": -0.09797650336862923,
        "spearman": -0.08663452588793705
      },
      {
        "cosine_pearson": 0.023596027827579243,
        "cosine_spearman": 0.023691897028889738,
        "euclidean_pearson": -0.020405562579532535,
        "euclidean_spearman": -0.023109536254012752,
        "hf_subset": "en-de",
        "languages": [
          "eng-Latn",
          "deu-Latn"
        ],
        "main_score": 0.023691897028889738,
        "manhattan_pearson": -0.04440024651144165,
        "manhattan_spearman": -0.052989833358641464,
        "pearson": 0.023596027827579243,
        "spearman": 0.023691897028889738
      },
      {
        "cosine_pearson": -0.006981309370129299,
        "cosine_spearman": -0.0008326029296261021,
        "euclidean_pearson": -0.020334508651668887,
        "euclidean_spearman": -0.017501574970395395,
        "hf_subset": "nl-en",
        "languages": [
          "nld-Latn",
          "eng-Latn"
        ],
        "main_score": -0.0008326029296261021,
        "manhattan_pearson": -0.033193430332178656,
        "manhattan_spearman": -0.028789379692680937,
        "pearson": -0.006981309370129299,
        "spearman": -0.0008326029296261021
      },
      {
        "cosine_pearson": -0.09644660221861324,
        "cosine_spearman": -0.10108999616687223,
        "euclidean_pearson": -0.1715305463818936,
        "euclidean_spearman": -0.15982384439344696,
        "hf_subset": "en-ar",
        "languages": [
          "eng-Latn",
          "ara-Arab"
        ],
        "main_score": -0.10108999616687223,
        "manhattan_pearson": -0.17544794712398415,
        "manhattan_spearman": -0.19634327916783276,
        "pearson": -0.09644660221861324,
        "spearman": -0.10108999616687223
      },
      {
        "cosine_pearson": -0.10419432514357621,
        "cosine_spearman": -0.07701565755688926,
        "euclidean_pearson": -0.16561046611709715,
        "euclidean_spearman": -0.13934722093722612,
        "hf_subset": "en-tr",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ],
        "main_score": -0.07701565755688926,
        "manhattan_pearson": -0.16844317222398153,
        "manhattan_spearman": -0.1404241237149216,
        "pearson": -0.10419432514357621,
        "spearman": -0.07701565755688926
      },
      {
        "cosine_pearson": -0.08139282215674949,
        "cosine_spearman": -0.0460557039738191,
        "euclidean_pearson": -0.0851936245563304,
        "euclidean_spearman": -0.06901724755566839,
        "hf_subset": "it-en",
        "languages": [
          "ita-Latn",
          "eng-Latn"
        ],
        "main_score": -0.0460557039738191,
        "manhattan_pearson": -0.10358624911616848,
        "manhattan_spearman": -0.07150736841352522,
        "pearson": -0.08139282215674949,
        "spearman": -0.0460557039738191
      }
    ]
  },
  "task_name": "STS17"
}