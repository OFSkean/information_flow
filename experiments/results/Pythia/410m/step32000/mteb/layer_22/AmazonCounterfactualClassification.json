{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 35.213611125946045,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.7609445277361319,
        "ap": 0.25545408823614263,
        "ap_weighted": 0.25545408823614263,
        "f1": 0.6363437357180775,
        "f1_weighted": 0.8046231475297866,
        "hf_subset": "en-ext",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7609445277361319,
        "scores_per_experiment": [
          {
            "accuracy": 0.8035982008995503,
            "ap": 0.29477461325448373,
            "ap_weighted": 0.29477461325448373,
            "f1": 0.6765791275701886,
            "f1_weighted": 0.8370242728283295
          },
          {
            "accuracy": 0.7901049475262368,
            "ap": 0.2837990943595418,
            "ap_weighted": 0.2837990943595418,
            "f1": 0.6646134506599624,
            "f1_weighted": 0.8270142113104353
          },
          {
            "accuracy": 0.7728635682158921,
            "ap": 0.2684196128071474,
            "ap_weighted": 0.2684196128071474,
            "f1": 0.6487359510283679,
            "f1_weighted": 0.8140307350763195
          },
          {
            "accuracy": 0.7218890554722639,
            "ap": 0.22006516612260302,
            "ap_weighted": 0.22006516612260302,
            "f1": 0.5997094760782828,
            "f1_weighted": 0.7747727540159272
          },
          {
            "accuracy": 0.7241379310344828,
            "ap": 0.24923560830068006,
            "ap_weighted": 0.24923560830068006,
            "f1": 0.6142484905061402,
            "f1_weighted": 0.7772305820762664
          },
          {
            "accuracy": 0.7541229385307346,
            "ap": 0.25788057414314763,
            "ap_weighted": 0.25788057414314763,
            "f1": 0.6341110163397053,
            "f1_weighted": 0.7999913695252118
          },
          {
            "accuracy": 0.7421289355322339,
            "ap": 0.22857800119534863,
            "ap_weighted": 0.22857800119534863,
            "f1": 0.6142862426159842,
            "f1_weighted": 0.7900699453758275
          },
          {
            "accuracy": 0.8013493253373314,
            "ap": 0.2733297654412283,
            "ap_weighted": 0.2733297654412283,
            "f1": 0.6661078342014914,
            "f1_weighted": 0.8343233991478364
          },
          {
            "accuracy": 0.7728635682158921,
            "ap": 0.2729290544861177,
            "ap_weighted": 0.2729290544861177,
            "f1": 0.6506570674180124,
            "f1_weighted": 0.8142186198166954
          },
          {
            "accuracy": 0.7263868065967016,
            "ap": 0.20552939225112768,
            "ap_weighted": 0.20552939225112768,
            "f1": 0.5943887007626402,
            "f1_weighted": 0.7775555861250171
          }
        ]
      },
      {
        "accuracy": 0.7620895522388059,
        "ap": 0.3943061063432061,
        "ap_weighted": 0.3943061063432061,
        "f1": 0.7023428164491059,
        "f1_weighted": 0.7833178086313265,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7620895522388059,
        "scores_per_experiment": [
          {
            "accuracy": 0.6940298507462687,
            "ap": 0.3146901681737047,
            "ap_weighted": 0.3146901681737047,
            "f1": 0.6320407206483155,
            "f1_weighted": 0.7240100482118239
          },
          {
            "accuracy": 0.7791044776119403,
            "ap": 0.4072535541123897,
            "ap_weighted": 0.4072535541123897,
            "f1": 0.7169315794281539,
            "f1_weighted": 0.7977167464949847
          },
          {
            "accuracy": 0.7761194029850746,
            "ap": 0.40172319066246376,
            "ap_weighted": 0.40172319066246376,
            "f1": 0.7131063305015073,
            "f1_weighted": 0.794983189015187
          },
          {
            "accuracy": 0.7402985074626866,
            "ap": 0.3714553983844769,
            "ap_weighted": 0.3714553983844769,
            "f1": 0.6824333158995817,
            "f1_weighted": 0.7649822605070881
          },
          {
            "accuracy": 0.7880597014925373,
            "ap": 0.41730711703429935,
            "ap_weighted": 0.41730711703429935,
            "f1": 0.7254256854256855,
            "f1_weighted": 0.8052840559109217
          },
          {
            "accuracy": 0.7656716417910447,
            "ap": 0.3954174334692175,
            "ap_weighted": 0.3954174334692175,
            "f1": 0.7054252277430683,
            "f1_weighted": 0.7865491120056901
          },
          {
            "accuracy": 0.7955223880597015,
            "ap": 0.4354011867626999,
            "ap_weighted": 0.4354011867626999,
            "f1": 0.7365467795218865,
            "f1_weighted": 0.8124522946115664
          },
          {
            "accuracy": 0.8149253731343283,
            "ap": 0.44643001522784803,
            "ap_weighted": 0.44643001522784803,
            "f1": 0.7497107876217102,
            "f1_weighted": 0.8275106440227283
          },
          {
            "accuracy": 0.753731343283582,
            "ap": 0.4040223971918277,
            "ap_weighted": 0.4040223971918277,
            "f1": 0.7029591236286545,
            "f1_weighted": 0.7777427540229161
          },
          {
            "accuracy": 0.7134328358208956,
            "ap": 0.34936060241313366,
            "ap_weighted": 0.34936060241313366,
            "f1": 0.6588486140724947,
            "f1_weighted": 0.7419469815103588
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}