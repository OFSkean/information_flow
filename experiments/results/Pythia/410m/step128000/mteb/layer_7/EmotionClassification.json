{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "evaluation_time": 11.835099935531616,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.33199999999999996,
        "f1": 0.2995734051237231,
        "f1_weighted": 0.35501299097361827,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.33199999999999996,
        "scores_per_experiment": [
          {
            "accuracy": 0.304,
            "f1": 0.2823135472439277,
            "f1_weighted": 0.32199453180444515
          },
          {
            "accuracy": 0.3185,
            "f1": 0.2993863441121149,
            "f1_weighted": 0.3330986626336004
          },
          {
            "accuracy": 0.3365,
            "f1": 0.30435712130719955,
            "f1_weighted": 0.3636924253774264
          },
          {
            "accuracy": 0.351,
            "f1": 0.3085345362305229,
            "f1_weighted": 0.3798747799199788
          },
          {
            "accuracy": 0.315,
            "f1": 0.27917567696837026,
            "f1_weighted": 0.34272676786373907
          },
          {
            "accuracy": 0.3365,
            "f1": 0.302168143493593,
            "f1_weighted": 0.352833276868869
          },
          {
            "accuracy": 0.359,
            "f1": 0.3229126782480202,
            "f1_weighted": 0.382652085353456
          },
          {
            "accuracy": 0.3335,
            "f1": 0.2979331274952263,
            "f1_weighted": 0.3544481252740517
          },
          {
            "accuracy": 0.323,
            "f1": 0.2919514232822826,
            "f1_weighted": 0.34786068727544134
          },
          {
            "accuracy": 0.343,
            "f1": 0.30700145285597363,
            "f1_weighted": 0.37094856736517473
          }
        ]
      }
    ]
  },
  "task_name": "EmotionClassification"
}