{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "evaluation_time": 15.983465909957886,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.34624999999999995,
        "f1": 0.3119172866138385,
        "f1_weighted": 0.3675534666576009,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.34624999999999995,
        "scores_per_experiment": [
          {
            "accuracy": 0.3105,
            "f1": 0.2883992814290495,
            "f1_weighted": 0.3252360678683228
          },
          {
            "accuracy": 0.353,
            "f1": 0.3147692576828414,
            "f1_weighted": 0.37729970667558355
          },
          {
            "accuracy": 0.3655,
            "f1": 0.31914169428250555,
            "f1_weighted": 0.3844498885066604
          },
          {
            "accuracy": 0.3165,
            "f1": 0.28789066487524384,
            "f1_weighted": 0.33724677092368005
          },
          {
            "accuracy": 0.3585,
            "f1": 0.31534739938866946,
            "f1_weighted": 0.3871792949472065
          },
          {
            "accuracy": 0.3395,
            "f1": 0.30094123916467136,
            "f1_weighted": 0.3710009242088742
          },
          {
            "accuracy": 0.3625,
            "f1": 0.32030273531465997,
            "f1_weighted": 0.38665895922936333
          },
          {
            "accuracy": 0.3415,
            "f1": 0.3085163311023508,
            "f1_weighted": 0.3623703287674608
          },
          {
            "accuracy": 0.3495,
            "f1": 0.32879129345045943,
            "f1_weighted": 0.36756808360422
          },
          {
            "accuracy": 0.3655,
            "f1": 0.3350729694479336,
            "f1_weighted": 0.37652464184463796
          }
        ]
      }
    ]
  },
  "task_name": "EmotionClassification"
}