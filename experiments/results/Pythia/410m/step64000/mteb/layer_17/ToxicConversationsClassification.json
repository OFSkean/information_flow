{
  "dataset_revision": "edfaf9da55d3dd50d43143d90c1ac476895ae6de",
  "evaluation_time": 43.87350606918335,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.654833984375,
        "ap": 0.11441977556055523,
        "ap_weighted": 0.11441977556055523,
        "f1": 0.49891488610614126,
        "f1_weighted": 0.7298868953441738,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.654833984375,
        "scores_per_experiment": [
          {
            "accuracy": 0.61474609375,
            "ap": 0.11177644016903915,
            "ap_weighted": 0.11177644016903915,
            "f1": 0.47983408740831596,
            "f1_weighted": 0.7028334152444267
          },
          {
            "accuracy": 0.6279296875,
            "ap": 0.10572732489608537,
            "ap_weighted": 0.10572732489608537,
            "f1": 0.4808815369815222,
            "f1_weighted": 0.7134604466089127
          },
          {
            "accuracy": 0.75927734375,
            "ap": 0.1229133542212246,
            "ap_weighted": 0.1229133542212246,
            "f1": 0.5531319279302724,
            "f1_weighted": 0.8086277560202869
          },
          {
            "accuracy": 0.7548828125,
            "ap": 0.1287732565616327,
            "ap_weighted": 0.1287732565616327,
            "f1": 0.5563587531565493,
            "f1_weighted": 0.8061802701697676
          },
          {
            "accuracy": 0.50732421875,
            "ap": 0.09604879422292383,
            "ap_weighted": 0.09604879422292383,
            "f1": 0.41407984257750974,
            "f1_weighted": 0.6108403132279053
          },
          {
            "accuracy": 0.5390625,
            "ap": 0.09993289847773588,
            "ap_weighted": 0.09993289847773588,
            "f1": 0.43351945354730126,
            "f1_weighted": 0.6393522726473608
          },
          {
            "accuracy": 0.81884765625,
            "ap": 0.137653537495245,
            "ap_weighted": 0.137653537495245,
            "f1": 0.590722788442323,
            "f1_weighted": 0.8479414098291348
          },
          {
            "accuracy": 0.5966796875,
            "ap": 0.11426443403986108,
            "ap_weighted": 0.11426443403986108,
            "f1": 0.4730462519936205,
            "f1_weighted": 0.6879091983776915
          },
          {
            "accuracy": 0.61669921875,
            "ap": 0.10282793475499417,
            "ap_weighted": 0.10282793475499417,
            "f1": 0.4731583333415259,
            "f1_weighted": 0.7046499015774561
          },
          {
            "accuracy": 0.712890625,
            "ap": 0.12427978076681048,
            "ap_weighted": 0.12427978076681048,
            "f1": 0.534415885682472,
            "f1_weighted": 0.7770739697387957
          }
        ]
      }
    ]
  },
  "task_name": "ToxicConversationsClassification"
}