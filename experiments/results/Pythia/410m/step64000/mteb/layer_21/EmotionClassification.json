{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "evaluation_time": 15.989458799362183,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.33344999999999997,
        "f1": 0.2977031460611468,
        "f1_weighted": 0.3548363724628995,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.33344999999999997,
        "scores_per_experiment": [
          {
            "accuracy": 0.331,
            "f1": 0.30429023241493497,
            "f1_weighted": 0.342857052371778
          },
          {
            "accuracy": 0.3255,
            "f1": 0.2883108068547605,
            "f1_weighted": 0.34597722593464714
          },
          {
            "accuracy": 0.356,
            "f1": 0.3195172567882572,
            "f1_weighted": 0.37614434216018827
          },
          {
            "accuracy": 0.3145,
            "f1": 0.2801613787765065,
            "f1_weighted": 0.3480406982582562
          },
          {
            "accuracy": 0.3215,
            "f1": 0.2939706116494427,
            "f1_weighted": 0.3420134103094455
          },
          {
            "accuracy": 0.32,
            "f1": 0.29220263598446583,
            "f1_weighted": 0.34333092940668736
          },
          {
            "accuracy": 0.308,
            "f1": 0.2860363280873411,
            "f1_weighted": 0.3236472512542354
          },
          {
            "accuracy": 0.337,
            "f1": 0.293279121198502,
            "f1_weighted": 0.3546003951718739
          },
          {
            "accuracy": 0.3745,
            "f1": 0.3116950363069837,
            "f1_weighted": 0.4052310818510019
          },
          {
            "accuracy": 0.3465,
            "f1": 0.3075680525502737,
            "f1_weighted": 0.36652133791088093
          }
        ]
      }
    ]
  },
  "task_name": "EmotionClassification"
}