{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "evaluation_time": 15.433787107467651,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.33740000000000003,
        "f1": 0.30583445579235824,
        "f1_weighted": 0.3610674403392352,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.33740000000000003,
        "scores_per_experiment": [
          {
            "accuracy": 0.3335,
            "f1": 0.3074609732555563,
            "f1_weighted": 0.35517323163012066
          },
          {
            "accuracy": 0.334,
            "f1": 0.29264280430622047,
            "f1_weighted": 0.3567301477026196
          },
          {
            "accuracy": 0.3095,
            "f1": 0.2957304032952097,
            "f1_weighted": 0.33086897692656597
          },
          {
            "accuracy": 0.361,
            "f1": 0.3275540670344191,
            "f1_weighted": 0.3845080912009448
          },
          {
            "accuracy": 0.335,
            "f1": 0.3083728146939293,
            "f1_weighted": 0.35875226574931607
          },
          {
            "accuracy": 0.3465,
            "f1": 0.3102671292088743,
            "f1_weighted": 0.36914962195058837
          },
          {
            "accuracy": 0.3355,
            "f1": 0.30092312718006486,
            "f1_weighted": 0.36617779739253103
          },
          {
            "accuracy": 0.302,
            "f1": 0.27706300212429086,
            "f1_weighted": 0.32518190169152883
          },
          {
            "accuracy": 0.3495,
            "f1": 0.3156223945953118,
            "f1_weighted": 0.37605354521456164
          },
          {
            "accuracy": 0.3675,
            "f1": 0.322707842229706,
            "f1_weighted": 0.38807882393357507
          }
        ]
      }
    ]
  },
  "task_name": "EmotionClassification"
}