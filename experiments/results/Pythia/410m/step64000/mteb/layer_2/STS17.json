{
  "dataset_revision": "faeb762787bd10488a50c8b5be4a3b82e411949c",
  "evaluation_time": 18.387519598007202,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.04276961539643063,
        "cosine_spearman": 0.06285191127299386,
        "euclidean_pearson": -0.01766535254694035,
        "euclidean_spearman": -0.013752555407771492,
        "hf_subset": "en-de",
        "languages": [
          "eng-Latn",
          "deu-Latn"
        ],
        "main_score": 0.06285191127299386,
        "manhattan_pearson": -0.03832243851650777,
        "manhattan_spearman": -0.028536831158625372,
        "pearson": 0.04276961539643063,
        "spearman": 0.06285191127299386
      },
      {
        "cosine_pearson": -0.007601678187407976,
        "cosine_spearman": 0.024157785648791324,
        "euclidean_pearson": -0.051885509994959104,
        "euclidean_spearman": -0.03938911458854417,
        "hf_subset": "it-en",
        "languages": [
          "ita-Latn",
          "eng-Latn"
        ],
        "main_score": 0.024157785648791324,
        "manhattan_pearson": -0.08927840588232784,
        "manhattan_spearman": -0.06903569859011995,
        "pearson": -0.007601678187407976,
        "spearman": 0.024157785648791324
      },
      {
        "cosine_pearson": 0.036317365460299914,
        "cosine_spearman": 0.020029366690257466,
        "euclidean_pearson": -0.012372995055125539,
        "euclidean_spearman": -0.023223317633130635,
        "hf_subset": "nl-en",
        "languages": [
          "nld-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020029366690257466,
        "manhattan_pearson": -0.04990201588871806,
        "manhattan_spearman": -0.04870996215898449,
        "pearson": 0.036317365460299914,
        "spearman": 0.020029366690257466
      },
      {
        "cosine_pearson": -0.09079016997558512,
        "cosine_spearman": -0.04273893019527388,
        "euclidean_pearson": -0.166227891294757,
        "euclidean_spearman": -0.12895920374673914,
        "hf_subset": "en-tr",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ],
        "main_score": -0.04273893019527388,
        "manhattan_pearson": -0.16427028870461197,
        "manhattan_spearman": -0.12805800413555807,
        "pearson": -0.09079016997558512,
        "spearman": -0.04273893019527388
      },
      {
        "cosine_pearson": 0.5115302581287654,
        "cosine_spearman": 0.5570390364715396,
        "euclidean_pearson": 0.5346357750267954,
        "euclidean_spearman": 0.5404350274479018,
        "hf_subset": "en-en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5570390364715396,
        "manhattan_pearson": 0.5337371949849316,
        "manhattan_spearman": 0.5421994076173311,
        "pearson": 0.5115302581287654,
        "spearman": 0.5570390364715396
      },
      {
        "cosine_pearson": -0.05867994576736057,
        "cosine_spearman": -0.0886712203336854,
        "euclidean_pearson": -0.12663687402788706,
        "euclidean_spearman": -0.139293866998491,
        "hf_subset": "en-ar",
        "languages": [
          "eng-Latn",
          "ara-Arab"
        ],
        "main_score": -0.0886712203336854,
        "manhattan_pearson": -0.1399078580380376,
        "manhattan_spearman": -0.16557791179205947,
        "pearson": -0.05867994576736057,
        "spearman": -0.0886712203336854
      },
      {
        "cosine_pearson": -0.04011171538053999,
        "cosine_spearman": -0.11128064950370395,
        "euclidean_pearson": -0.07685965750476073,
        "euclidean_spearman": -0.1490868074007522,
        "hf_subset": "es-en",
        "languages": [
          "spa-Latn",
          "eng-Latn"
        ],
        "main_score": -0.11128064950370395,
        "manhattan_pearson": -0.09123372464531693,
        "manhattan_spearman": -0.1731410777176655,
        "pearson": -0.04011171538053999,
        "spearman": -0.11128064950370395
      },
      {
        "cosine_pearson": 0.009036638462023301,
        "cosine_spearman": 0.01415963135535877,
        "euclidean_pearson": -0.039605780037442244,
        "euclidean_spearman": -0.03874717234825073,
        "hf_subset": "fr-en",
        "languages": [
          "fra-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01415963135535877,
        "manhattan_pearson": -0.06066488169593276,
        "manhattan_spearman": -0.061004501448532616,
        "pearson": 0.009036638462023301,
        "spearman": 0.01415963135535877
      }
    ]
  },
  "task_name": "STS17"
}