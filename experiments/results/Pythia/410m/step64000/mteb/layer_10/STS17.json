{
  "dataset_revision": "faeb762787bd10488a50c8b5be4a3b82e411949c",
  "evaluation_time": 19.412423610687256,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.1734059452646472,
        "cosine_spearman": 0.21084650541920688,
        "euclidean_pearson": 0.082002653807217,
        "euclidean_spearman": 0.11504796575366769,
        "hf_subset": "it-en",
        "languages": [
          "ita-Latn",
          "eng-Latn"
        ],
        "main_score": 0.21084650541920688,
        "manhattan_pearson": 0.07866064227497767,
        "manhattan_spearman": 0.11358956523889324,
        "pearson": 0.1734059452646472,
        "spearman": 0.21084650541920688
      },
      {
        "cosine_pearson": 0.6146641720623885,
        "cosine_spearman": 0.6320916942756195,
        "euclidean_pearson": 0.6026562005121994,
        "euclidean_spearman": 0.6176226236966462,
        "hf_subset": "en-en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6320916942756195,
        "manhattan_pearson": 0.6024480318575285,
        "manhattan_spearman": 0.6173754567143057,
        "pearson": 0.6146641720623885,
        "spearman": 0.6320916942756195
      },
      {
        "cosine_pearson": 0.0015362692266893282,
        "cosine_spearman": 0.011117585496871567,
        "euclidean_pearson": -0.13291171650082395,
        "euclidean_spearman": -0.12180410064339246,
        "hf_subset": "en-ar",
        "languages": [
          "eng-Latn",
          "ara-Arab"
        ],
        "main_score": 0.011117585496871567,
        "manhattan_pearson": -0.14412087111507152,
        "manhattan_spearman": -0.12758430716840657,
        "pearson": 0.0015362692266893282,
        "spearman": 0.011117585496871567
      },
      {
        "cosine_pearson": 0.24758728252712633,
        "cosine_spearman": 0.2460556919113733,
        "euclidean_pearson": 0.1448449368545377,
        "euclidean_spearman": 0.13619016045928414,
        "hf_subset": "nl-en",
        "languages": [
          "nld-Latn",
          "eng-Latn"
        ],
        "main_score": 0.2460556919113733,
        "manhattan_pearson": 0.1387807508710888,
        "manhattan_spearman": 0.12535709685691904,
        "pearson": 0.24758728252712633,
        "spearman": 0.2460556919113733
      },
      {
        "cosine_pearson": 0.25082585125118656,
        "cosine_spearman": 0.22756813630595643,
        "euclidean_pearson": 0.19889874687294568,
        "euclidean_spearman": 0.1673211675623579,
        "hf_subset": "es-en",
        "languages": [
          "spa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.22756813630595643,
        "manhattan_pearson": 0.1903507535176658,
        "manhattan_spearman": 0.16473471168515932,
        "pearson": 0.25082585125118656,
        "spearman": 0.22756813630595643
      },
      {
        "cosine_pearson": 0.016096453914210624,
        "cosine_spearman": 0.031301307655587085,
        "euclidean_pearson": -0.07120125446926096,
        "euclidean_spearman": -0.07570422757662533,
        "hf_subset": "en-tr",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ],
        "main_score": 0.031301307655587085,
        "manhattan_pearson": -0.06194934328739076,
        "manhattan_spearman": -0.05787593100236011,
        "pearson": 0.016096453914210624,
        "spearman": 0.031301307655587085
      },
      {
        "cosine_pearson": 0.14926551314675035,
        "cosine_spearman": 0.15000729448763606,
        "euclidean_pearson": 0.055743750406226006,
        "euclidean_spearman": 0.04467572035546374,
        "hf_subset": "en-de",
        "languages": [
          "eng-Latn",
          "deu-Latn"
        ],
        "main_score": 0.15000729448763606,
        "manhattan_pearson": 0.07045088933183728,
        "manhattan_spearman": 0.053383839823492235,
        "pearson": 0.14926551314675035,
        "spearman": 0.15000729448763606
      },
      {
        "cosine_pearson": 0.22480892037959066,
        "cosine_spearman": 0.2202596081619049,
        "euclidean_pearson": 0.13727754120872854,
        "euclidean_spearman": 0.1283181034898414,
        "hf_subset": "fr-en",
        "languages": [
          "fra-Latn",
          "eng-Latn"
        ],
        "main_score": 0.2202596081619049,
        "manhattan_pearson": 0.12716107167875895,
        "manhattan_spearman": 0.1265191276308155,
        "pearson": 0.22480892037959066,
        "spearman": 0.2202596081619049
      }
    ]
  },
  "task_name": "STS17"
}