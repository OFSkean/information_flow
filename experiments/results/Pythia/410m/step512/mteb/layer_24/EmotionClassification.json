{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "evaluation_time": 15.952704429626465,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.177,
        "f1": 0.15866229283773942,
        "f1_weighted": 0.19548158877634977,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.177,
        "scores_per_experiment": [
          {
            "accuracy": 0.1885,
            "f1": 0.16487092693806607,
            "f1_weighted": 0.20653456723826216
          },
          {
            "accuracy": 0.2025,
            "f1": 0.17487943579638077,
            "f1_weighted": 0.22370263045660566
          },
          {
            "accuracy": 0.1805,
            "f1": 0.1624055198559902,
            "f1_weighted": 0.19672651119218665
          },
          {
            "accuracy": 0.152,
            "f1": 0.13655970767760597,
            "f1_weighted": 0.16891078083842936
          },
          {
            "accuracy": 0.1515,
            "f1": 0.14509158184615675,
            "f1_weighted": 0.16583706840784887
          },
          {
            "accuracy": 0.185,
            "f1": 0.1694410914427381,
            "f1_weighted": 0.20981096050988027
          },
          {
            "accuracy": 0.1685,
            "f1": 0.15385451062795055,
            "f1_weighted": 0.18282148173273824
          },
          {
            "accuracy": 0.1905,
            "f1": 0.17305518740432432,
            "f1_weighted": 0.21183959917297665
          },
          {
            "accuracy": 0.167,
            "f1": 0.14335014119216902,
            "f1_weighted": 0.18820008510129999
          },
          {
            "accuracy": 0.184,
            "f1": 0.16311482559601265,
            "f1_weighted": 0.20043220311327
          }
        ]
      }
    ]
  },
  "task_name": "EmotionClassification"
}