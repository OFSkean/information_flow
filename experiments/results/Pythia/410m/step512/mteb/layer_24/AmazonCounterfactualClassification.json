{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 35.205310344696045,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.6299850074962519,
        "ap": 0.1527804330021291,
        "ap_weighted": 0.1527804330021291,
        "f1": 0.5141920816573531,
        "f1_weighted": 0.7012393648352224,
        "hf_subset": "en-ext",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6299850074962519,
        "scores_per_experiment": [
          {
            "accuracy": 0.6064467766116941,
            "ap": 0.1444793796418914,
            "ap_weighted": 0.1444793796418914,
            "f1": 0.4975662074086296,
            "f1_weighted": 0.682715774362633
          },
          {
            "accuracy": 0.5877061469265368,
            "ap": 0.13423102424432395,
            "ap_weighted": 0.13423102424432395,
            "f1": 0.48050016993315964,
            "f1_weighted": 0.667314545683995
          },
          {
            "accuracy": 0.7083958020989505,
            "ap": 0.17062521149833207,
            "ap_weighted": 0.17062521149833207,
            "f1": 0.5643915259971106,
            "f1_weighted": 0.7626555619339332
          },
          {
            "accuracy": 0.5974512743628186,
            "ap": 0.14582656780689957,
            "ap_weighted": 0.14582656780689957,
            "f1": 0.4940785213005854,
            "f1_weighted": 0.6751094122354415
          },
          {
            "accuracy": 0.5727136431784108,
            "ap": 0.12796999080902655,
            "ap_weighted": 0.12796999080902655,
            "f1": 0.46792788707794875,
            "f1_weighted": 0.6548430195814755
          },
          {
            "accuracy": 0.618440779610195,
            "ap": 0.1636285802808008,
            "ap_weighted": 0.1636285802808008,
            "f1": 0.516304111663664,
            "f1_weighted": 0.6922524336074432
          },
          {
            "accuracy": 0.6071964017991005,
            "ap": 0.13753967282122798,
            "ap_weighted": 0.13753967282122798,
            "f1": 0.4925842044134727,
            "f1_weighted": 0.6834840158318054
          },
          {
            "accuracy": 0.697151424287856,
            "ap": 0.18395032003608316,
            "ap_weighted": 0.18395032003608316,
            "f1": 0.5676946968530212,
            "f1_weighted": 0.7549636066765633
          },
          {
            "accuracy": 0.6371814092953523,
            "ap": 0.16123987046144278,
            "ap_weighted": 0.16123987046144278,
            "f1": 0.5242230239577438,
            "f1_weighted": 0.7077369545985355
          },
          {
            "accuracy": 0.6671664167916042,
            "ap": 0.1583137124212627,
            "ap_weighted": 0.1583137124212627,
            "f1": 0.536650467968195,
            "f1_weighted": 0.7313183238403985
          }
        ]
      },
      {
        "accuracy": 0.6338805970149253,
        "ap": 0.27908924491383197,
        "ap_weighted": 0.27908924491383197,
        "f1": 0.5808605854708484,
        "f1_weighted": 0.6710746769541789,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6338805970149253,
        "scores_per_experiment": [
          {
            "accuracy": 0.5880597014925373,
            "ap": 0.26099591290833307,
            "ap_weighted": 0.26099591290833307,
            "f1": 0.5468713243942601,
            "f1_weighted": 0.630063690018503
          },
          {
            "accuracy": 0.6746268656716418,
            "ap": 0.31027626032153416,
            "ap_weighted": 0.31027626032153416,
            "f1": 0.6200154012654012,
            "f1_weighted": 0.7077377535399924
          },
          {
            "accuracy": 0.6611940298507463,
            "ap": 0.26517580397585316,
            "ap_weighted": 0.26517580397585316,
            "f1": 0.5863466376555382,
            "f1_weighted": 0.6934965885876256
          },
          {
            "accuracy": 0.5805970149253732,
            "ap": 0.24400073424227464,
            "ap_weighted": 0.24400073424227464,
            "f1": 0.5324517290618986,
            "f1_weighted": 0.6238158064214224
          },
          {
            "accuracy": 0.6850746268656717,
            "ap": 0.3049228117576612,
            "ap_weighted": 0.3049228117576612,
            "f1": 0.6223799386170403,
            "f1_weighted": 0.7160774946809288
          },
          {
            "accuracy": 0.6179104477611941,
            "ap": 0.2605728048656315,
            "ap_weighted": 0.2605728048656315,
            "f1": 0.562734540708109,
            "f1_weighted": 0.657321809941969
          },
          {
            "accuracy": 0.5835820895522388,
            "ap": 0.24663127675166716,
            "ap_weighted": 0.24663127675166716,
            "f1": 0.5357794747625256,
            "f1_weighted": 0.6264932739913767
          },
          {
            "accuracy": 0.6597014925373135,
            "ap": 0.2881402257680114,
            "ap_weighted": 0.2881402257680114,
            "f1": 0.6004561432875795,
            "f1_weighted": 0.6941464630313448
          },
          {
            "accuracy": 0.6537313432835821,
            "ap": 0.31714508888470616,
            "ap_weighted": 0.31714508888470616,
            "f1": 0.6118851435705368,
            "f1_weighted": 0.6894908230383663
          },
          {
            "accuracy": 0.6343283582089553,
            "ap": 0.29303152966264745,
            "ap_weighted": 0.29303152966264745,
            "f1": 0.5896855213855956,
            "f1_weighted": 0.6721030662902595
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}