{
  "dataset_revision": "edfaf9da55d3dd50d43143d90c1ac476895ae6de",
  "evaluation_time": 20.95613956451416,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.565869140625,
        "ap": 0.08409609212280292,
        "ap_weighted": 0.08409609212280292,
        "f1": 0.4259989815469023,
        "f1_weighted": 0.6585363774091025,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.565869140625,
        "scores_per_experiment": [
          {
            "accuracy": 0.46826171875,
            "ap": 0.09228743576372159,
            "ap_weighted": 0.09228743576372159,
            "f1": 0.3901386786764615,
            "f1_weighted": 0.5738823636516052
          },
          {
            "accuracy": 0.55078125,
            "ap": 0.08072080159385707,
            "ap_weighted": 0.08072080159385707,
            "f1": 0.41807759541914,
            "f1_weighted": 0.6520051010402059
          },
          {
            "accuracy": 0.70751953125,
            "ap": 0.08900946302204982,
            "ap_weighted": 0.08900946302204982,
            "f1": 0.4936516171958808,
            "f1_weighted": 0.7706676080518547
          },
          {
            "accuracy": 0.6220703125,
            "ap": 0.0815376757283198,
            "ap_weighted": 0.0815376757283198,
            "f1": 0.4489111389236546,
            "f1_weighted": 0.7089515703222778
          },
          {
            "accuracy": 0.490234375,
            "ap": 0.08417808750144226,
            "ap_weighted": 0.08417808750144226,
            "f1": 0.39403613146629907,
            "f1_weighted": 0.5972784989321084
          },
          {
            "accuracy": 0.38671875,
            "ap": 0.08088669161404652,
            "ap_weighted": 0.08088669161404652,
            "f1": 0.3336421240240194,
            "f1_weighted": 0.49195372122573333
          },
          {
            "accuracy": 0.66748046875,
            "ap": 0.08402555010162896,
            "ap_weighted": 0.08402555010162896,
            "f1": 0.470566597692065,
            "f1_weighted": 0.7423676494966126
          },
          {
            "accuracy": 0.57568359375,
            "ap": 0.0834989639699119,
            "ap_weighted": 0.0834989639699119,
            "f1": 0.4331360136324184,
            "f1_weighted": 0.6724271802562847
          },
          {
            "accuracy": 0.60107421875,
            "ap": 0.07887771358908512,
            "ap_weighted": 0.07887771358908512,
            "f1": 0.43556773105592556,
            "f1_weighted": 0.6928564459202938
          },
          {
            "accuracy": 0.5888671875,
            "ap": 0.08593853834396598,
            "ap_weighted": 0.08593853834396598,
            "f1": 0.4422621873831588,
            "f1_weighted": 0.6829736351940485
          }
        ]
      }
    ]
  },
  "task_name": "ToxicConversationsClassification"
}