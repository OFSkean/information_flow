{
  "dataset_revision": "faeb762787bd10488a50c8b5be4a3b82e411949c",
  "evaluation_time": 19.744791507720947,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.07475771393848572,
        "cosine_spearman": 0.08974083441716535,
        "euclidean_pearson": 0.06088348907854792,
        "euclidean_spearman": 0.087346812697077,
        "hf_subset": "en-de",
        "languages": [
          "eng-Latn",
          "deu-Latn"
        ],
        "main_score": 0.08974083441716535,
        "manhattan_pearson": 0.05918248050697704,
        "manhattan_spearman": 0.0898242484687484,
        "pearson": 0.07475771393848572,
        "spearman": 0.08974083441716535
      },
      {
        "cosine_pearson": 0.01595414241021715,
        "cosine_spearman": 0.0007288823340024552,
        "euclidean_pearson": -0.0026039476949204178,
        "euclidean_spearman": -0.016391779451229268,
        "hf_subset": "es-en",
        "languages": [
          "spa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.0007288823340024552,
        "manhattan_pearson": -0.0025538251780729032,
        "manhattan_spearman": -0.013608494589321157,
        "pearson": 0.01595414241021715,
        "spearman": 0.0007288823340024552
      },
      {
        "cosine_pearson": -0.01917823130656957,
        "cosine_spearman": -0.026692276444134737,
        "euclidean_pearson": -0.03062323503434793,
        "euclidean_spearman": -0.051733943935791546,
        "hf_subset": "en-ar",
        "languages": [
          "eng-Latn",
          "ara-Arab"
        ],
        "main_score": -0.026692276444134737,
        "manhattan_pearson": -0.030149918950905845,
        "manhattan_spearman": -0.04428006452323928,
        "pearson": -0.01917823130656957,
        "spearman": -0.026692276444134737
      },
      {
        "cosine_pearson": 0.04390941448256889,
        "cosine_spearman": 0.053648674293769696,
        "euclidean_pearson": -0.00840938505164463,
        "euclidean_spearman": 0.011044693357678657,
        "hf_subset": "en-tr",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ],
        "main_score": 0.053648674293769696,
        "manhattan_pearson": -0.0073419942486261285,
        "manhattan_spearman": 0.008974317971070256,
        "pearson": 0.04390941448256889,
        "spearman": 0.053648674293769696
      },
      {
        "cosine_pearson": 0.2902798353217188,
        "cosine_spearman": 0.3148384575708866,
        "euclidean_pearson": 0.28577991013421417,
        "euclidean_spearman": 0.28745443166893186,
        "hf_subset": "en-en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.3148384575708866,
        "manhattan_pearson": 0.28511361377349453,
        "manhattan_spearman": 0.2854079044310144,
        "pearson": 0.2902798353217188,
        "spearman": 0.3148384575708866
      },
      {
        "cosine_pearson": -0.0843608651751831,
        "cosine_spearman": -0.07340244341031964,
        "euclidean_pearson": -0.09777357726205749,
        "euclidean_spearman": -0.054425554476902546,
        "hf_subset": "it-en",
        "languages": [
          "ita-Latn",
          "eng-Latn"
        ],
        "main_score": -0.07340244341031964,
        "manhattan_pearson": -0.10369247569461264,
        "manhattan_spearman": -0.0632313106689038,
        "pearson": -0.0843608651751831,
        "spearman": -0.07340244341031964
      },
      {
        "cosine_pearson": -0.02212961143543336,
        "cosine_spearman": -0.024431860389707027,
        "euclidean_pearson": -0.07963336938977203,
        "euclidean_spearman": -0.0835020783932357,
        "hf_subset": "nl-en",
        "languages": [
          "nld-Latn",
          "eng-Latn"
        ],
        "main_score": -0.024431860389707027,
        "manhattan_pearson": -0.0824059284626411,
        "manhattan_spearman": -0.09091631907034939,
        "pearson": -0.02212961143543336,
        "spearman": -0.024431860389707027
      },
      {
        "cosine_pearson": -0.01771966568645947,
        "cosine_spearman": -0.012204206100045759,
        "euclidean_pearson": -0.05262536485141667,
        "euclidean_spearman": -0.04488098811373721,
        "hf_subset": "fr-en",
        "languages": [
          "fra-Latn",
          "eng-Latn"
        ],
        "main_score": -0.012204206100045759,
        "manhattan_pearson": -0.06079681916255103,
        "manhattan_spearman": -0.050925623879374535,
        "pearson": -0.01771966568645947,
        "spearman": -0.012204206100045759
      }
    ]
  },
  "task_name": "STS17"
}