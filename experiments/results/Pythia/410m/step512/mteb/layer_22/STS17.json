{
  "dataset_revision": "faeb762787bd10488a50c8b5be4a3b82e411949c",
  "evaluation_time": 17.894676446914673,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.028745507589656594,
        "cosine_spearman": 0.013292107373665029,
        "euclidean_pearson": 0.014573539335325136,
        "euclidean_spearman": -0.007667872908234689,
        "hf_subset": "es-en",
        "languages": [
          "spa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.013292107373665029,
        "manhattan_pearson": 0.007733981086112375,
        "manhattan_spearman": -0.014694513889720383,
        "pearson": 0.028745507589656594,
        "spearman": 0.013292107373665029
      },
      {
        "cosine_pearson": 0.0798110199876294,
        "cosine_spearman": 0.10830158637952104,
        "euclidean_pearson": 0.02101995034103971,
        "euclidean_spearman": 0.045457907861772416,
        "hf_subset": "en-tr",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ],
        "main_score": 0.10830158637952104,
        "manhattan_pearson": 0.02960160762063547,
        "manhattan_spearman": 0.050845497516840844,
        "pearson": 0.0798110199876294,
        "spearman": 0.10830158637952104
      },
      {
        "cosine_pearson": 0.27160633615787044,
        "cosine_spearman": 0.30336850713108293,
        "euclidean_pearson": 0.2815550867000935,
        "euclidean_spearman": 0.2804522640945694,
        "hf_subset": "en-en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.30336850713108293,
        "manhattan_pearson": 0.28028405420151825,
        "manhattan_spearman": 0.28000444211256836,
        "pearson": 0.27160633615787044,
        "spearman": 0.30336850713108293
      },
      {
        "cosine_pearson": 0.10156947949938919,
        "cosine_spearman": 0.1358238305461107,
        "euclidean_pearson": 0.07611987954564471,
        "euclidean_spearman": 0.1037303902152294,
        "hf_subset": "en-de",
        "languages": [
          "eng-Latn",
          "deu-Latn"
        ],
        "main_score": 0.1358238305461107,
        "manhattan_pearson": 0.07148222393399975,
        "manhattan_spearman": 0.10032365586478133,
        "pearson": 0.10156947949938919,
        "spearman": 0.1358238305461107
      },
      {
        "cosine_pearson": -0.09321572993606932,
        "cosine_spearman": -0.08798567976496185,
        "euclidean_pearson": -0.10069388488785923,
        "euclidean_spearman": -0.06404084980546547,
        "hf_subset": "it-en",
        "languages": [
          "ita-Latn",
          "eng-Latn"
        ],
        "main_score": -0.08798567976496185,
        "manhattan_pearson": -0.0999660276738147,
        "manhattan_spearman": -0.07036917022579536,
        "pearson": -0.09321572993606932,
        "spearman": -0.08798567976496185
      },
      {
        "cosine_pearson": -0.017173592699973612,
        "cosine_spearman": -0.02245221815167636,
        "euclidean_pearson": -0.06790052014966674,
        "euclidean_spearman": -0.06687077721447164,
        "hf_subset": "nl-en",
        "languages": [
          "nld-Latn",
          "eng-Latn"
        ],
        "main_score": -0.02245221815167636,
        "manhattan_pearson": -0.06673440648710806,
        "manhattan_spearman": -0.0664706204048037,
        "pearson": -0.017173592699973612,
        "spearman": -0.02245221815167636
      },
      {
        "cosine_pearson": -0.008959950467682625,
        "cosine_spearman": -0.01902044284526319,
        "euclidean_pearson": -0.010922025686818685,
        "euclidean_spearman": -0.025749730298006212,
        "hf_subset": "en-ar",
        "languages": [
          "eng-Latn",
          "ara-Arab"
        ],
        "main_score": -0.01902044284526319,
        "manhattan_pearson": 0.008795943281848172,
        "manhattan_spearman": -0.011441633784467956,
        "pearson": -0.008959950467682625,
        "spearman": -0.01902044284526319
      },
      {
        "cosine_pearson": -0.01696640866625288,
        "cosine_spearman": -0.00032596827531068077,
        "euclidean_pearson": -0.04484622059548238,
        "euclidean_spearman": -0.03807678476317782,
        "hf_subset": "fr-en",
        "languages": [
          "fra-Latn",
          "eng-Latn"
        ],
        "main_score": -0.00032596827531068077,
        "manhattan_pearson": -0.04222106444767164,
        "manhattan_spearman": -0.032870902271983776,
        "pearson": -0.01696640866625288,
        "spearman": -0.00032596827531068077
      }
    ]
  },
  "task_name": "STS17"
}