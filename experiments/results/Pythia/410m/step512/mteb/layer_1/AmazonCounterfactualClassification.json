{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 23.361417770385742,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.6817091454272863,
        "ap": 0.17619280234310225,
        "ap_weighted": 0.17619280234310225,
        "f1": 0.5546448483229527,
        "f1_weighted": 0.7413559734102957,
        "hf_subset": "en-ext",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6817091454272863,
        "scores_per_experiment": [
          {
            "accuracy": 0.7308845577211395,
            "ap": 0.19682483744292767,
            "ap_weighted": 0.19682483744292767,
            "f1": 0.5916262689570783,
            "f1_weighted": 0.7804025885140085
          },
          {
            "accuracy": 0.6829085457271364,
            "ap": 0.1827492434960027,
            "ap_weighted": 0.1827492434960027,
            "f1": 0.560024669968991,
            "f1_weighted": 0.7440890285514047
          },
          {
            "accuracy": 0.7548725637181409,
            "ap": 0.1912864620737303,
            "ap_weighted": 0.1912864620737303,
            "f1": 0.5994306677257472,
            "f1_weighted": 0.7969597196727601
          },
          {
            "accuracy": 0.6304347826086957,
            "ap": 0.16047944274847722,
            "ap_weighted": 0.16047944274847722,
            "f1": 0.520387096303697,
            "f1_weighted": 0.7022499393992816
          },
          {
            "accuracy": 0.6041979010494752,
            "ap": 0.15657683070543105,
            "ap_weighted": 0.15657683070543105,
            "f1": 0.5046583850931676,
            "f1_weighted": 0.6804338513972826
          },
          {
            "accuracy": 0.6701649175412294,
            "ap": 0.18230981904815188,
            "ap_weighted": 0.18230981904815188,
            "f1": 0.5534497029895802,
            "f1_weighted": 0.7341700351985853
          },
          {
            "accuracy": 0.6251874062968515,
            "ap": 0.16021209806378406,
            "ap_weighted": 0.16021209806378406,
            "f1": 0.5175951212738381,
            "f1_weighted": 0.6979402847409844
          },
          {
            "accuracy": 0.7391304347826086,
            "ap": 0.20133592942404363,
            "ap_weighted": 0.20133592942404363,
            "f1": 0.5982261548687271,
            "f1_weighted": 0.7865741543485485
          },
          {
            "accuracy": 0.6041979010494752,
            "ap": 0.1463511950608482,
            "ap_weighted": 0.1463511950608482,
            "f1": 0.4978097193702944,
            "f1_weighted": 0.6807835302061495
          },
          {
            "accuracy": 0.775112443778111,
            "ap": 0.18380216536762595,
            "ap_weighted": 0.18380216536762595,
            "f1": 0.603240696678405,
            "f1_weighted": 0.8099566020739511
          }
        ]
      },
      {
        "accuracy": 0.7086567164179105,
        "ap": 0.33336563408937875,
        "ap_weighted": 0.33336563408937875,
        "f1": 0.6477087408064418,
        "f1_weighted": 0.7363430604788352,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7086567164179105,
        "scores_per_experiment": [
          {
            "accuracy": 0.664179104477612,
            "ap": 0.3136921680460747,
            "ap_weighted": 0.3136921680460747,
            "f1": 0.6161494763591364,
            "f1_weighted": 0.6988333931200563
          },
          {
            "accuracy": 0.7089552238805971,
            "ap": 0.35019840115147255,
            "ap_weighted": 0.35019840115147255,
            "f1": 0.6568875909648378,
            "f1_weighted": 0.7382806723044154
          },
          {
            "accuracy": 0.7626865671641792,
            "ap": 0.34945425544035547,
            "ap_weighted": 0.34945425544035547,
            "f1": 0.6810278490563777,
            "f1_weighted": 0.7793073681949704
          },
          {
            "accuracy": 0.6328358208955224,
            "ap": 0.27783240099103906,
            "ap_weighted": 0.27783240099103906,
            "f1": 0.5808282723471786,
            "f1_weighted": 0.6707396274646543
          },
          {
            "accuracy": 0.7373134328358208,
            "ap": 0.34471049724675445,
            "ap_weighted": 0.34471049724675445,
            "f1": 0.6680778238155287,
            "f1_weighted": 0.7603919691759183
          },
          {
            "accuracy": 0.6880597014925374,
            "ap": 0.3008531812798249,
            "ap_weighted": 0.3008531812798249,
            "f1": 0.6214781355845154,
            "f1_weighted": 0.7181517259420704
          },
          {
            "accuracy": 0.7029850746268657,
            "ap": 0.34154088145684885,
            "ap_weighted": 0.34154088145684885,
            "f1": 0.6498493877025779,
            "f1_weighted": 0.7329120707106596
          },
          {
            "accuracy": 0.7716417910447761,
            "ap": 0.38783752990771336,
            "ap_weighted": 0.38783752990771336,
            "f1": 0.7047004225972882,
            "f1_weighted": 0.7903182229940753
          },
          {
            "accuracy": 0.6925373134328359,
            "ap": 0.3238536671258558,
            "ap_weighted": 0.3238536671258558,
            "f1": 0.6360270461282054,
            "f1_weighted": 0.7233610955989977
          },
          {
            "accuracy": 0.7253731343283583,
            "ap": 0.34368335824784846,
            "ap_weighted": 0.34368335824784846,
            "f1": 0.662061403508772,
            "f1_weighted": 0.7511344592825346
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}