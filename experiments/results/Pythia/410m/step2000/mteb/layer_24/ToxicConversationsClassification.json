{
  "dataset_revision": "edfaf9da55d3dd50d43143d90c1ac476895ae6de",
  "evaluation_time": 54.921597480773926,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.59873046875,
        "ap": 0.09611533200198437,
        "ap_weighted": 0.09611533200198437,
        "f1": 0.4565549872738828,
        "f1_weighted": 0.6867924541384729,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.59873046875,
        "scores_per_experiment": [
          {
            "accuracy": 0.50244140625,
            "ap": 0.09805115294423718,
            "ap_weighted": 0.09805115294423718,
            "f1": 0.41311334982984627,
            "f1_weighted": 0.6058562400280252
          },
          {
            "accuracy": 0.607421875,
            "ap": 0.1004386594890754,
            "ap_weighted": 0.1004386594890754,
            "f1": 0.466708122813836,
            "f1_weighted": 0.6973074657500973
          },
          {
            "accuracy": 0.6669921875,
            "ap": 0.09284901582716976,
            "ap_weighted": 0.09284901582716976,
            "f1": 0.4838190859690514,
            "f1_weighted": 0.7426636982963918
          },
          {
            "accuracy": 0.7138671875,
            "ap": 0.10672097151292903,
            "ap_weighted": 0.10672097151292903,
            "f1": 0.5187722945056072,
            "f1_weighted": 0.7767044996607706
          },
          {
            "accuracy": 0.5078125,
            "ap": 0.08439295313776,
            "ap_weighted": 0.08439295313776,
            "f1": 0.4030363143192583,
            "f1_weighted": 0.613565619812963
          },
          {
            "accuracy": 0.4658203125,
            "ap": 0.08236714013432253,
            "ap_weighted": 0.08236714013432253,
            "f1": 0.37946406810154965,
            "f1_weighted": 0.5743307766655921
          },
          {
            "accuracy": 0.70947265625,
            "ap": 0.10293974474385353,
            "ap_weighted": 0.10293974474385353,
            "f1": 0.5129078072017342,
            "f1_weighted": 0.7733826725047398
          },
          {
            "accuracy": 0.58251953125,
            "ap": 0.09442961886534573,
            "ap_weighted": 0.09442961886534573,
            "f1": 0.44940264224095233,
            "f1_weighted": 0.6773008712892126
          },
          {
            "accuracy": 0.59326171875,
            "ap": 0.10114415513688679,
            "ap_weighted": 0.10114415513688679,
            "f1": 0.46082762156065005,
            "f1_weighted": 0.6857698713679794
          },
          {
            "accuracy": 0.6376953125,
            "ap": 0.09781990822826372,
            "ap_weighted": 0.09781990822826372,
            "f1": 0.47749856619634246,
            "f1_weighted": 0.7210428260089577
          }
        ]
      }
    ]
  },
  "task_name": "ToxicConversationsClassification"
}