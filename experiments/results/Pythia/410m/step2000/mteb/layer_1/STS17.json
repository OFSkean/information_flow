{
  "dataset_revision": "faeb762787bd10488a50c8b5be4a3b82e411949c",
  "evaluation_time": 20.11179494857788,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.08108676827218522,
        "cosine_spearman": 0.06631957646788804,
        "euclidean_pearson": -0.07493692966595153,
        "euclidean_spearman": -0.09640071377020754,
        "hf_subset": "en-ar",
        "languages": [
          "eng-Latn",
          "ara-Arab"
        ],
        "main_score": 0.06631957646788804,
        "manhattan_pearson": -0.07809662744335069,
        "manhattan_spearman": -0.10153974290054693,
        "pearson": 0.08108676827218522,
        "spearman": 0.06631957646788804
      },
      {
        "cosine_pearson": 0.5494049310456566,
        "cosine_spearman": 0.5696372490364361,
        "euclidean_pearson": 0.5059584361730232,
        "euclidean_spearman": 0.5159501203341466,
        "hf_subset": "en-en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5696372490364361,
        "manhattan_pearson": 0.5041767330707799,
        "manhattan_spearman": 0.514283761285241,
        "pearson": 0.5494049310456566,
        "spearman": 0.5696372490364361
      },
      {
        "cosine_pearson": -0.11535095907772837,
        "cosine_spearman": -0.08676583765055483,
        "euclidean_pearson": -0.19451554851694508,
        "euclidean_spearman": -0.14732691288691183,
        "hf_subset": "en-tr",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ],
        "main_score": -0.08676583765055483,
        "manhattan_pearson": -0.18779267043466213,
        "manhattan_spearman": -0.14142067209042558,
        "pearson": -0.11535095907772837,
        "spearman": -0.08676583765055483
      },
      {
        "cosine_pearson": -0.0055159086497451925,
        "cosine_spearman": -0.026585752473773098,
        "euclidean_pearson": -0.05476362395208872,
        "euclidean_spearman": -0.1256603380313845,
        "hf_subset": "es-en",
        "languages": [
          "spa-Latn",
          "eng-Latn"
        ],
        "main_score": -0.026585752473773098,
        "manhattan_pearson": -0.05527226555752252,
        "manhattan_spearman": -0.1230892352914431,
        "pearson": -0.0055159086497451925,
        "spearman": -0.026585752473773098
      },
      {
        "cosine_pearson": -0.020208581584492007,
        "cosine_spearman": 0.009384657397918585,
        "euclidean_pearson": -0.0943353612732134,
        "euclidean_spearman": -0.06481233368347082,
        "hf_subset": "it-en",
        "languages": [
          "ita-Latn",
          "eng-Latn"
        ],
        "main_score": 0.009384657397918585,
        "manhattan_pearson": -0.08802276171915482,
        "manhattan_spearman": -0.06095183912103549,
        "pearson": -0.020208581584492007,
        "spearman": 0.009384657397918585
      },
      {
        "cosine_pearson": 0.021792894135212765,
        "cosine_spearman": 0.006424419558098358,
        "euclidean_pearson": -0.07512100759452031,
        "euclidean_spearman": -0.07543859194135816,
        "hf_subset": "nl-en",
        "languages": [
          "nld-Latn",
          "eng-Latn"
        ],
        "main_score": 0.006424419558098358,
        "manhattan_pearson": -0.07210112485616964,
        "manhattan_spearman": -0.07022732789844909,
        "pearson": 0.021792894135212765,
        "spearman": 0.006424419558098358
      },
      {
        "cosine_pearson": 0.04098203687337885,
        "cosine_spearman": 0.07928409503830161,
        "euclidean_pearson": -0.05589191397537807,
        "euclidean_spearman": -0.04594269138780337,
        "hf_subset": "en-de",
        "languages": [
          "eng-Latn",
          "deu-Latn"
        ],
        "main_score": 0.07928409503830161,
        "manhattan_pearson": -0.05224821329031091,
        "manhattan_spearman": -0.04067184587947783,
        "pearson": 0.04098203687337885,
        "spearman": 0.07928409503830161
      },
      {
        "cosine_pearson": 0.010014096000974804,
        "cosine_spearman": 0.020149298414192527,
        "euclidean_pearson": -0.06722466777405656,
        "euclidean_spearman": -0.07035917591546743,
        "hf_subset": "fr-en",
        "languages": [
          "fra-Latn",
          "eng-Latn"
        ],
        "main_score": 0.020149298414192527,
        "manhattan_pearson": -0.07004076650392296,
        "manhattan_spearman": -0.07163229729262424,
        "pearson": 0.010014096000974804,
        "spearman": 0.020149298414192527
      }
    ]
  },
  "task_name": "STS17"
}