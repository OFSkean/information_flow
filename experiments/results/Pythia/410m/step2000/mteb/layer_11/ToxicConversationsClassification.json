{
  "dataset_revision": "edfaf9da55d3dd50d43143d90c1ac476895ae6de",
  "evaluation_time": 33.44786763191223,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.595654296875,
        "ap": 0.09513670604825472,
        "ap_weighted": 0.09513670604825472,
        "f1": 0.4541772496488038,
        "f1_weighted": 0.6839594683166894,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.595654296875,
        "scores_per_experiment": [
          {
            "accuracy": 0.572265625,
            "ap": 0.09925572273662552,
            "ap_weighted": 0.09925572273662552,
            "f1": 0.449218980253463,
            "f1_weighted": 0.668364037632626
          },
          {
            "accuracy": 0.5966796875,
            "ap": 0.09043636485042736,
            "ap_weighted": 0.09043636485042736,
            "f1": 0.45136713251786664,
            "f1_weighted": 0.6890510459801036
          },
          {
            "accuracy": 0.6572265625,
            "ap": 0.0972430889423077,
            "ap_weighted": 0.0972430889423077,
            "f1": 0.4851485148514852,
            "f1_weighted": 0.7357081045018565
          },
          {
            "accuracy": 0.6748046875,
            "ap": 0.09872174157178958,
            "ap_weighted": 0.09872174157178958,
            "f1": 0.49410117027084777,
            "f1_weighted": 0.7486214837537388
          },
          {
            "accuracy": 0.46240234375,
            "ap": 0.08870484983766234,
            "ap_weighted": 0.08870484983766234,
            "f1": 0.3839117166578824,
            "f1_weighted": 0.5690250423853936
          },
          {
            "accuracy": 0.44091796875,
            "ap": 0.08437860981214562,
            "ap_weighted": 0.08437860981214562,
            "f1": 0.36815313534767935,
            "f1_weighted": 0.5486518012262417
          },
          {
            "accuracy": 0.7158203125,
            "ap": 0.10339664808723195,
            "ap_weighted": 0.10339664808723195,
            "f1": 0.5159548546811953,
            "f1_weighted": 0.777784679361757
          },
          {
            "accuracy": 0.5908203125,
            "ap": 0.09289870189214879,
            "ap_weighted": 0.09289870189214879,
            "f1": 0.45155946415788945,
            "f1_weighted": 0.6842006487914154
          },
          {
            "accuracy": 0.59326171875,
            "ap": 0.09598882619036044,
            "ap_weighted": 0.09598882619036044,
            "f1": 0.45590683098477014,
            "f1_weighted": 0.686032998630306
          },
          {
            "accuracy": 0.65234375,
            "ap": 0.1003425065618481,
            "ap_weighted": 0.1003425065618481,
            "f1": 0.48645069676495944,
            "f1_weighted": 0.732154840903456
          }
        ]
      }
    ]
  },
  "task_name": "ToxicConversationsClassification"
}