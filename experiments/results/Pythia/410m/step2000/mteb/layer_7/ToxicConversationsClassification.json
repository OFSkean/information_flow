{
  "dataset_revision": "edfaf9da55d3dd50d43143d90c1ac476895ae6de",
  "evaluation_time": 27.256518602371216,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.5865234375,
        "ap": 0.0942806229623935,
        "ap_weighted": 0.0942806229623935,
        "f1": 0.4488715231269079,
        "f1_weighted": 0.6763796842502265,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5865234375,
        "scores_per_experiment": [
          {
            "accuracy": 0.55126953125,
            "ap": 0.09681238847584389,
            "ap_weighted": 0.09681238847584389,
            "f1": 0.4368938254983357,
            "f1_weighted": 0.6505273213985189
          },
          {
            "accuracy": 0.60009765625,
            "ap": 0.09218093228305708,
            "ap_weighted": 0.09218093228305708,
            "f1": 0.45489697129235585,
            "f1_weighted": 0.6917238216868483
          },
          {
            "accuracy": 0.65283203125,
            "ap": 0.09804931155842614,
            "ap_weighted": 0.09804931155842614,
            "f1": 0.484202796749488,
            "f1_weighted": 0.7324665032216336
          },
          {
            "accuracy": 0.66650390625,
            "ap": 0.093495609694772,
            "ap_weighted": 0.093495609694772,
            "f1": 0.48445515744237,
            "f1_weighted": 0.7423450859093824
          },
          {
            "accuracy": 0.494140625,
            "ap": 0.088872220289631,
            "ap_weighted": 0.088872220289631,
            "f1": 0.4008855154965212,
            "f1_weighted": 0.5998605263678052
          },
          {
            "accuracy": 0.40625,
            "ap": 0.08550467785493827,
            "ap_weighted": 0.08550467785493827,
            "f1": 0.3492752153868184,
            "f1_weighted": 0.5113618963655729
          },
          {
            "accuracy": 0.6865234375,
            "ap": 0.09759510719797176,
            "ap_weighted": 0.09759510719797176,
            "f1": 0.49754200601658227,
            "f1_weighted": 0.7569400855368149
          },
          {
            "accuracy": 0.5615234375,
            "ap": 0.08626686178711898,
            "ap_weighted": 0.08626686178711898,
            "f1": 0.4306144310491087,
            "f1_weighted": 0.660438389421142
          },
          {
            "accuracy": 0.5908203125,
            "ap": 0.10150398973800584,
            "ap_weighted": 0.10150398973800584,
            "f1": 0.46000805477245266,
            "f1_weighted": 0.6837385431874244
          },
          {
            "accuracy": 0.6552734375,
            "ap": 0.10252513074417009,
            "ap_weighted": 0.10252513074417009,
            "f1": 0.48994125756504636,
            "f1_weighted": 0.7343946694071218
          }
        ]
      }
    ]
  },
  "task_name": "ToxicConversationsClassification"
}