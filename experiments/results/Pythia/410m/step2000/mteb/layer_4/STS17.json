{
  "dataset_revision": "faeb762787bd10488a50c8b5be4a3b82e411949c",
  "evaluation_time": 19.721980810165405,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.12042500626259629,
        "cosine_spearman": 0.12382950496295128,
        "euclidean_pearson": -0.019953535964113076,
        "euclidean_spearman": -0.02106454660229952,
        "hf_subset": "fr-en",
        "languages": [
          "fra-Latn",
          "eng-Latn"
        ],
        "main_score": 0.12382950496295128,
        "manhattan_pearson": -0.025855070571215465,
        "manhattan_spearman": -0.02029575350015169,
        "pearson": 0.12042500626259629,
        "spearman": 0.12382950496295128
      },
      {
        "cosine_pearson": 0.5738002887992473,
        "cosine_spearman": 0.5830442319447922,
        "euclidean_pearson": 0.5257131435411194,
        "euclidean_spearman": 0.5414913491702529,
        "hf_subset": "en-en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5830442319447922,
        "manhattan_pearson": 0.5253609735354509,
        "manhattan_spearman": 0.5412956913257563,
        "pearson": 0.5738002887992473,
        "spearman": 0.5830442319447922
      },
      {
        "cosine_pearson": 0.008149718179090035,
        "cosine_spearman": 0.01654978084325195,
        "euclidean_pearson": -0.08013798486634263,
        "euclidean_spearman": -0.15849923095861934,
        "hf_subset": "es-en",
        "languages": [
          "spa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.01654978084325195,
        "manhattan_pearson": -0.08718327552868484,
        "manhattan_spearman": -0.14674792548088356,
        "pearson": 0.008149718179090035,
        "spearman": 0.01654978084325195
      },
      {
        "cosine_pearson": 0.14179662254783998,
        "cosine_spearman": 0.1862136056332882,
        "euclidean_pearson": 0.00034611148870967746,
        "euclidean_spearman": 0.03540023157805015,
        "hf_subset": "en-de",
        "languages": [
          "eng-Latn",
          "deu-Latn"
        ],
        "main_score": 0.1862136056332882,
        "manhattan_pearson": -0.00917116971731463,
        "manhattan_spearman": 0.018853113243971282,
        "pearson": 0.14179662254783998,
        "spearman": 0.1862136056332882
      },
      {
        "cosine_pearson": 0.12968262731996535,
        "cosine_spearman": 0.13756099667763155,
        "euclidean_pearson": -0.08721409028458187,
        "euclidean_spearman": -0.10401065914333409,
        "hf_subset": "en-ar",
        "languages": [
          "eng-Latn",
          "ara-Arab"
        ],
        "main_score": 0.13756099667763155,
        "manhattan_pearson": -0.07388588338647716,
        "manhattan_spearman": -0.10106577903505898,
        "pearson": 0.12968262731996535,
        "spearman": 0.13756099667763155
      },
      {
        "cosine_pearson": 0.07983176373952397,
        "cosine_spearman": 0.08729299717992664,
        "euclidean_pearson": -0.06035384926765053,
        "euclidean_spearman": -0.03153551470846928,
        "hf_subset": "it-en",
        "languages": [
          "ita-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08729299717992664,
        "manhattan_pearson": -0.0648007004841721,
        "manhattan_spearman": -0.035640479422471345,
        "pearson": 0.07983176373952397,
        "spearman": 0.08729299717992664
      },
      {
        "cosine_pearson": -0.056538894779864915,
        "cosine_spearman": -0.049768979209969255,
        "euclidean_pearson": -0.1868488934204002,
        "euclidean_spearman": -0.1555238308520912,
        "hf_subset": "en-tr",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ],
        "main_score": -0.049768979209969255,
        "manhattan_pearson": -0.19071359779478617,
        "manhattan_spearman": -0.15975839250633542,
        "pearson": -0.056538894779864915,
        "spearman": -0.049768979209969255
      },
      {
        "cosine_pearson": 0.12072124116354983,
        "cosine_spearman": 0.12222426496566663,
        "euclidean_pearson": -0.02031963973087805,
        "euclidean_spearman": -0.0006238756023929657,
        "hf_subset": "nl-en",
        "languages": [
          "nld-Latn",
          "eng-Latn"
        ],
        "main_score": 0.12222426496566663,
        "manhattan_pearson": -0.014192207320030653,
        "manhattan_spearman": 0.0016805817212951605,
        "pearson": 0.12072124116354983,
        "spearman": 0.12222426496566663
      }
    ]
  },
  "task_name": "STS17"
}