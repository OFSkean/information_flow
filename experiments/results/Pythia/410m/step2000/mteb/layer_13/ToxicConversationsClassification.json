{
  "dataset_revision": "edfaf9da55d3dd50d43143d90c1ac476895ae6de",
  "evaluation_time": 39.69072890281677,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.594189453125,
        "ap": 0.0949272286232444,
        "ap_weighted": 0.0949272286232444,
        "f1": 0.45323661968421114,
        "f1_weighted": 0.6826443379510392,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.594189453125,
        "scores_per_experiment": [
          {
            "accuracy": 0.58203125,
            "ap": 0.09171684974586589,
            "ap_weighted": 0.09171684974586589,
            "f1": 0.44629557804092596,
            "f1_weighted": 0.6770729926932373
          },
          {
            "accuracy": 0.5810546875,
            "ap": 0.09158853780422777,
            "ap_weighted": 0.09158853780422777,
            "f1": 0.4457112574759634,
            "f1_weighted": 0.6762765473588084
          },
          {
            "accuracy": 0.65966796875,
            "ap": 0.1000426310356409,
            "ap_weighted": 0.1000426310356409,
            "f1": 0.4892484833522075,
            "f1_weighted": 0.7376028306267587
          },
          {
            "accuracy": 0.7060546875,
            "ap": 0.10045594240782732,
            "ap_weighted": 0.10045594240782732,
            "f1": 0.5087085076708507,
            "f1_weighted": 0.7708231563807532
          },
          {
            "accuracy": 0.45361328125,
            "ap": 0.08720802170147125,
            "ap_weighted": 0.08720802170147125,
            "f1": 0.3777727819577044,
            "f1_weighted": 0.5606385452862606
          },
          {
            "accuracy": 0.44482421875,
            "ap": 0.08789385347254508,
            "ap_weighted": 0.08789385347254508,
            "f1": 0.37350366159486204,
            "f1_weighted": 0.551443807087565
          },
          {
            "accuracy": 0.6806640625,
            "ap": 0.09815834190340367,
            "ap_weighted": 0.09815834190340367,
            "f1": 0.49584447495844475,
            "f1_weighted": 0.7528033208629942
          },
          {
            "accuracy": 0.57275390625,
            "ap": 0.08990386889572831,
            "ap_weighted": 0.08990386889572831,
            "f1": 0.440051620241259,
            "f1_weighted": 0.6695187627478482
          },
          {
            "accuracy": 0.59912109375,
            "ap": 0.09759888636545834,
            "ap_weighted": 0.09759888636545834,
            "f1": 0.4601845457612938,
            "f1_weighted": 0.6907202615770103
          },
          {
            "accuracy": 0.662109375,
            "ap": 0.10470535290027551,
            "ap_weighted": 0.10470535290027551,
            "f1": 0.49504528578859974,
            "f1_weighted": 0.7395431548891549
          }
        ]
      }
    ]
  },
  "task_name": "ToxicConversationsClassification"
}