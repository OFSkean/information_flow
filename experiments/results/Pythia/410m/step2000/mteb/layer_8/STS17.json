{
  "dataset_revision": "faeb762787bd10488a50c8b5be4a3b82e411949c",
  "evaluation_time": 17.40869116783142,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.2936851554210319,
        "cosine_spearman": 0.3137240919693233,
        "euclidean_pearson": 0.08353303644202062,
        "euclidean_spearman": 0.08068176089800638,
        "hf_subset": "fr-en",
        "languages": [
          "fra-Latn",
          "eng-Latn"
        ],
        "main_score": 0.3137240919693233,
        "manhattan_pearson": 0.09230304550950473,
        "manhattan_spearman": 0.09217906174062719,
        "pearson": 0.2936851554210319,
        "spearman": 0.3137240919693233
      },
      {
        "cosine_pearson": 0.25502521492347857,
        "cosine_spearman": 0.26177712645374535,
        "euclidean_pearson": 0.0798450734133339,
        "euclidean_spearman": 0.09822600388557097,
        "hf_subset": "nl-en",
        "languages": [
          "nld-Latn",
          "eng-Latn"
        ],
        "main_score": 0.26177712645374535,
        "manhattan_pearson": 0.0836716616245187,
        "manhattan_spearman": 0.09582006587239933,
        "pearson": 0.25502521492347857,
        "spearman": 0.26177712645374535
      },
      {
        "cosine_pearson": 0.24657491893457706,
        "cosine_spearman": 0.270506772128634,
        "euclidean_pearson": 0.11235177111675793,
        "euclidean_spearman": 0.15850591783532925,
        "hf_subset": "en-de",
        "languages": [
          "eng-Latn",
          "deu-Latn"
        ],
        "main_score": 0.270506772128634,
        "manhattan_pearson": 0.10803982531256347,
        "manhattan_spearman": 0.15537577671993438,
        "pearson": 0.24657491893457706,
        "spearman": 0.270506772128634
      },
      {
        "cosine_pearson": 0.22226409522300783,
        "cosine_spearman": 0.2138308571270304,
        "euclidean_pearson": 0.018805583782538885,
        "euclidean_spearman": -0.04891930690092111,
        "hf_subset": "es-en",
        "languages": [
          "spa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.2138308571270304,
        "manhattan_pearson": 0.033582221606559146,
        "manhattan_spearman": -0.027715212546188295,
        "pearson": 0.22226409522300783,
        "spearman": 0.2138308571270304
      },
      {
        "cosine_pearson": 0.5847963109488815,
        "cosine_spearman": 0.5901932390016648,
        "euclidean_pearson": 0.5328745309706739,
        "euclidean_spearman": 0.5336365900456085,
        "hf_subset": "en-en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5901932390016648,
        "manhattan_pearson": 0.5336954591803166,
        "manhattan_spearman": 0.5357469271110044,
        "pearson": 0.5847963109488815,
        "spearman": 0.5901932390016648
      },
      {
        "cosine_pearson": 0.2189552720207512,
        "cosine_spearman": 0.22520909815353266,
        "euclidean_pearson": 0.017358137671971047,
        "euclidean_spearman": 0.0441825395804359,
        "hf_subset": "it-en",
        "languages": [
          "ita-Latn",
          "eng-Latn"
        ],
        "main_score": 0.22520909815353266,
        "manhattan_pearson": 0.011094433470846493,
        "manhattan_spearman": 0.04452349932123847,
        "pearson": 0.2189552720207512,
        "spearman": 0.22520909815353266
      },
      {
        "cosine_pearson": 0.10378887607921314,
        "cosine_spearman": 0.08437058441776553,
        "euclidean_pearson": -0.1006176883622548,
        "euclidean_spearman": -0.07176493951512307,
        "hf_subset": "en-tr",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ],
        "main_score": 0.08437058441776553,
        "manhattan_pearson": -0.09459734973888916,
        "manhattan_spearman": -0.06326428959907632,
        "pearson": 0.10378887607921314,
        "spearman": 0.08437058441776553
      },
      {
        "cosine_pearson": 0.23116594323218215,
        "cosine_spearman": 0.2171269598484514,
        "euclidean_pearson": -0.020340537802710258,
        "euclidean_spearman": -0.032728877047235184,
        "hf_subset": "en-ar",
        "languages": [
          "eng-Latn",
          "ara-Arab"
        ],
        "main_score": 0.2171269598484514,
        "manhattan_pearson": -0.0142847991475643,
        "manhattan_spearman": -0.02954451641325122,
        "pearson": 0.23116594323218215,
        "spearman": 0.2171269598484514
      }
    ]
  },
  "task_name": "STS17"
}