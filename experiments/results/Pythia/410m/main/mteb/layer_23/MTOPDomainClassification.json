{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 55.124842405319214,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.8084131326949384,
        "f1": 0.8058012418843786,
        "f1_weighted": 0.8089816550999247,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8084131326949384,
        "scores_per_experiment": [
          {
            "accuracy": 0.7820337437300502,
            "f1": 0.7787680906531077,
            "f1_weighted": 0.7786605499996878
          },
          {
            "accuracy": 0.8264933880528956,
            "f1": 0.8254621196447655,
            "f1_weighted": 0.8271088704888283
          },
          {
            "accuracy": 0.8066575467396261,
            "f1": 0.8007966051939747,
            "f1_weighted": 0.8078345358070403
          },
          {
            "accuracy": 0.8230734154126766,
            "f1": 0.8187256863454241,
            "f1_weighted": 0.8227004372295665
          },
          {
            "accuracy": 0.8372093023255814,
            "f1": 0.8336473425302157,
            "f1_weighted": 0.8389982220970033
          },
          {
            "accuracy": 0.8034655722754218,
            "f1": 0.8030968038673687,
            "f1_weighted": 0.8041940704319824
          },
          {
            "accuracy": 0.8000455996352029,
            "f1": 0.7989234202315334,
            "f1_weighted": 0.7964908868913766
          },
          {
            "accuracy": 0.79046967624259,
            "f1": 0.7890924102127925,
            "f1_weighted": 0.7941655509081741
          },
          {
            "accuracy": 0.8230734154126766,
            "f1": 0.819462706597577,
            "f1_weighted": 0.8251964697281842
          },
          {
            "accuracy": 0.791609667122663,
            "f1": 0.7900372335670266,
            "f1_weighted": 0.7944669574174037
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.8006263982102908,
        "f1": 0.8025419429919332,
        "f1_weighted": 0.8011180280556646,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8006263982102908,
        "scores_per_experiment": [
          {
            "accuracy": 0.7664429530201342,
            "f1": 0.768342298431127,
            "f1_weighted": 0.7630529332211672
          },
          {
            "accuracy": 0.8348993288590604,
            "f1": 0.836915479336248,
            "f1_weighted": 0.8353699365466822
          },
          {
            "accuracy": 0.7977628635346756,
            "f1": 0.7947723551174746,
            "f1_weighted": 0.7989252963792839
          },
          {
            "accuracy": 0.8223713646532439,
            "f1": 0.8241499782132962,
            "f1_weighted": 0.8217756475033212
          },
          {
            "accuracy": 0.8237136465324385,
            "f1": 0.825874398465229,
            "f1_weighted": 0.8248773697942715
          },
          {
            "accuracy": 0.7941834451901566,
            "f1": 0.7964986695712839,
            "f1_weighted": 0.7941468313369608
          },
          {
            "accuracy": 0.7906040268456376,
            "f1": 0.7938865742178169,
            "f1_weighted": 0.78920912244919
          },
          {
            "accuracy": 0.7847874720357941,
            "f1": 0.7917345855924939,
            "f1_weighted": 0.7888044732406426
          },
          {
            "accuracy": 0.8116331096196868,
            "f1": 0.80991522805204,
            "f1_weighted": 0.8124960473030143
          },
          {
            "accuracy": 0.7798657718120805,
            "f1": 0.7833298629223214,
            "f1_weighted": 0.7825226227821127
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}