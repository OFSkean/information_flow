{
  "dataset_revision": "4672e20407010da34463acc759c162ca9734bca6",
  "evaluation_time": 90.55757355690002,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.566072629455279,
        "f1": 0.5344001526266672,
        "f1_weighted": 0.5711270741740084,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.566072629455279,
        "scores_per_experiment": [
          {
            "accuracy": 0.5675857431069267,
            "f1": 0.5461831426752365,
            "f1_weighted": 0.5723141212316377
          },
          {
            "accuracy": 0.5803631472763954,
            "f1": 0.5464307481133086,
            "f1_weighted": 0.5886522887555702
          },
          {
            "accuracy": 0.5501008742434432,
            "f1": 0.5164535627215993,
            "f1_weighted": 0.5535895458627841
          },
          {
            "accuracy": 0.5847343644922663,
            "f1": 0.5439129957866194,
            "f1_weighted": 0.5889087474985423
          },
          {
            "accuracy": 0.574310692669805,
            "f1": 0.5342555518358995,
            "f1_weighted": 0.5764671445179413
          },
          {
            "accuracy": 0.5379959650302623,
            "f1": 0.5235378640854965,
            "f1_weighted": 0.5435558877251261
          },
          {
            "accuracy": 0.558843308675185,
            "f1": 0.5321252206089995,
            "f1_weighted": 0.5651402750039506
          },
          {
            "accuracy": 0.5605245460659045,
            "f1": 0.5309649801674514,
            "f1_weighted": 0.5678706006080868
          },
          {
            "accuracy": 0.5628782784129119,
            "f1": 0.5252660395644102,
            "f1_weighted": 0.568060218957887
          },
          {
            "accuracy": 0.5833893745796906,
            "f1": 0.5448714207076507,
            "f1_weighted": 0.5867119115785581
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.5733398917855386,
        "f1": 0.5379345093463459,
        "f1_weighted": 0.5779722941073202,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5733398917855386,
        "scores_per_experiment": [
          {
            "accuracy": 0.5745204131824889,
            "f1": 0.5440744465997684,
            "f1_weighted": 0.5746356258248655
          },
          {
            "accuracy": 0.5932120019675357,
            "f1": 0.5492147145243765,
            "f1_weighted": 0.5999323441792735
          },
          {
            "accuracy": 0.5843580914904083,
            "f1": 0.5466040658919972,
            "f1_weighted": 0.5880703008675704
          },
          {
            "accuracy": 0.5818986719134285,
            "f1": 0.5339047066294168,
            "f1_weighted": 0.5855190212943705
          },
          {
            "accuracy": 0.5764879488440728,
            "f1": 0.5481119737136224,
            "f1_weighted": 0.5819004046085307
          },
          {
            "accuracy": 0.5499262174126907,
            "f1": 0.5283435140073383,
            "f1_weighted": 0.5520221461407819
          },
          {
            "accuracy": 0.5469749139203148,
            "f1": 0.5232785417835281,
            "f1_weighted": 0.5551011335377867
          },
          {
            "accuracy": 0.573536645351697,
            "f1": 0.5327391823271145,
            "f1_weighted": 0.5788002514693683
          },
          {
            "accuracy": 0.5553369404820462,
            "f1": 0.5224193674274478,
            "f1_weighted": 0.5625812083452459
          },
          {
            "accuracy": 0.5971470732907034,
            "f1": 0.5506545805588499,
            "f1_weighted": 0.6011605048054093
          }
        ]
      }
    ]
  },
  "task_name": "MassiveIntentClassification"
}