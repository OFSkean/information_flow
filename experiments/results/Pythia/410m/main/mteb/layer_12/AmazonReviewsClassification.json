{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 186.25148129463196,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.37244,
        "f1": 0.3700818181460783,
        "f1_weighted": 0.3700818181460784,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.37244,
        "scores_per_experiment": [
          {
            "accuracy": 0.3876,
            "f1": 0.3902928613700462,
            "f1_weighted": 0.3902928613700462
          },
          {
            "accuracy": 0.3884,
            "f1": 0.3884739318794256,
            "f1_weighted": 0.3884739318794256
          },
          {
            "accuracy": 0.354,
            "f1": 0.3495698030568322,
            "f1_weighted": 0.34956980305683216
          },
          {
            "accuracy": 0.3892,
            "f1": 0.387786948918408,
            "f1_weighted": 0.387786948918408
          },
          {
            "accuracy": 0.4206,
            "f1": 0.398266514400209,
            "f1_weighted": 0.39826651440020905
          },
          {
            "accuracy": 0.3458,
            "f1": 0.3473607885715667,
            "f1_weighted": 0.3473607885715668
          },
          {
            "accuracy": 0.3378,
            "f1": 0.3372508638857886,
            "f1_weighted": 0.3372508638857887
          },
          {
            "accuracy": 0.3706,
            "f1": 0.36772681124769024,
            "f1_weighted": 0.36772681124769035
          },
          {
            "accuracy": 0.3626,
            "f1": 0.36543458727825656,
            "f1_weighted": 0.36543458727825656
          },
          {
            "accuracy": 0.3678,
            "f1": 0.36865507085255994,
            "f1_weighted": 0.36865507085256005
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.37516000000000005,
        "f1": 0.3721250194556237,
        "f1_weighted": 0.3721250194556237,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.37516000000000005,
        "scores_per_experiment": [
          {
            "accuracy": 0.3836,
            "f1": 0.38764003650935924,
            "f1_weighted": 0.3876400365093593
          },
          {
            "accuracy": 0.391,
            "f1": 0.39045459093226,
            "f1_weighted": 0.39045459093226
          },
          {
            "accuracy": 0.368,
            "f1": 0.36371351294606963,
            "f1_weighted": 0.3637135129460696
          },
          {
            "accuracy": 0.3838,
            "f1": 0.3823225948807446,
            "f1_weighted": 0.3823225948807446
          },
          {
            "accuracy": 0.4168,
            "f1": 0.39059014113046053,
            "f1_weighted": 0.39059014113046053
          },
          {
            "accuracy": 0.3418,
            "f1": 0.3428695444432325,
            "f1_weighted": 0.34286954444323253
          },
          {
            "accuracy": 0.3464,
            "f1": 0.344178237678799,
            "f1_weighted": 0.344178237678799
          },
          {
            "accuracy": 0.3636,
            "f1": 0.3603078317203742,
            "f1_weighted": 0.3603078317203742
          },
          {
            "accuracy": 0.3778,
            "f1": 0.3813740353972842,
            "f1_weighted": 0.38137403539728415
          },
          {
            "accuracy": 0.3788,
            "f1": 0.37779966891765315,
            "f1_weighted": 0.3777996689176531
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}