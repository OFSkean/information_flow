{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 54.27020215988159,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.8274509803921568,
        "f1": 0.8233259082826262,
        "f1_weighted": 0.8275761608833372,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8274509803921568,
        "scores_per_experiment": [
          {
            "accuracy": 0.797765617875057,
            "f1": 0.7929686138788177,
            "f1_weighted": 0.7955263746825382
          },
          {
            "accuracy": 0.8495212038303693,
            "f1": 0.8444814380622752,
            "f1_weighted": 0.8502466227077273
          },
          {
            "accuracy": 0.8228454172366622,
            "f1": 0.8145150930090487,
            "f1_weighted": 0.824323858402586
          },
          {
            "accuracy": 0.837437300501596,
            "f1": 0.8315366917827713,
            "f1_weighted": 0.8373170331523362
          },
          {
            "accuracy": 0.8568171454628363,
            "f1": 0.8524576648425463,
            "f1_weighted": 0.8572532066076629
          },
          {
            "accuracy": 0.8187414500683995,
            "f1": 0.8174890889569724,
            "f1_weighted": 0.8185059166142145
          },
          {
            "accuracy": 0.8036935704514364,
            "f1": 0.8000783902208,
            "f1_weighted": 0.8004625878352405
          },
          {
            "accuracy": 0.8301413588691291,
            "f1": 0.8246692419473579,
            "f1_weighted": 0.8325331239022847
          },
          {
            "accuracy": 0.8367533059735522,
            "f1": 0.8367963643196152,
            "f1_weighted": 0.8379685333766658
          },
          {
            "accuracy": 0.8207934336525308,
            "f1": 0.8182664958060584,
            "f1_weighted": 0.8216243515521165
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.8220134228187919,
        "f1": 0.8217159127376021,
        "f1_weighted": 0.8220122702947499,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8220134228187919,
        "scores_per_experiment": [
          {
            "accuracy": 0.7847874720357941,
            "f1": 0.7865760951128212,
            "f1_weighted": 0.7829171984530666
          },
          {
            "accuracy": 0.8527964205816555,
            "f1": 0.8516404070383115,
            "f1_weighted": 0.8529865505618461
          },
          {
            "accuracy": 0.8223713646532439,
            "f1": 0.8168228592063023,
            "f1_weighted": 0.8235246499425917
          },
          {
            "accuracy": 0.8371364653243848,
            "f1": 0.8376977730595322,
            "f1_weighted": 0.8371443651463853
          },
          {
            "accuracy": 0.8451901565995525,
            "f1": 0.8488652491910709,
            "f1_weighted": 0.8460572702934538
          },
          {
            "accuracy": 0.8111856823266219,
            "f1": 0.8116661686323993,
            "f1_weighted": 0.8099606885013481
          },
          {
            "accuracy": 0.7923937360178971,
            "f1": 0.7903816663388661,
            "f1_weighted": 0.790406369333955
          },
          {
            "accuracy": 0.8210290827740492,
            "f1": 0.8195644448099493,
            "f1_weighted": 0.8232433281418733
          },
          {
            "accuracy": 0.836241610738255,
            "f1": 0.8366600860148119,
            "f1_weighted": 0.8370206913827897
          },
          {
            "accuracy": 0.8170022371364654,
            "f1": 0.8172843779719575,
            "f1_weighted": 0.8168615911901892
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}