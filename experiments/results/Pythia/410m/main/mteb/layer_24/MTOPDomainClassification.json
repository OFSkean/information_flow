{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 56.551969051361084,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.7841313269493844,
        "f1": 0.7822999149847245,
        "f1_weighted": 0.784986792460091,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7841313269493844,
        "scores_per_experiment": [
          {
            "accuracy": 0.7567259461924305,
            "f1": 0.7521329432384501,
            "f1_weighted": 0.7476641626826687
          },
          {
            "accuracy": 0.815093479252166,
            "f1": 0.8155335415677457,
            "f1_weighted": 0.8158341224669348
          },
          {
            "accuracy": 0.7911536707706338,
            "f1": 0.784709659526211,
            "f1_weighted": 0.7935836056624749
          },
          {
            "accuracy": 0.7849977200182399,
            "f1": 0.7811214709148483,
            "f1_weighted": 0.7825277451971355
          },
          {
            "accuracy": 0.8107615139078888,
            "f1": 0.8047618781540166,
            "f1_weighted": 0.8116667480920087
          },
          {
            "accuracy": 0.7738258093935249,
            "f1": 0.7746457916234248,
            "f1_weighted": 0.776583645228317
          },
          {
            "accuracy": 0.7909256725946192,
            "f1": 0.7877560478993235,
            "f1_weighted": 0.7882441112688767
          },
          {
            "accuracy": 0.7471500227998176,
            "f1": 0.7524500022603647,
            "f1_weighted": 0.7555744569394802
          },
          {
            "accuracy": 0.8014135886912904,
            "f1": 0.8001009194984875,
            "f1_weighted": 0.8045323385425853
          },
          {
            "accuracy": 0.769265845873233,
            "f1": 0.769786895164373,
            "f1_weighted": 0.7736569885204282
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7758836689038031,
        "f1": 0.7777901534762737,
        "f1_weighted": 0.7769688827273638,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7758836689038031,
        "scores_per_experiment": [
          {
            "accuracy": 0.748993288590604,
            "f1": 0.7517490371700494,
            "f1_weighted": 0.7405560240842628
          },
          {
            "accuracy": 0.8138702460850112,
            "f1": 0.8181944434294576,
            "f1_weighted": 0.8143285343733244
          },
          {
            "accuracy": 0.7798657718120805,
            "f1": 0.7738158688334842,
            "f1_weighted": 0.7819673315183833
          },
          {
            "accuracy": 0.7874720357941835,
            "f1": 0.7894994125310919,
            "f1_weighted": 0.7857815645667442
          },
          {
            "accuracy": 0.8058165548098434,
            "f1": 0.8062055155349799,
            "f1_weighted": 0.8071650481815591
          },
          {
            "accuracy": 0.7583892617449665,
            "f1": 0.7598790580445837,
            "f1_weighted": 0.7598821280306696
          },
          {
            "accuracy": 0.7825503355704698,
            "f1": 0.7822207362408391,
            "f1_weighted": 0.7810582411972005
          },
          {
            "accuracy": 0.7395973154362416,
            "f1": 0.7501049943846205,
            "f1_weighted": 0.7500134914984633
          },
          {
            "accuracy": 0.7870246085011185,
            "f1": 0.7856081782940454,
            "f1_weighted": 0.7893553151101422
          },
          {
            "accuracy": 0.7552572706935123,
            "f1": 0.7606242902995857,
            "f1_weighted": 0.7595811487128882
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}