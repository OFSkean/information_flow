{
  "dataset_revision": "4672e20407010da34463acc759c162ca9734bca6",
  "evaluation_time": 88.85422205924988,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.5618359112306657,
        "f1": 0.5263989797339657,
        "f1_weighted": 0.566856911558842,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5618359112306657,
        "scores_per_experiment": [
          {
            "accuracy": 0.5622057834566241,
            "f1": 0.5283900525913883,
            "f1_weighted": 0.5670398783938237
          },
          {
            "accuracy": 0.5776731674512441,
            "f1": 0.5411692737906234,
            "f1_weighted": 0.5840773595448753
          },
          {
            "accuracy": 0.5514458641560188,
            "f1": 0.5122306998021561,
            "f1_weighted": 0.5539427507327916
          },
          {
            "accuracy": 0.5813718897108272,
            "f1": 0.5338957163907998,
            "f1_weighted": 0.5879180517587633
          },
          {
            "accuracy": 0.5578345662407532,
            "f1": 0.5164698122253507,
            "f1_weighted": 0.5601045619644094
          },
          {
            "accuracy": 0.5447209145931405,
            "f1": 0.522506035400068,
            "f1_weighted": 0.5471383055620885
          },
          {
            "accuracy": 0.5568258238063215,
            "f1": 0.5308045738720234,
            "f1_weighted": 0.5616968239837856
          },
          {
            "accuracy": 0.5574983187626092,
            "f1": 0.5237516970119287,
            "f1_weighted": 0.5659359992748341
          },
          {
            "accuracy": 0.5514458641560188,
            "f1": 0.5131556127474257,
            "f1_weighted": 0.5571793362173676
          },
          {
            "accuracy": 0.5773369199731002,
            "f1": 0.541616323507892,
            "f1_weighted": 0.583536048155681
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.5679783571077226,
        "f1": 0.5293782082541456,
        "f1_weighted": 0.5728643567774658,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5679783571077226,
        "scores_per_experiment": [
          {
            "accuracy": 0.5632070831283817,
            "f1": 0.527658214434695,
            "f1_weighted": 0.565348343854322
          },
          {
            "accuracy": 0.5814067879980325,
            "f1": 0.5330781038535235,
            "f1_weighted": 0.5889360908754346
          },
          {
            "accuracy": 0.5755041810132808,
            "f1": 0.5416234120900253,
            "f1_weighted": 0.5797689903506975
          },
          {
            "accuracy": 0.5912444663059518,
            "f1": 0.53575613151939,
            "f1_weighted": 0.5950293276711695
          },
          {
            "accuracy": 0.5622233152975897,
            "f1": 0.5392115496440856,
            "f1_weighted": 0.56375418819088
          },
          {
            "accuracy": 0.5494343334972946,
            "f1": 0.5193240069642105,
            "f1_weighted": 0.551732409234297
          },
          {
            "accuracy": 0.5479586817511067,
            "f1": 0.522956302597004,
            "f1_weighted": 0.5536926673068145
          },
          {
            "accuracy": 0.5700934579439252,
            "f1": 0.5165336601158993,
            "f1_weighted": 0.5768545054969146
          },
          {
            "accuracy": 0.5553369404820462,
            "f1": 0.521254908251285,
            "f1_weighted": 0.5640352548167181
          },
          {
            "accuracy": 0.5833743236596163,
            "f1": 0.5363857930713398,
            "f1_weighted": 0.58949178997741
          }
        ]
      }
    ]
  },
  "task_name": "MassiveIntentClassification"
}