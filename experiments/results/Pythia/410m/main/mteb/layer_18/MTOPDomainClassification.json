{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 55.75044226646423,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.8286365709074328,
        "f1": 0.8248050224655399,
        "f1_weighted": 0.8288117325868848,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8286365709074328,
        "scores_per_experiment": [
          {
            "accuracy": 0.797765617875057,
            "f1": 0.7938104842562801,
            "f1_weighted": 0.796875410842678
          },
          {
            "accuracy": 0.8590971272229823,
            "f1": 0.8551914412296334,
            "f1_weighted": 0.8592177831207802
          },
          {
            "accuracy": 0.8267213862289101,
            "f1": 0.8197504380514457,
            "f1_weighted": 0.8282149758997014
          },
          {
            "accuracy": 0.8431372549019608,
            "f1": 0.8377846518456935,
            "f1_weighted": 0.8433055028609496
          },
          {
            "accuracy": 0.8572731418148655,
            "f1": 0.8531633545919513,
            "f1_weighted": 0.8580830525746737
          },
          {
            "accuracy": 0.8253533971728226,
            "f1": 0.8240778186234063,
            "f1_weighted": 0.8251922265071867
          },
          {
            "accuracy": 0.8064295485636115,
            "f1": 0.8034987528978768,
            "f1_weighted": 0.8032016469169498
          },
          {
            "accuracy": 0.82124943000456,
            "f1": 0.8157653311616403,
            "f1_weighted": 0.8238524481655966
          },
          {
            "accuracy": 0.8337893296853626,
            "f1": 0.8329813258765473,
            "f1_weighted": 0.8344439613097082
          },
          {
            "accuracy": 0.8155494756041952,
            "f1": 0.8120266261209256,
            "f1_weighted": 0.8157303176706237
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.823579418344519,
        "f1": 0.8232879103576739,
        "f1_weighted": 0.8238748659646455,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.823579418344519,
        "scores_per_experiment": [
          {
            "accuracy": 0.78165548098434,
            "f1": 0.7834595559956551,
            "f1_weighted": 0.7816977854436651
          },
          {
            "accuracy": 0.8653243847874721,
            "f1": 0.8646954810413987,
            "f1_weighted": 0.8655687057153866
          },
          {
            "accuracy": 0.8205816554809844,
            "f1": 0.8145593658037847,
            "f1_weighted": 0.82130930560752
          },
          {
            "accuracy": 0.8442953020134228,
            "f1": 0.8436852970406309,
            "f1_weighted": 0.8446284381036236
          },
          {
            "accuracy": 0.8527964205816555,
            "f1": 0.8561623524141517,
            "f1_weighted": 0.8539513948191033
          },
          {
            "accuracy": 0.8125279642058165,
            "f1": 0.8127203219623849,
            "f1_weighted": 0.8116823774382536
          },
          {
            "accuracy": 0.7986577181208053,
            "f1": 0.7977865453332118,
            "f1_weighted": 0.7970359777242632
          },
          {
            "accuracy": 0.8214765100671141,
            "f1": 0.8234922536477775,
            "f1_weighted": 0.8237847102050716
          },
          {
            "accuracy": 0.829082774049217,
            "f1": 0.8272678404981747,
            "f1_weighted": 0.8299140480783826
          },
          {
            "accuracy": 0.8093959731543624,
            "f1": 0.8090500898395686,
            "f1_weighted": 0.8091759165111874
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}