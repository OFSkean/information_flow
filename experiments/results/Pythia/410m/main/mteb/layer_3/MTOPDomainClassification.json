{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 46.276585817337036,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.8033743730050158,
        "f1": 0.7973174442187341,
        "f1_weighted": 0.8058126975693292,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8033743730050158,
        "scores_per_experiment": [
          {
            "accuracy": 0.759233926128591,
            "f1": 0.7538981208681925,
            "f1_weighted": 0.7608560300093712
          },
          {
            "accuracy": 0.7984496124031008,
            "f1": 0.7976130884182964,
            "f1_weighted": 0.8028049108219434
          },
          {
            "accuracy": 0.8014135886912904,
            "f1": 0.7907902286672065,
            "f1_weighted": 0.8057167749825251
          },
          {
            "accuracy": 0.8071135430916553,
            "f1": 0.7999454458950084,
            "f1_weighted": 0.811338075893572
          },
          {
            "accuracy": 0.8310533515731874,
            "f1": 0.8228526174205243,
            "f1_weighted": 0.833887739170273
          },
          {
            "accuracy": 0.8169174646602827,
            "f1": 0.8128294808657054,
            "f1_weighted": 0.8178684611355355
          },
          {
            "accuracy": 0.7884176926584587,
            "f1": 0.7818620556597232,
            "f1_weighted": 0.7872053802947068
          },
          {
            "accuracy": 0.7868217054263565,
            "f1": 0.7824449079843482,
            "f1_weighted": 0.7904943527208875
          },
          {
            "accuracy": 0.8194254445964432,
            "f1": 0.8164134645118385,
            "f1_weighted": 0.8213080343943139
          },
          {
            "accuracy": 0.8248974008207934,
            "f1": 0.814525031896498,
            "f1_weighted": 0.826647216270163
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7974049217002237,
        "f1": 0.7955332363051225,
        "f1_weighted": 0.799272630813278,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7974049217002237,
        "scores_per_experiment": [
          {
            "accuracy": 0.7485458612975392,
            "f1": 0.7477926241506004,
            "f1_weighted": 0.7492695510611698
          },
          {
            "accuracy": 0.8040268456375839,
            "f1": 0.8087982647290254,
            "f1_weighted": 0.8066562079141004
          },
          {
            "accuracy": 0.8008948545861297,
            "f1": 0.7949828144896255,
            "f1_weighted": 0.8041033892790411
          },
          {
            "accuracy": 0.8067114093959732,
            "f1": 0.8066150613877471,
            "f1_weighted": 0.8122920908360963
          },
          {
            "accuracy": 0.8281879194630872,
            "f1": 0.8250291919278723,
            "f1_weighted": 0.83045108943217
          },
          {
            "accuracy": 0.8035794183445191,
            "f1": 0.8012323876177402,
            "f1_weighted": 0.8039331896294101
          },
          {
            "accuracy": 0.7682326621923937,
            "f1": 0.7627668345351922,
            "f1_weighted": 0.7673608973594556
          },
          {
            "accuracy": 0.7843400447427293,
            "f1": 0.7830745813921843,
            "f1_weighted": 0.7874895609925074
          },
          {
            "accuracy": 0.8111856823266219,
            "f1": 0.8123257992165577,
            "f1_weighted": 0.8120604283285813
          },
          {
            "accuracy": 0.81834451901566,
            "f1": 0.8127148036046801,
            "f1_weighted": 0.8191099033002489
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}