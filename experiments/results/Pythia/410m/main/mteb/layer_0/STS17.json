{
  "dataset_revision": "faeb762787bd10488a50c8b5be4a3b82e411949c",
  "evaluation_time": 25.806270599365234,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.02833803496079059,
        "cosine_spearman": 0.008216476279204953,
        "euclidean_pearson": -0.0923463425057279,
        "euclidean_spearman": -0.08416785321969572,
        "hf_subset": "nl-en",
        "languages": [
          "nld-Latn",
          "eng-Latn"
        ],
        "main_score": 0.008216476279204953,
        "manhattan_pearson": -0.11030334804582537,
        "manhattan_spearman": -0.10627911163056951,
        "pearson": 0.02833803496079059,
        "spearman": 0.008216476279204953
      },
      {
        "cosine_pearson": 0.55757416753994,
        "cosine_spearman": 0.6012234980347309,
        "euclidean_pearson": 0.5401321211674862,
        "euclidean_spearman": 0.5713751058438413,
        "hf_subset": "en-en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6012234980347309,
        "manhattan_pearson": 0.5580953682249684,
        "manhattan_spearman": 0.5798852610880667,
        "pearson": 0.55757416753994,
        "spearman": 0.6012234980347309
      },
      {
        "cosine_pearson": -0.02451241304668489,
        "cosine_spearman": -0.010243783689568789,
        "euclidean_pearson": -0.1267629204567762,
        "euclidean_spearman": -0.11057628067502481,
        "hf_subset": "fr-en",
        "languages": [
          "fra-Latn",
          "eng-Latn"
        ],
        "main_score": -0.010243783689568789,
        "manhattan_pearson": -0.15293265080975396,
        "manhattan_spearman": -0.137926479680485,
        "pearson": -0.02451241304668489,
        "spearman": -0.010243783689568789
      },
      {
        "cosine_pearson": 0.21448117526623753,
        "cosine_spearman": 0.200428324948777,
        "euclidean_pearson": -0.1485418207564209,
        "euclidean_spearman": -0.15225080131641677,
        "hf_subset": "en-ar",
        "languages": [
          "eng-Latn",
          "ara-Arab"
        ],
        "main_score": 0.200428324948777,
        "manhattan_pearson": -0.16485629294798856,
        "manhattan_spearman": -0.17582906212850127,
        "pearson": 0.21448117526623753,
        "spearman": 0.200428324948777
      },
      {
        "cosine_pearson": 0.12005613387213752,
        "cosine_spearman": 0.12836307788631707,
        "euclidean_pearson": -0.07794810571805212,
        "euclidean_spearman": -0.07703768159382565,
        "hf_subset": "en-de",
        "languages": [
          "eng-Latn",
          "deu-Latn"
        ],
        "main_score": 0.12836307788631707,
        "manhattan_pearson": -0.10071938893025464,
        "manhattan_spearman": -0.10780478154178189,
        "pearson": 0.12005613387213752,
        "spearman": 0.12836307788631707
      },
      {
        "cosine_pearson": -0.002916746331965191,
        "cosine_spearman": -0.028144238223797333,
        "euclidean_pearson": -0.09843317774765799,
        "euclidean_spearman": -0.1821087139018824,
        "hf_subset": "es-en",
        "languages": [
          "spa-Latn",
          "eng-Latn"
        ],
        "main_score": -0.028144238223797333,
        "manhattan_pearson": -0.11001292204362392,
        "manhattan_spearman": -0.1979373010433471,
        "pearson": -0.002916746331965191,
        "spearman": -0.028144238223797333
      },
      {
        "cosine_pearson": -0.04264521362412595,
        "cosine_spearman": -0.0032487784618089135,
        "euclidean_pearson": -0.2369138231130316,
        "euclidean_spearman": -0.22281045421062845,
        "hf_subset": "en-tr",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ],
        "main_score": -0.0032487784618089135,
        "manhattan_pearson": -0.24617142228977476,
        "manhattan_spearman": -0.24282831212690573,
        "pearson": -0.04264521362412595,
        "spearman": -0.0032487784618089135
      },
      {
        "cosine_pearson": -0.012004770405528593,
        "cosine_spearman": 0.005092101112076164,
        "euclidean_pearson": -0.10887248947747623,
        "euclidean_spearman": -0.1178094705765827,
        "hf_subset": "it-en",
        "languages": [
          "ita-Latn",
          "eng-Latn"
        ],
        "main_score": 0.005092101112076164,
        "manhattan_pearson": -0.14477079003792537,
        "manhattan_spearman": -0.1465577198382987,
        "pearson": -0.012004770405528593,
        "spearman": 0.005092101112076164
      }
    ]
  },
  "task_name": "STS17"
}