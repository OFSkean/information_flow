{
  "dataset_revision": "4672e20407010da34463acc759c162ca9734bca6",
  "evaluation_time": 61.46019721031189,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.5578345662407532,
        "f1": 0.5390130560685311,
        "f1_weighted": 0.5595102474311238,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5578345662407532,
        "scores_per_experiment": [
          {
            "accuracy": 0.5537995965030262,
            "f1": 0.5452502721545722,
            "f1_weighted": 0.5533449022853715
          },
          {
            "accuracy": 0.5776731674512441,
            "f1": 0.5532879280729875,
            "f1_weighted": 0.5829126710327351
          },
          {
            "accuracy": 0.5591795561533288,
            "f1": 0.5411683278941385,
            "f1_weighted": 0.5543902778223462
          },
          {
            "accuracy": 0.5780094149293881,
            "f1": 0.5523993687930387,
            "f1_weighted": 0.5810016777338398
          },
          {
            "accuracy": 0.5611970410221924,
            "f1": 0.5386761859725321,
            "f1_weighted": 0.5586053909875556
          },
          {
            "accuracy": 0.5279085406859448,
            "f1": 0.5133454455916279,
            "f1_weighted": 0.5312463832432911
          },
          {
            "accuracy": 0.5464021519838601,
            "f1": 0.5364399151353169,
            "f1_weighted": 0.5470240994073197
          },
          {
            "accuracy": 0.554808338937458,
            "f1": 0.5293213765345867,
            "f1_weighted": 0.5591978399082267
          },
          {
            "accuracy": 0.5494283792871554,
            "f1": 0.5312181619127615,
            "f1_weighted": 0.5507910281029191
          },
          {
            "accuracy": 0.5699394754539341,
            "f1": 0.5490235786237494,
            "f1_weighted": 0.5765882037876334
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.5657156910969011,
        "f1": 0.5473203674280989,
        "f1_weighted": 0.5673022502782634,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5657156910969011,
        "scores_per_experiment": [
          {
            "accuracy": 0.5494343334972946,
            "f1": 0.5402124799109996,
            "f1_weighted": 0.5503040164368677
          },
          {
            "accuracy": 0.5833743236596163,
            "f1": 0.5447511117439172,
            "f1_weighted": 0.585875846064439
          },
          {
            "accuracy": 0.5745204131824889,
            "f1": 0.5546767970969219,
            "f1_weighted": 0.574024272032586
          },
          {
            "accuracy": 0.5715691096901131,
            "f1": 0.536282735122305,
            "f1_weighted": 0.5708951003570473
          },
          {
            "accuracy": 0.5833743236596163,
            "f1": 0.5550984457825536,
            "f1_weighted": 0.5845304998222485
          },
          {
            "accuracy": 0.5332021642892277,
            "f1": 0.5255876174360837,
            "f1_weighted": 0.5357579564655013
          },
          {
            "accuracy": 0.5469749139203148,
            "f1": 0.5500619079731414,
            "f1_weighted": 0.5484870658887401
          },
          {
            "accuracy": 0.5646827348745695,
            "f1": 0.5424492051434453,
            "f1_weighted": 0.5649504833885164
          },
          {
            "accuracy": 0.5617314313821938,
            "f1": 0.5549395572392339,
            "f1_weighted": 0.5661244297615322
          },
          {
            "accuracy": 0.588293162813576,
            "f1": 0.5691438168323877,
            "f1_weighted": 0.5920728325651553
          }
        ]
      }
    ]
  },
  "task_name": "MassiveIntentClassification"
}