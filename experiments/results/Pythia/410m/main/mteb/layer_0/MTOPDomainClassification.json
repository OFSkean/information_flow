{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 39.065932750701904,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.8025763793889649,
        "f1": 0.7992752000494294,
        "f1_weighted": 0.8052632457178686,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8025763793889649,
        "scores_per_experiment": [
          {
            "accuracy": 0.7669858641130871,
            "f1": 0.7619519148224815,
            "f1_weighted": 0.7703733191185528
          },
          {
            "accuracy": 0.7861377108983129,
            "f1": 0.7869424558577475,
            "f1_weighted": 0.7912729824457102
          },
          {
            "accuracy": 0.8082535339717283,
            "f1": 0.8033989678180796,
            "f1_weighted": 0.8098701794667109
          },
          {
            "accuracy": 0.8125854993160054,
            "f1": 0.8124762872669303,
            "f1_weighted": 0.8164330298487699
          },
          {
            "accuracy": 0.8342453260373917,
            "f1": 0.8283114924438504,
            "f1_weighted": 0.8366231908008125
          },
          {
            "accuracy": 0.8093935248518012,
            "f1": 0.8070500074652603,
            "f1_weighted": 0.8120365210628889
          },
          {
            "accuracy": 0.7881896944824441,
            "f1": 0.7884677903044653,
            "f1_weighted": 0.7894017430069967
          },
          {
            "accuracy": 0.781577747378021,
            "f1": 0.7751820498686333,
            "f1_weighted": 0.7855868905548712
          },
          {
            "accuracy": 0.8055175558595531,
            "f1": 0.8050595066557785,
            "f1_weighted": 0.8089757041994552
          },
          {
            "accuracy": 0.8328773369813042,
            "f1": 0.823911527991067,
            "f1_weighted": 0.8320588966739173
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.796331096196868,
        "f1": 0.795735956637523,
        "f1_weighted": 0.7982731122348439,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.796331096196868,
        "scores_per_experiment": [
          {
            "accuracy": 0.7574944071588366,
            "f1": 0.754301274395048,
            "f1_weighted": 0.7586113351058899
          },
          {
            "accuracy": 0.789261744966443,
            "f1": 0.7930872059247771,
            "f1_weighted": 0.792447979908869
          },
          {
            "accuracy": 0.807158836689038,
            "f1": 0.8033977449212849,
            "f1_weighted": 0.8075272834398668
          },
          {
            "accuracy": 0.7977628635346756,
            "f1": 0.8026272136278788,
            "f1_weighted": 0.802953995418371
          },
          {
            "accuracy": 0.8263982102908277,
            "f1": 0.8241606405168526,
            "f1_weighted": 0.82869404220812
          },
          {
            "accuracy": 0.7977628635346756,
            "f1": 0.7990749057044714,
            "f1_weighted": 0.7992115062855786
          },
          {
            "accuracy": 0.7776286353467562,
            "f1": 0.7796051178000379,
            "f1_weighted": 0.779789098470582
          },
          {
            "accuracy": 0.7888143176733781,
            "f1": 0.7864638300719381,
            "f1_weighted": 0.7924526186497817
          },
          {
            "accuracy": 0.8,
            "f1": 0.8008657629575936,
            "f1_weighted": 0.8022559391309597
          },
          {
            "accuracy": 0.8210290827740492,
            "f1": 0.8137758704553469,
            "f1_weighted": 0.8187873237304207
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}