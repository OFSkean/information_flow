{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 51.641095876693726,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.817624259005928,
        "f1": 0.8122972372775135,
        "f1_weighted": 0.8179466173757195,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.817624259005928,
        "scores_per_experiment": [
          {
            "accuracy": 0.781577747378021,
            "f1": 0.7769354268273346,
            "f1_weighted": 0.7789200414218762
          },
          {
            "accuracy": 0.8287733698130415,
            "f1": 0.8234538446754442,
            "f1_weighted": 0.8313985432601472
          },
          {
            "accuracy": 0.820109439124487,
            "f1": 0.8099232571867429,
            "f1_weighted": 0.820838184311503
          },
          {
            "accuracy": 0.8207934336525308,
            "f1": 0.8143504376053552,
            "f1_weighted": 0.8207345908827869
          },
          {
            "accuracy": 0.8449612403100775,
            "f1": 0.8394555775849345,
            "f1_weighted": 0.8452733339637001
          },
          {
            "accuracy": 0.8305973552211582,
            "f1": 0.8277228776282676,
            "f1_weighted": 0.8312228998003277
          },
          {
            "accuracy": 0.8005015959872321,
            "f1": 0.7968735043031809,
            "f1_weighted": 0.797459069261982
          },
          {
            "accuracy": 0.8068855449156407,
            "f1": 0.7992079540351021,
            "f1_weighted": 0.8098457857526418
          },
          {
            "accuracy": 0.8164614683082535,
            "f1": 0.8158660895857021,
            "f1_weighted": 0.8175196992625151
          },
          {
            "accuracy": 0.8255813953488372,
            "f1": 0.8191834033430706,
            "f1_weighted": 0.826254025839715
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.8145861297539151,
        "f1": 0.8136663404969285,
        "f1_weighted": 0.8149189790975147,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8145861297539151,
        "scores_per_experiment": [
          {
            "accuracy": 0.7758389261744967,
            "f1": 0.7789645790390761,
            "f1_weighted": 0.7735706312044317
          },
          {
            "accuracy": 0.8268456375838926,
            "f1": 0.8261728892765657,
            "f1_weighted": 0.8280992777094291
          },
          {
            "accuracy": 0.8102908277404922,
            "f1": 0.8019391887795465,
            "f1_weighted": 0.8107977616598346
          },
          {
            "accuracy": 0.8326621923937361,
            "f1": 0.8341314381240796,
            "f1_weighted": 0.8340145787092805
          },
          {
            "accuracy": 0.8407158836689038,
            "f1": 0.8427278824155732,
            "f1_weighted": 0.8410396518134745
          },
          {
            "accuracy": 0.8322147651006712,
            "f1": 0.8311764473872306,
            "f1_weighted": 0.8325764362792958
          },
          {
            "accuracy": 0.7843400447427293,
            "f1": 0.7815667861831652,
            "f1_weighted": 0.7825285325919777
          },
          {
            "accuracy": 0.8062639821029083,
            "f1": 0.8062937761115698,
            "f1_weighted": 0.8085219687311478
          },
          {
            "accuracy": 0.8178970917225951,
            "f1": 0.8176495804311382,
            "f1_weighted": 0.818678802274269
          },
          {
            "accuracy": 0.8187919463087249,
            "f1": 0.8160408372213402,
            "f1_weighted": 0.8193621500020053
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}