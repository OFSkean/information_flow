{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 97.7008888721466,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.32678,
        "f1": 0.32449863742197277,
        "f1_weighted": 0.32449863742197277,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.32678,
        "scores_per_experiment": [
          {
            "accuracy": 0.3556,
            "f1": 0.3530265382114203,
            "f1_weighted": 0.3530265382114203
          },
          {
            "accuracy": 0.331,
            "f1": 0.331359459716268,
            "f1_weighted": 0.331359459716268
          },
          {
            "accuracy": 0.3098,
            "f1": 0.309196671623525,
            "f1_weighted": 0.309196671623525
          },
          {
            "accuracy": 0.3208,
            "f1": 0.3162333707440007,
            "f1_weighted": 0.31623337074400076
          },
          {
            "accuracy": 0.3716,
            "f1": 0.3663995216219721,
            "f1_weighted": 0.3663995216219721
          },
          {
            "accuracy": 0.2914,
            "f1": 0.2904625461069322,
            "f1_weighted": 0.2904625461069322
          },
          {
            "accuracy": 0.2932,
            "f1": 0.29150092854886617,
            "f1_weighted": 0.2915009285488662
          },
          {
            "accuracy": 0.332,
            "f1": 0.3294585532238247,
            "f1_weighted": 0.3294585532238247
          },
          {
            "accuracy": 0.3202,
            "f1": 0.31738370033104024,
            "f1_weighted": 0.31738370033104024
          },
          {
            "accuracy": 0.3422,
            "f1": 0.33996508409187826,
            "f1_weighted": 0.3399650840918782
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.32652000000000003,
        "f1": 0.3242315964176189,
        "f1_weighted": 0.3242315964176189,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.32652000000000003,
        "scores_per_experiment": [
          {
            "accuracy": 0.3514,
            "f1": 0.35038106223308896,
            "f1_weighted": 0.35038106223308896
          },
          {
            "accuracy": 0.3402,
            "f1": 0.34323018953731566,
            "f1_weighted": 0.34323018953731566
          },
          {
            "accuracy": 0.304,
            "f1": 0.302765741417531,
            "f1_weighted": 0.302765741417531
          },
          {
            "accuracy": 0.3236,
            "f1": 0.3184149077258738,
            "f1_weighted": 0.31841490772587383
          },
          {
            "accuracy": 0.3676,
            "f1": 0.36103953297601,
            "f1_weighted": 0.36103953297601
          },
          {
            "accuracy": 0.2886,
            "f1": 0.2867180575777847,
            "f1_weighted": 0.2867180575777847
          },
          {
            "accuracy": 0.2928,
            "f1": 0.28944672656082526,
            "f1_weighted": 0.2894467265608252
          },
          {
            "accuracy": 0.3208,
            "f1": 0.31835545218558775,
            "f1_weighted": 0.3183554521855878
          },
          {
            "accuracy": 0.3312,
            "f1": 0.32881426449324913,
            "f1_weighted": 0.3288142644932492
          },
          {
            "accuracy": 0.345,
            "f1": 0.3431500294689229,
            "f1_weighted": 0.3431500294689229
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}