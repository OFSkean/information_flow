{
  "dataset_revision": "ae001d0e6b1228650b7bd1c2c65fb50ad11a8aba",
  "evaluation_time": 106.38042259216309,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.7063155494756043,
        "f1": 0.4892667096935373,
        "f1_weighted": 0.7428957657013245,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7063155494756043,
        "scores_per_experiment": [
          {
            "accuracy": 0.6988144094847242,
            "f1": 0.4903461000393585,
            "f1_weighted": 0.7359116575780719
          },
          {
            "accuracy": 0.6979024167806658,
            "f1": 0.4694152479742271,
            "f1_weighted": 0.7345183307247309
          },
          {
            "accuracy": 0.6951664386684907,
            "f1": 0.48515696935184455,
            "f1_weighted": 0.7322329505037101
          },
          {
            "accuracy": 0.7118103055175559,
            "f1": 0.4958405595134677,
            "f1_weighted": 0.7486200490917824
          },
          {
            "accuracy": 0.7097583219334246,
            "f1": 0.4791651674144563,
            "f1_weighted": 0.745834489209156
          },
          {
            "accuracy": 0.7113543091655267,
            "f1": 0.499182056662424,
            "f1_weighted": 0.7491141684487239
          },
          {
            "accuracy": 0.6999544003647971,
            "f1": 0.4912020290038183,
            "f1_weighted": 0.7389249799287421
          },
          {
            "accuracy": 0.7252621979024167,
            "f1": 0.5078701096260151,
            "f1_weighted": 0.76065549677485
          },
          {
            "accuracy": 0.6999544003647971,
            "f1": 0.4908740502228987,
            "f1_weighted": 0.7354373511766625
          },
          {
            "accuracy": 0.7131782945736435,
            "f1": 0.4836148071268621,
            "f1_weighted": 0.7477081835768143
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7097539149888143,
        "f1": 0.47892690455114656,
        "f1_weighted": 0.7484308296583329,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7097539149888143,
        "scores_per_experiment": [
          {
            "accuracy": 0.7029082774049217,
            "f1": 0.48113825873130994,
            "f1_weighted": 0.7402870116889562
          },
          {
            "accuracy": 0.6997762863534676,
            "f1": 0.46738503152634,
            "f1_weighted": 0.7388178552389733
          },
          {
            "accuracy": 0.7087248322147651,
            "f1": 0.46967123465200683,
            "f1_weighted": 0.7479382708148962
          },
          {
            "accuracy": 0.7109619686800895,
            "f1": 0.48622646291440924,
            "f1_weighted": 0.7502159264219436
          },
          {
            "accuracy": 0.7149888143176734,
            "f1": 0.47110285309182365,
            "f1_weighted": 0.7523333434460211
          },
          {
            "accuracy": 0.7140939597315437,
            "f1": 0.48701312031230903,
            "f1_weighted": 0.7552696964859954
          },
          {
            "accuracy": 0.7024608501118568,
            "f1": 0.47709607354962474,
            "f1_weighted": 0.7437320652697365
          },
          {
            "accuracy": 0.727069351230425,
            "f1": 0.49972294418449076,
            "f1_weighted": 0.7649031856354311
          },
          {
            "accuracy": 0.6993288590604027,
            "f1": 0.46200524865453474,
            "f1_weighted": 0.7346310237751164
          },
          {
            "accuracy": 0.7172259507829978,
            "f1": 0.4879078178946164,
            "f1_weighted": 0.7561799178062586
          }
        ]
      }
    ]
  },
  "task_name": "MTOPIntentClassification"
}