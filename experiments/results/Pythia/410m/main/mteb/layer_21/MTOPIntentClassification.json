{
  "dataset_revision": "ae001d0e6b1228650b7bd1c2c65fb50ad11a8aba",
  "evaluation_time": 139.2297534942627,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.6746694026447788,
        "f1": 0.449564280365452,
        "f1_weighted": 0.7141079592900849,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6746694026447788,
        "scores_per_experiment": [
          {
            "accuracy": 0.6643866849065208,
            "f1": 0.4446827007772514,
            "f1_weighted": 0.7041993979792992
          },
          {
            "accuracy": 0.67875056999544,
            "f1": 0.4640482090031576,
            "f1_weighted": 0.7165385929553543
          },
          {
            "accuracy": 0.6919744642042863,
            "f1": 0.44579195308788033,
            "f1_weighted": 0.7328406502646313
          },
          {
            "accuracy": 0.6805745554035568,
            "f1": 0.46519974070301345,
            "f1_weighted": 0.7208721140340403
          },
          {
            "accuracy": 0.6812585499316005,
            "f1": 0.45076908889287715,
            "f1_weighted": 0.7163712322901163
          },
          {
            "accuracy": 0.6698586411308709,
            "f1": 0.44667468367166496,
            "f1_weighted": 0.7128599596895262
          },
          {
            "accuracy": 0.6595987232102143,
            "f1": 0.4545651202892445,
            "f1_weighted": 0.7049613193675605
          },
          {
            "accuracy": 0.6878704970360238,
            "f1": 0.4594009619784149,
            "f1_weighted": 0.7274120235350027
          },
          {
            "accuracy": 0.6700866393068855,
            "f1": 0.44517658523620557,
            "f1_weighted": 0.7045824105535131
          },
          {
            "accuracy": 0.6623347013223895,
            "f1": 0.4193337600148098,
            "f1_weighted": 0.7004418922318045
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.674854586129754,
        "f1": 0.4297605216745241,
        "f1_weighted": 0.7165290201967155,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.674854586129754,
        "scores_per_experiment": [
          {
            "accuracy": 0.6541387024608502,
            "f1": 0.4134326895571342,
            "f1_weighted": 0.6991052595377022
          },
          {
            "accuracy": 0.6809843400447427,
            "f1": 0.4487671156145246,
            "f1_weighted": 0.7204917262790439
          },
          {
            "accuracy": 0.6836689038031319,
            "f1": 0.4187691709225959,
            "f1_weighted": 0.7253978957375876
          },
          {
            "accuracy": 0.6738255033557047,
            "f1": 0.43718721946031375,
            "f1_weighted": 0.7201905965894905
          },
          {
            "accuracy": 0.6747203579418345,
            "f1": 0.4196136400084737,
            "f1_weighted": 0.7105304100488129
          },
          {
            "accuracy": 0.6756152125279642,
            "f1": 0.42611276401866144,
            "f1_weighted": 0.7230810387718437
          },
          {
            "accuracy": 0.661744966442953,
            "f1": 0.41333368347198846,
            "f1_weighted": 0.7079502836903621
          },
          {
            "accuracy": 0.7011185682326622,
            "f1": 0.4493021759051715,
            "f1_weighted": 0.7404917821696818
          },
          {
            "accuracy": 0.669351230425056,
            "f1": 0.4330685230650204,
            "f1_weighted": 0.7074382202579357
          },
          {
            "accuracy": 0.6733780760626398,
            "f1": 0.4380182347213572,
            "f1_weighted": 0.7106129888846948
          }
        ]
      }
    ]
  },
  "task_name": "MTOPIntentClassification"
}