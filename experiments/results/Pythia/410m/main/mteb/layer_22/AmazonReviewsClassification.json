{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 288.6426513195038,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.33246,
        "f1": 0.3334749464958415,
        "f1_weighted": 0.3334749464958415,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.33246,
        "scores_per_experiment": [
          {
            "accuracy": 0.3564,
            "f1": 0.3540343762457031,
            "f1_weighted": 0.35403437624570305
          },
          {
            "accuracy": 0.3542,
            "f1": 0.35416882525330523,
            "f1_weighted": 0.3541688252533053
          },
          {
            "accuracy": 0.3304,
            "f1": 0.32584776163492657,
            "f1_weighted": 0.3258477616349265
          },
          {
            "accuracy": 0.3262,
            "f1": 0.32938522183297014,
            "f1_weighted": 0.32938522183297014
          },
          {
            "accuracy": 0.3448,
            "f1": 0.3423608132353832,
            "f1_weighted": 0.34236081323538325
          },
          {
            "accuracy": 0.3282,
            "f1": 0.33068345955713685,
            "f1_weighted": 0.33068345955713685
          },
          {
            "accuracy": 0.2924,
            "f1": 0.2958937743326013,
            "f1_weighted": 0.2958937743326013
          },
          {
            "accuracy": 0.3408,
            "f1": 0.3433942115174883,
            "f1_weighted": 0.3433942115174882
          },
          {
            "accuracy": 0.3274,
            "f1": 0.3266086260980687,
            "f1_weighted": 0.32660862609806873
          },
          {
            "accuracy": 0.3238,
            "f1": 0.3323723952508314,
            "f1_weighted": 0.3323723952508314
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.3383,
        "f1": 0.3387438600251531,
        "f1_weighted": 0.33874386002515317,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.3383,
        "scores_per_experiment": [
          {
            "accuracy": 0.3544,
            "f1": 0.35307190376292397,
            "f1_weighted": 0.353071903762924
          },
          {
            "accuracy": 0.3558,
            "f1": 0.35453360333549433,
            "f1_weighted": 0.35453360333549433
          },
          {
            "accuracy": 0.341,
            "f1": 0.3368091442406819,
            "f1_weighted": 0.3368091442406819
          },
          {
            "accuracy": 0.3244,
            "f1": 0.32726668239819345,
            "f1_weighted": 0.32726668239819345
          },
          {
            "accuracy": 0.3466,
            "f1": 0.34219231923319754,
            "f1_weighted": 0.34219231923319754
          },
          {
            "accuracy": 0.3338,
            "f1": 0.335006922284722,
            "f1_weighted": 0.335006922284722
          },
          {
            "accuracy": 0.3194,
            "f1": 0.3222815747972383,
            "f1_weighted": 0.3222815747972383
          },
          {
            "accuracy": 0.3302,
            "f1": 0.3327191310036039,
            "f1_weighted": 0.33271913100360395
          },
          {
            "accuracy": 0.3496,
            "f1": 0.3489755340703279,
            "f1_weighted": 0.3489755340703278
          },
          {
            "accuracy": 0.3278,
            "f1": 0.3345817851251479,
            "f1_weighted": 0.33458178512514786
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}