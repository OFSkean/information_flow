{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 56.29788088798523,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.8214774281805746,
        "f1": 0.8189448370103076,
        "f1_weighted": 0.8222061320466535,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8214774281805746,
        "scores_per_experiment": [
          {
            "accuracy": 0.7875056999544003,
            "f1": 0.784436744417702,
            "f1_weighted": 0.7852150205956221
          },
          {
            "accuracy": 0.8429092567259462,
            "f1": 0.840682124253417,
            "f1_weighted": 0.8435323457540729
          },
          {
            "accuracy": 0.8164614683082535,
            "f1": 0.8108378135456404,
            "f1_weighted": 0.8177651473870797
          },
          {
            "accuracy": 0.8358413132694938,
            "f1": 0.8310967563897684,
            "f1_weighted": 0.8371764446667607
          },
          {
            "accuracy": 0.8451892384860921,
            "f1": 0.8428499062707965,
            "f1_weighted": 0.8464616959489578
          },
          {
            "accuracy": 0.8187414500683995,
            "f1": 0.8184040304462321,
            "f1_weighted": 0.8184273106107436
          },
          {
            "accuracy": 0.8146374829001368,
            "f1": 0.8137092816364656,
            "f1_weighted": 0.8131193250056604
          },
          {
            "accuracy": 0.8093935248518012,
            "f1": 0.8059424940900626,
            "f1_weighted": 0.8123475746545467
          },
          {
            "accuracy": 0.8310533515731874,
            "f1": 0.8298512999651255,
            "f1_weighted": 0.8328136607693933
          },
          {
            "accuracy": 0.8130414956680346,
            "f1": 0.8116379190878658,
            "f1_weighted": 0.8152027950736973
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.8187024608501119,
        "f1": 0.8199774593233744,
        "f1_weighted": 0.819406490981802,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8187024608501119,
        "scores_per_experiment": [
          {
            "accuracy": 0.78165548098434,
            "f1": 0.7863241792733114,
            "f1_weighted": 0.7797377498813771
          },
          {
            "accuracy": 0.8536912751677852,
            "f1": 0.8554322250588192,
            "f1_weighted": 0.8539442647225285
          },
          {
            "accuracy": 0.8098434004474273,
            "f1": 0.8074524549800113,
            "f1_weighted": 0.810874545934192
          },
          {
            "accuracy": 0.8487695749440716,
            "f1": 0.8491493072489559,
            "f1_weighted": 0.8499988282098122
          },
          {
            "accuracy": 0.8331096196868009,
            "f1": 0.8362073174404042,
            "f1_weighted": 0.8349262076767675
          },
          {
            "accuracy": 0.8152125279642058,
            "f1": 0.8157641721122822,
            "f1_weighted": 0.8151243787123729
          },
          {
            "accuracy": 0.8076062639821029,
            "f1": 0.8076162941623877,
            "f1_weighted": 0.8063714353762146
          },
          {
            "accuracy": 0.8,
            "f1": 0.8026637850100045,
            "f1_weighted": 0.802570093367568
          },
          {
            "accuracy": 0.8308724832214766,
            "f1": 0.8294914770685048,
            "f1_weighted": 0.8319415561519622
          },
          {
            "accuracy": 0.8062639821029083,
            "f1": 0.809673380879063,
            "f1_weighted": 0.8085758497852248
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}