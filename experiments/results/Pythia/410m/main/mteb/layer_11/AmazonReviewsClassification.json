{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 175.91329383850098,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.37212,
        "f1": 0.3693794978810353,
        "f1_weighted": 0.3693794978810353,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.37212,
        "scores_per_experiment": [
          {
            "accuracy": 0.3796,
            "f1": 0.3829068001872415,
            "f1_weighted": 0.3829068001872415
          },
          {
            "accuracy": 0.4006,
            "f1": 0.39801011497848016,
            "f1_weighted": 0.39801011497848016
          },
          {
            "accuracy": 0.3578,
            "f1": 0.35223610798680544,
            "f1_weighted": 0.3522361079868054
          },
          {
            "accuracy": 0.3816,
            "f1": 0.38300587576753786,
            "f1_weighted": 0.3830058757675379
          },
          {
            "accuracy": 0.4138,
            "f1": 0.3924495851656262,
            "f1_weighted": 0.39244958516562617
          },
          {
            "accuracy": 0.333,
            "f1": 0.3339094320092324,
            "f1_weighted": 0.3339094320092324
          },
          {
            "accuracy": 0.344,
            "f1": 0.34475029513274663,
            "f1_weighted": 0.3447502951327467
          },
          {
            "accuracy": 0.373,
            "f1": 0.36897434815958874,
            "f1_weighted": 0.3689743481595886
          },
          {
            "accuracy": 0.3626,
            "f1": 0.3639177576142366,
            "f1_weighted": 0.3639177576142366
          },
          {
            "accuracy": 0.3752,
            "f1": 0.3736346618088582,
            "f1_weighted": 0.3736346618088582
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.37622000000000005,
        "f1": 0.3728677427920194,
        "f1_weighted": 0.3728677427920194,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.37622000000000005,
        "scores_per_experiment": [
          {
            "accuracy": 0.3794,
            "f1": 0.3832511745761249,
            "f1_weighted": 0.38325117457612484
          },
          {
            "accuracy": 0.4004,
            "f1": 0.39826053422511365,
            "f1_weighted": 0.39826053422511354
          },
          {
            "accuracy": 0.3684,
            "f1": 0.36231036675405826,
            "f1_weighted": 0.3623103667540583
          },
          {
            "accuracy": 0.3784,
            "f1": 0.37943021867975135,
            "f1_weighted": 0.37943021867975135
          },
          {
            "accuracy": 0.4174,
            "f1": 0.3916383028627965,
            "f1_weighted": 0.3916383028627965
          },
          {
            "accuracy": 0.338,
            "f1": 0.3382941444821652,
            "f1_weighted": 0.3382941444821652
          },
          {
            "accuracy": 0.3538,
            "f1": 0.35335496563629765,
            "f1_weighted": 0.3533549656362976
          },
          {
            "accuracy": 0.3696,
            "f1": 0.36459149751754427,
            "f1_weighted": 0.3645914975175442
          },
          {
            "accuracy": 0.3794,
            "f1": 0.3821537309488702,
            "f1_weighted": 0.3821537309488702
          },
          {
            "accuracy": 0.3774,
            "f1": 0.37539249223747173,
            "f1_weighted": 0.37539249223747173
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}