{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 141.38747334480286,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.35634000000000005,
        "f1": 0.35439182745120656,
        "f1_weighted": 0.35439182745120656,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.35634000000000005,
        "scores_per_experiment": [
          {
            "accuracy": 0.3658,
            "f1": 0.3706168447613022,
            "f1_weighted": 0.3706168447613022
          },
          {
            "accuracy": 0.3764,
            "f1": 0.3763450606268211,
            "f1_weighted": 0.3763450606268211
          },
          {
            "accuracy": 0.3462,
            "f1": 0.34318506197852694,
            "f1_weighted": 0.34318506197852694
          },
          {
            "accuracy": 0.3668,
            "f1": 0.3671540057269014,
            "f1_weighted": 0.36715400572690143
          },
          {
            "accuracy": 0.4014,
            "f1": 0.38659173681320097,
            "f1_weighted": 0.38659173681320097
          },
          {
            "accuracy": 0.3132,
            "f1": 0.31054834724620034,
            "f1_weighted": 0.31054834724620034
          },
          {
            "accuracy": 0.3172,
            "f1": 0.31696618100679486,
            "f1_weighted": 0.3169661810067948
          },
          {
            "accuracy": 0.3658,
            "f1": 0.3613735049454354,
            "f1_weighted": 0.3613735049454354
          },
          {
            "accuracy": 0.3458,
            "f1": 0.3457849656298475,
            "f1_weighted": 0.34578496562984745
          },
          {
            "accuracy": 0.3648,
            "f1": 0.365352565777035,
            "f1_weighted": 0.365352565777035
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.35733999999999994,
        "f1": 0.3553721992699178,
        "f1_weighted": 0.3553721992699178,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.35733999999999994,
        "scores_per_experiment": [
          {
            "accuracy": 0.3588,
            "f1": 0.3648794917570565,
            "f1_weighted": 0.3648794917570565
          },
          {
            "accuracy": 0.3764,
            "f1": 0.37791505374334705,
            "f1_weighted": 0.3779150537433471
          },
          {
            "accuracy": 0.348,
            "f1": 0.3446005946130141,
            "f1_weighted": 0.3446005946130142
          },
          {
            "accuracy": 0.3524,
            "f1": 0.3536515034216291,
            "f1_weighted": 0.35365150342162904
          },
          {
            "accuracy": 0.404,
            "f1": 0.3851793462600684,
            "f1_weighted": 0.38517934626006833
          },
          {
            "accuracy": 0.3224,
            "f1": 0.31864727861015624,
            "f1_weighted": 0.31864727861015624
          },
          {
            "accuracy": 0.3288,
            "f1": 0.32827255066288297,
            "f1_weighted": 0.32827255066288297
          },
          {
            "accuracy": 0.3532,
            "f1": 0.3476027677183472,
            "f1_weighted": 0.34760276771834714
          },
          {
            "accuracy": 0.3644,
            "f1": 0.36717917948347606,
            "f1_weighted": 0.36717917948347606
          },
          {
            "accuracy": 0.365,
            "f1": 0.3657942264292008,
            "f1_weighted": 0.3657942264292008
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}