{
  "dataset_revision": "ae001d0e6b1228650b7bd1c2c65fb50ad11a8aba",
  "evaluation_time": 112.10802984237671,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.7095987232102143,
        "f1": 0.4900337636399765,
        "f1_weighted": 0.7457937815061764,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7095987232102143,
        "scores_per_experiment": [
          {
            "accuracy": 0.6979024167806658,
            "f1": 0.4826443461594029,
            "f1_weighted": 0.7339175207427576
          },
          {
            "accuracy": 0.702234382124943,
            "f1": 0.47345376422680824,
            "f1_weighted": 0.7397198455410445
          },
          {
            "accuracy": 0.7008663930688555,
            "f1": 0.4881838634116969,
            "f1_weighted": 0.7383784250682182
          },
          {
            "accuracy": 0.7077063383492932,
            "f1": 0.4977381644177048,
            "f1_weighted": 0.7460533294344824
          },
          {
            "accuracy": 0.7143182854537163,
            "f1": 0.4854789651913471,
            "f1_weighted": 0.7489229245676333
          },
          {
            "accuracy": 0.7191062471500228,
            "f1": 0.5003749418031507,
            "f1_weighted": 0.7555592107473943
          },
          {
            "accuracy": 0.6994984040127679,
            "f1": 0.4881181731069995,
            "f1_weighted": 0.7373640339843348
          },
          {
            "accuracy": 0.7355221158230734,
            "f1": 0.5041937974793727,
            "f1_weighted": 0.7700416110974462
          },
          {
            "accuracy": 0.7056543547651619,
            "f1": 0.49004281861499727,
            "f1_weighted": 0.7403952043493497
          },
          {
            "accuracy": 0.7131782945736435,
            "f1": 0.49010880198828566,
            "f1_weighted": 0.7475857095291037
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7100671140939598,
        "f1": 0.4759769919511001,
        "f1_weighted": 0.7489257162110949,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7100671140939598,
        "scores_per_experiment": [
          {
            "accuracy": 0.6917225950782998,
            "f1": 0.45184638423194573,
            "f1_weighted": 0.7306376212131203
          },
          {
            "accuracy": 0.7136465324384788,
            "f1": 0.4802959956104652,
            "f1_weighted": 0.7527272381906503
          },
          {
            "accuracy": 0.7038031319910515,
            "f1": 0.46486247427189764,
            "f1_weighted": 0.745227484777096
          },
          {
            "accuracy": 0.7024608501118568,
            "f1": 0.4901045630971553,
            "f1_weighted": 0.7419703139652699
          },
          {
            "accuracy": 0.7185682326621924,
            "f1": 0.49022454985396186,
            "f1_weighted": 0.7543273642342646
          },
          {
            "accuracy": 0.7190156599552573,
            "f1": 0.47693957043436946,
            "f1_weighted": 0.761596937909871
          },
          {
            "accuracy": 0.6961968680089485,
            "f1": 0.47290027748998226,
            "f1_weighted": 0.7360247978511489
          },
          {
            "accuracy": 0.7306487695749441,
            "f1": 0.48484931009951016,
            "f1_weighted": 0.7687676235052021
          },
          {
            "accuracy": 0.70917225950783,
            "f1": 0.4647269394992686,
            "f1_weighted": 0.7443829681316467
          },
          {
            "accuracy": 0.7154362416107383,
            "f1": 0.48301985492244576,
            "f1_weighted": 0.7535948123326793
          }
        ]
      }
    ]
  },
  "task_name": "MTOPIntentClassification"
}