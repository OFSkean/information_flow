{
  "dataset_revision": "d66bd1f72af766a5cc4b0ca5e00c162f89e8cc46",
  "evaluation_time": 28.260783672332764,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "cosine_accuracy": 0.9917128712871287,
        "cosine_accuracy_threshold": 0.9055051803588867,
        "cosine_ap": 0.40874619396821066,
        "cosine_f1": 0.4401055408970976,
        "cosine_f1_threshold": 0.882403552532196,
        "cosine_precision": 0.4659217877094972,
        "cosine_recall": 0.417,
        "dot_accuracy": 0.9905940594059406,
        "dot_accuracy_threshold": 3931.82470703125,
        "dot_ap": 0.21258478106985568,
        "dot_f1": 0.27098078867542974,
        "dot_f1_threshold": 3709.80810546875,
        "dot_precision": 0.2740286298568507,
        "dot_recall": 0.268,
        "euclidean_accuracy": 0.9914653465346535,
        "euclidean_accuracy_threshold": 27.509780883789062,
        "euclidean_ap": 0.37823828207858756,
        "euclidean_f1": 0.4210526315789474,
        "euclidean_f1_threshold": 30.60727882385254,
        "euclidean_precision": 0.4444444444444444,
        "euclidean_recall": 0.4,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.40874619396821066,
        "manhattan_accuracy": 0.9914653465346535,
        "manhattan_accuracy_threshold": 689.1971435546875,
        "manhattan_ap": 0.38401777211910904,
        "manhattan_f1": 0.42644628099173554,
        "manhattan_f1_threshold": 768.2877197265625,
        "manhattan_precision": 0.47484662576687114,
        "manhattan_recall": 0.387,
        "max_accuracy": 0.9917128712871287,
        "max_ap": 0.40874619396821066,
        "max_f1": 0.4401055408970976,
        "max_precision": 0.47484662576687114,
        "max_recall": 0.417,
        "similarity_accuracy": 0.9917128712871287,
        "similarity_accuracy_threshold": 0.9055051803588867,
        "similarity_ap": 0.40874619396821066,
        "similarity_f1": 0.4401055408970976,
        "similarity_f1_threshold": 0.882403552532196,
        "similarity_precision": 0.4659217877094972,
        "similarity_recall": 0.417
      }
    ],
    "validation": [
      {
        "cosine_accuracy": 0.9908712871287129,
        "cosine_accuracy_threshold": 0.9032412767410278,
        "cosine_ap": 0.3318244604258901,
        "cosine_f1": 0.3987308302485457,
        "cosine_f1_threshold": 0.875779390335083,
        "cosine_precision": 0.42312008978675647,
        "cosine_recall": 0.377,
        "dot_accuracy": 0.9902574257425742,
        "dot_accuracy_threshold": 3975.89990234375,
        "dot_ap": 0.15465319187152862,
        "dot_f1": 0.21867881548974943,
        "dot_f1_threshold": 3649.06201171875,
        "dot_precision": 0.200836820083682,
        "dot_recall": 0.24,
        "euclidean_accuracy": 0.9908910891089109,
        "euclidean_accuracy_threshold": 28.359233856201172,
        "euclidean_ap": 0.3059532385152913,
        "euclidean_f1": 0.3727272727272728,
        "euclidean_f1_threshold": 31.689640045166016,
        "euclidean_precision": 0.376530612244898,
        "euclidean_recall": 0.369,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.3318244604258901,
        "manhattan_accuracy": 0.9908811881188119,
        "manhattan_accuracy_threshold": 702.633056640625,
        "manhattan_ap": 0.311089278336929,
        "manhattan_f1": 0.3777452415812591,
        "manhattan_f1_threshold": 807.240234375,
        "manhattan_precision": 0.36892278360343184,
        "manhattan_recall": 0.387,
        "max_accuracy": 0.9908910891089109,
        "max_ap": 0.3318244604258901,
        "max_f1": 0.3987308302485457,
        "max_precision": 0.42312008978675647,
        "max_recall": 0.387,
        "similarity_accuracy": 0.9908712871287129,
        "similarity_accuracy_threshold": 0.9032412767410278,
        "similarity_ap": 0.3318244604258901,
        "similarity_f1": 0.3987308302485457,
        "similarity_f1_threshold": 0.875779390335083,
        "similarity_precision": 0.42312008978675647,
        "similarity_recall": 0.377
      }
    ]
  },
  "task_name": "SprintDuplicateQuestions"
}