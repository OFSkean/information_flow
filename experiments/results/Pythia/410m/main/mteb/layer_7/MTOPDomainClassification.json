{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 49.01052188873291,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.8319881440948471,
        "f1": 0.8261872886358083,
        "f1_weighted": 0.8324333771962482,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8319881440948471,
        "scores_per_experiment": [
          {
            "accuracy": 0.7957136342909257,
            "f1": 0.7901963307301195,
            "f1_weighted": 0.7927691226354585
          },
          {
            "accuracy": 0.8337893296853626,
            "f1": 0.8292767226167359,
            "f1_weighted": 0.8364419332079105
          },
          {
            "accuracy": 0.8383492932056543,
            "f1": 0.8289416837089884,
            "f1_weighted": 0.839007232855471
          },
          {
            "accuracy": 0.8381212950296397,
            "f1": 0.8298762252516437,
            "f1_weighted": 0.8380075712181516
          },
          {
            "accuracy": 0.8618331053351573,
            "f1": 0.8557234449243719,
            "f1_weighted": 0.8627255459497413
          },
          {
            "accuracy": 0.8461012311901505,
            "f1": 0.8413437211586462,
            "f1_weighted": 0.8464786676915692
          },
          {
            "accuracy": 0.810077519379845,
            "f1": 0.807009891412282,
            "f1_weighted": 0.8077012666082154
          },
          {
            "accuracy": 0.832421340629275,
            "f1": 0.8273256747262061,
            "f1_weighted": 0.8348332710584727
          },
          {
            "accuracy": 0.8271773825809393,
            "f1": 0.8237210155412916,
            "f1_weighted": 0.8288586023764813
          },
          {
            "accuracy": 0.836297309621523,
            "f1": 0.8284581762877955,
            "f1_weighted": 0.8375105583610101
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.8288590604026845,
        "f1": 0.8274470820612129,
        "f1_weighted": 0.829220715664774,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8288590604026845,
        "scores_per_experiment": [
          {
            "accuracy": 0.7888143176733781,
            "f1": 0.7908301845348089,
            "f1_weighted": 0.7851814581188151
          },
          {
            "accuracy": 0.8375838926174497,
            "f1": 0.8372298008542388,
            "f1_weighted": 0.8393094221099959
          },
          {
            "accuracy": 0.8357941834451902,
            "f1": 0.8281558267999523,
            "f1_weighted": 0.8363456051335743
          },
          {
            "accuracy": 0.8420581655480984,
            "f1": 0.8421749008289914,
            "f1_weighted": 0.8434627558924308
          },
          {
            "accuracy": 0.8541387024608501,
            "f1": 0.8537274389579395,
            "f1_weighted": 0.8553603869470833
          },
          {
            "accuracy": 0.8371364653243848,
            "f1": 0.8366688022343421,
            "f1_weighted": 0.8370647223517198
          },
          {
            "accuracy": 0.7977628635346756,
            "f1": 0.7949059634474375,
            "f1_weighted": 0.7961323206179077
          },
          {
            "accuracy": 0.8331096196868009,
            "f1": 0.8324889545975687,
            "f1_weighted": 0.8354708049806274
          },
          {
            "accuracy": 0.8331096196868009,
            "f1": 0.8324833738767526,
            "f1_weighted": 0.8339646136112867
          },
          {
            "accuracy": 0.829082774049217,
            "f1": 0.8258055744800976,
            "f1_weighted": 0.8299150668842971
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}