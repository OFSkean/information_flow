{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 131.48269963264465,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.34659999999999996,
        "f1": 0.34497798698632487,
        "f1_weighted": 0.3449779869863249,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.34659999999999996,
        "scores_per_experiment": [
          {
            "accuracy": 0.359,
            "f1": 0.3627452815083839,
            "f1_weighted": 0.3627452815083839
          },
          {
            "accuracy": 0.3598,
            "f1": 0.3602505382515636,
            "f1_weighted": 0.3602505382515636
          },
          {
            "accuracy": 0.3302,
            "f1": 0.328690558979443,
            "f1_weighted": 0.328690558979443
          },
          {
            "accuracy": 0.3542,
            "f1": 0.352566949768303,
            "f1_weighted": 0.352566949768303
          },
          {
            "accuracy": 0.3998,
            "f1": 0.38496738395932384,
            "f1_weighted": 0.38496738395932384
          },
          {
            "accuracy": 0.3072,
            "f1": 0.3049656049248311,
            "f1_weighted": 0.3049656049248311
          },
          {
            "accuracy": 0.3072,
            "f1": 0.3079076202703601,
            "f1_weighted": 0.3079076202703601
          },
          {
            "accuracy": 0.3574,
            "f1": 0.3546942917872042,
            "f1_weighted": 0.35469429178720424
          },
          {
            "accuracy": 0.3396,
            "f1": 0.3398501951371752,
            "f1_weighted": 0.3398501951371752
          },
          {
            "accuracy": 0.3516,
            "f1": 0.3531414452766614,
            "f1_weighted": 0.35314144527666147
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.34689999999999993,
        "f1": 0.34544722038728004,
        "f1_weighted": 0.34544722038728004,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.34689999999999993,
        "scores_per_experiment": [
          {
            "accuracy": 0.3496,
            "f1": 0.35401190717526737,
            "f1_weighted": 0.3540119071752673
          },
          {
            "accuracy": 0.3628,
            "f1": 0.3654798675941735,
            "f1_weighted": 0.36547986759417356
          },
          {
            "accuracy": 0.336,
            "f1": 0.33447233923315656,
            "f1_weighted": 0.33447233923315656
          },
          {
            "accuracy": 0.346,
            "f1": 0.34558556481089475,
            "f1_weighted": 0.3455855648108948
          },
          {
            "accuracy": 0.4026,
            "f1": 0.38712529011934144,
            "f1_weighted": 0.38712529011934144
          },
          {
            "accuracy": 0.3128,
            "f1": 0.30949060230752723,
            "f1_weighted": 0.30949060230752723
          },
          {
            "accuracy": 0.3156,
            "f1": 0.3159897799136529,
            "f1_weighted": 0.31598977991365285
          },
          {
            "accuracy": 0.3422,
            "f1": 0.3382252831160283,
            "f1_weighted": 0.33822528311602834
          },
          {
            "accuracy": 0.3444,
            "f1": 0.34650598467356575,
            "f1_weighted": 0.3465059846735657
          },
          {
            "accuracy": 0.357,
            "f1": 0.35758558492919257,
            "f1_weighted": 0.35758558492919257
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}