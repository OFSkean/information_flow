{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 43.406378507614136,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.799954400364797,
        "f1": 0.7937389155500858,
        "f1_weighted": 0.8026302521668638,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.799954400364797,
        "scores_per_experiment": [
          {
            "accuracy": 0.7432740538075695,
            "f1": 0.7423110885393299,
            "f1_weighted": 0.7460706295215391
          },
          {
            "accuracy": 0.7906976744186046,
            "f1": 0.7908514908153509,
            "f1_weighted": 0.7957646337289163
          },
          {
            "accuracy": 0.8093935248518012,
            "f1": 0.7970761315460243,
            "f1_weighted": 0.8110704210595788
          },
          {
            "accuracy": 0.8205654354765162,
            "f1": 0.8158819065347945,
            "f1_weighted": 0.8249010900913385
          },
          {
            "accuracy": 0.8326493388052896,
            "f1": 0.8239208636134808,
            "f1_weighted": 0.8354259357350436
          },
          {
            "accuracy": 0.808937528499772,
            "f1": 0.8026626897197002,
            "f1_weighted": 0.8115295364496814
          },
          {
            "accuracy": 0.7770177838577291,
            "f1": 0.767216043394857,
            "f1_weighted": 0.7755158012919743
          },
          {
            "accuracy": 0.7729138166894665,
            "f1": 0.7693817148502454,
            "f1_weighted": 0.7789573685569684
          },
          {
            "accuracy": 0.8194254445964432,
            "f1": 0.8147562094753866,
            "f1_weighted": 0.8230204067313691
          },
          {
            "accuracy": 0.8246694026447788,
            "f1": 0.813331017011688,
            "f1_weighted": 0.8240466985022278
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7900223713646533,
        "f1": 0.7878040609000687,
        "f1_weighted": 0.7920471322546099,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7900223713646533,
        "scores_per_experiment": [
          {
            "accuracy": 0.738255033557047,
            "f1": 0.7393854019868251,
            "f1_weighted": 0.7408865846778303
          },
          {
            "accuracy": 0.789261744966443,
            "f1": 0.7925250934210945,
            "f1_weighted": 0.792577667108223
          },
          {
            "accuracy": 0.8049217002237137,
            "f1": 0.7970185226874655,
            "f1_weighted": 0.805989856236147
          },
          {
            "accuracy": 0.8022371364653244,
            "f1": 0.8028449852530464,
            "f1_weighted": 0.8070567289636605
          },
          {
            "accuracy": 0.8237136465324385,
            "f1": 0.8196274046242181,
            "f1_weighted": 0.8254957172816203
          },
          {
            "accuracy": 0.8013422818791947,
            "f1": 0.7994662100557343,
            "f1_weighted": 0.8027048864407094
          },
          {
            "accuracy": 0.7583892617449665,
            "f1": 0.7508108616024789,
            "f1_weighted": 0.7573360505141452
          },
          {
            "accuracy": 0.7597315436241611,
            "f1": 0.7622749804590399,
            "f1_weighted": 0.7658122513936344
          },
          {
            "accuracy": 0.8134228187919463,
            "f1": 0.8122360048561821,
            "f1_weighted": 0.8154517347881539
          },
          {
            "accuracy": 0.8089485458612975,
            "f1": 0.8018511440546031,
            "f1_weighted": 0.8071598451419756
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}