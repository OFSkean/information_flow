{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 218.25226593017578,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.37055999999999994,
        "f1": 0.36898057752051766,
        "f1_weighted": 0.36898057752051766,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.37055999999999994,
        "scores_per_experiment": [
          {
            "accuracy": 0.3926,
            "f1": 0.3947704934132988,
            "f1_weighted": 0.39477049341329873
          },
          {
            "accuracy": 0.3902,
            "f1": 0.3894418749003642,
            "f1_weighted": 0.38944187490036414
          },
          {
            "accuracy": 0.3532,
            "f1": 0.34494616014300505,
            "f1_weighted": 0.34494616014300505
          },
          {
            "accuracy": 0.3854,
            "f1": 0.3854227712327175,
            "f1_weighted": 0.3854227712327174
          },
          {
            "accuracy": 0.4006,
            "f1": 0.3870067374115134,
            "f1_weighted": 0.3870067374115134
          },
          {
            "accuracy": 0.3362,
            "f1": 0.33706877181724676,
            "f1_weighted": 0.33706877181724676
          },
          {
            "accuracy": 0.335,
            "f1": 0.3370914872279871,
            "f1_weighted": 0.33709148722798715
          },
          {
            "accuracy": 0.3724,
            "f1": 0.3687346334730585,
            "f1_weighted": 0.3687346334730585
          },
          {
            "accuracy": 0.3682,
            "f1": 0.37206531351961664,
            "f1_weighted": 0.3720653135196167
          },
          {
            "accuracy": 0.3718,
            "f1": 0.3732575320663688,
            "f1_weighted": 0.3732575320663688
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.37408,
        "f1": 0.37166225477913717,
        "f1_weighted": 0.37166225477913717,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.37408,
        "scores_per_experiment": [
          {
            "accuracy": 0.3904,
            "f1": 0.3934549373095176,
            "f1_weighted": 0.39345493730951764
          },
          {
            "accuracy": 0.393,
            "f1": 0.39166116931875133,
            "f1_weighted": 0.39166116931875133
          },
          {
            "accuracy": 0.3652,
            "f1": 0.35795954421950105,
            "f1_weighted": 0.35795954421950105
          },
          {
            "accuracy": 0.378,
            "f1": 0.37786628785621545,
            "f1_weighted": 0.3778662878562155
          },
          {
            "accuracy": 0.4026,
            "f1": 0.3821994259978087,
            "f1_weighted": 0.38219942599780876
          },
          {
            "accuracy": 0.3462,
            "f1": 0.3467334964278704,
            "f1_weighted": 0.3467334964278704
          },
          {
            "accuracy": 0.3446,
            "f1": 0.3455390666642653,
            "f1_weighted": 0.34553906666426526
          },
          {
            "accuracy": 0.3598,
            "f1": 0.3563867656191453,
            "f1_weighted": 0.3563867656191453
          },
          {
            "accuracy": 0.3816,
            "f1": 0.3855858558401251,
            "f1_weighted": 0.3855858558401251
          },
          {
            "accuracy": 0.3794,
            "f1": 0.3792359985381718,
            "f1_weighted": 0.37923599853817175
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}