{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 55.16994833946228,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.8348609211126311,
        "f1": 0.8308480955821367,
        "f1_weighted": 0.8350723324931202,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8348609211126311,
        "scores_per_experiment": [
          {
            "accuracy": 0.8077975376196991,
            "f1": 0.8031330924199458,
            "f1_weighted": 0.8047279004358625
          },
          {
            "accuracy": 0.8522571819425444,
            "f1": 0.8481665608820438,
            "f1_weighted": 0.8534510981494667
          },
          {
            "accuracy": 0.8303693570451436,
            "f1": 0.8226944679509597,
            "f1_weighted": 0.8317111016880789
          },
          {
            "accuracy": 0.8394892840857273,
            "f1": 0.8336732196886494,
            "f1_weighted": 0.8394657108592469
          },
          {
            "accuracy": 0.859781121751026,
            "f1": 0.8569776650663085,
            "f1_weighted": 0.8603851194270372
          },
          {
            "accuracy": 0.8349293205654355,
            "f1": 0.8332146796061642,
            "f1_weighted": 0.8354146442898006
          },
          {
            "accuracy": 0.8173734610123119,
            "f1": 0.8131389416783512,
            "f1_weighted": 0.8142792221033538
          },
          {
            "accuracy": 0.8365253077975376,
            "f1": 0.831693270749252,
            "f1_weighted": 0.8387682857549982
          },
          {
            "accuracy": 0.8399452804377565,
            "f1": 0.8391961104986084,
            "f1_weighted": 0.8411254176019196
          },
          {
            "accuracy": 0.8301413588691291,
            "f1": 0.8265929472810836,
            "f1_weighted": 0.8313948246214373
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.8301118568232662,
        "f1": 0.8299622443488011,
        "f1_weighted": 0.8301968811793385,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8301118568232662,
        "scores_per_experiment": [
          {
            "accuracy": 0.7968680089485458,
            "f1": 0.7995257031328449,
            "f1_weighted": 0.79443521631966
          },
          {
            "accuracy": 0.8550335570469799,
            "f1": 0.8550289384096836,
            "f1_weighted": 0.8557835330369593
          },
          {
            "accuracy": 0.829082774049217,
            "f1": 0.8229284817035356,
            "f1_weighted": 0.8296533045417449
          },
          {
            "accuracy": 0.8371364653243848,
            "f1": 0.838329450607445,
            "f1_weighted": 0.8370591769661607
          },
          {
            "accuracy": 0.851006711409396,
            "f1": 0.854309121978405,
            "f1_weighted": 0.8522662260651204
          },
          {
            "accuracy": 0.8322147651006712,
            "f1": 0.8333322008575293,
            "f1_weighted": 0.8320737977999625
          },
          {
            "accuracy": 0.807158836689038,
            "f1": 0.8040910039919205,
            "f1_weighted": 0.8051711776595051
          },
          {
            "accuracy": 0.825503355704698,
            "f1": 0.8245425369588074,
            "f1_weighted": 0.8277879098669025
          },
          {
            "accuracy": 0.8429530201342282,
            "f1": 0.8421693988907296,
            "f1_weighted": 0.8432523437012114
          },
          {
            "accuracy": 0.8241610738255034,
            "f1": 0.8253656069571094,
            "f1_weighted": 0.824486125836158
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}