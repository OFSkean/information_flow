{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 52.628578901290894,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.8375512995896033,
        "f1": 0.8331003249102121,
        "f1_weighted": 0.83768626731168,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8375512995896033,
        "scores_per_experiment": [
          {
            "accuracy": 0.8093935248518012,
            "f1": 0.8058406098057694,
            "f1_weighted": 0.8054053603235621
          },
          {
            "accuracy": 0.8579571363429093,
            "f1": 0.8522934779233399,
            "f1_weighted": 0.8604673911947319
          },
          {
            "accuracy": 0.8388052895576835,
            "f1": 0.8303087288086214,
            "f1_weighted": 0.8395316495381171
          },
          {
            "accuracy": 0.8401732786137711,
            "f1": 0.8327295433831989,
            "f1_weighted": 0.8406213389198177
          },
          {
            "accuracy": 0.8657090743274054,
            "f1": 0.8603322615960113,
            "f1_weighted": 0.8661870457407291
          },
          {
            "accuracy": 0.8429092567259462,
            "f1": 0.8413478946018913,
            "f1_weighted": 0.8429695601923968
          },
          {
            "accuracy": 0.8109895120839034,
            "f1": 0.8075355407632593,
            "f1_weighted": 0.807407992448134
          },
          {
            "accuracy": 0.8369813041495668,
            "f1": 0.8305372078653924,
            "f1_weighted": 0.8393086254089879
          },
          {
            "accuracy": 0.8406292749658003,
            "f1": 0.8408301745255102,
            "f1_weighted": 0.8417190414102588
          },
          {
            "accuracy": 0.8319653442772458,
            "f1": 0.8292478098291268,
            "f1_weighted": 0.8332446679400658
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.8335123042505591,
        "f1": 0.8332042714316674,
        "f1_weighted": 0.8336280465794396,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8335123042505591,
        "scores_per_experiment": [
          {
            "accuracy": 0.7977628635346756,
            "f1": 0.8001669260044886,
            "f1_weighted": 0.7941064558920329
          },
          {
            "accuracy": 0.8577181208053691,
            "f1": 0.8567439495308602,
            "f1_weighted": 0.85920413508481
          },
          {
            "accuracy": 0.8313199105145413,
            "f1": 0.8238253975840899,
            "f1_weighted": 0.8316095820814647
          },
          {
            "accuracy": 0.8425055928411633,
            "f1": 0.8443575286602787,
            "f1_weighted": 0.8434303627075711
          },
          {
            "accuracy": 0.8586129753914988,
            "f1": 0.8611951928634848,
            "f1_weighted": 0.8597491741558857
          },
          {
            "accuracy": 0.8389261744966443,
            "f1": 0.8387935633073368,
            "f1_weighted": 0.8391128260380344
          },
          {
            "accuracy": 0.8022371364653244,
            "f1": 0.7996174511707452,
            "f1_weighted": 0.800169198951096
          },
          {
            "accuracy": 0.8375838926174497,
            "f1": 0.8369127695276876,
            "f1_weighted": 0.8399099567109409
          },
          {
            "accuracy": 0.8416107382550335,
            "f1": 0.8415879666569798,
            "f1_weighted": 0.8417470859366379
          },
          {
            "accuracy": 0.8268456375838926,
            "f1": 0.8288419690107229,
            "f1_weighted": 0.8272416882359216
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}