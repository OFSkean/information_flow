{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 197.6837067604065,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.37370000000000003,
        "f1": 0.3709630655200751,
        "f1_weighted": 0.3709630655200751,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.37370000000000003,
        "scores_per_experiment": [
          {
            "accuracy": 0.3806,
            "f1": 0.3825886868972551,
            "f1_weighted": 0.3825886868972551
          },
          {
            "accuracy": 0.3868,
            "f1": 0.3859450926237872,
            "f1_weighted": 0.38594509262378723
          },
          {
            "accuracy": 0.3648,
            "f1": 0.3540094956657168,
            "f1_weighted": 0.3540094956657168
          },
          {
            "accuracy": 0.3874,
            "f1": 0.38640882890099365,
            "f1_weighted": 0.3864088289009937
          },
          {
            "accuracy": 0.414,
            "f1": 0.3963157364207979,
            "f1_weighted": 0.3963157364207979
          },
          {
            "accuracy": 0.3454,
            "f1": 0.34753730673643607,
            "f1_weighted": 0.347537306736436
          },
          {
            "accuracy": 0.3448,
            "f1": 0.345090138833071,
            "f1_weighted": 0.345090138833071
          },
          {
            "accuracy": 0.3748,
            "f1": 0.37095383795931774,
            "f1_weighted": 0.37095383795931774
          },
          {
            "accuracy": 0.366,
            "f1": 0.3682357056721122,
            "f1_weighted": 0.3682357056721122
          },
          {
            "accuracy": 0.3724,
            "f1": 0.3725458254912632,
            "f1_weighted": 0.3725458254912632
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.38042,
        "f1": 0.37698938466464554,
        "f1_weighted": 0.3769893846646456,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.38042,
        "scores_per_experiment": [
          {
            "accuracy": 0.3874,
            "f1": 0.3908651913294946,
            "f1_weighted": 0.3908651913294946
          },
          {
            "accuracy": 0.397,
            "f1": 0.39613680266817547,
            "f1_weighted": 0.3961368026681755
          },
          {
            "accuracy": 0.3754,
            "f1": 0.36474812135846796,
            "f1_weighted": 0.364748121358468
          },
          {
            "accuracy": 0.3854,
            "f1": 0.38411671606239695,
            "f1_weighted": 0.3841167160623969
          },
          {
            "accuracy": 0.413,
            "f1": 0.389738557909161,
            "f1_weighted": 0.389738557909161
          },
          {
            "accuracy": 0.3484,
            "f1": 0.35008117824032603,
            "f1_weighted": 0.3500811782403261
          },
          {
            "accuracy": 0.3558,
            "f1": 0.35523248946807967,
            "f1_weighted": 0.3552324894680797
          },
          {
            "accuracy": 0.3696,
            "f1": 0.3644662119960603,
            "f1_weighted": 0.36446621199606033
          },
          {
            "accuracy": 0.3878,
            "f1": 0.39171323253607476,
            "f1_weighted": 0.3917132325360748
          },
          {
            "accuracy": 0.3844,
            "f1": 0.382795345078219,
            "f1_weighted": 0.38279534507821905
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}