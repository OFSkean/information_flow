{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 46.71282935142517,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.8193570451436388,
        "f1": 0.8132191645647486,
        "f1_weighted": 0.8204498530159127,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8193570451436388,
        "scores_per_experiment": [
          {
            "accuracy": 0.7781577747378021,
            "f1": 0.7738487794823893,
            "f1_weighted": 0.7769940265506327
          },
          {
            "accuracy": 0.8248974008207934,
            "f1": 0.8202984161374435,
            "f1_weighted": 0.8276317107478468
          },
          {
            "accuracy": 0.8315093479252166,
            "f1": 0.820341374030826,
            "f1_weighted": 0.8332906067500121
          },
          {
            "accuracy": 0.8253533971728226,
            "f1": 0.8174973757079266,
            "f1_weighted": 0.8267869624366547
          },
          {
            "accuracy": 0.8461012311901505,
            "f1": 0.8374905961248756,
            "f1_weighted": 0.8479861438759542
          },
          {
            "accuracy": 0.826265389876881,
            "f1": 0.8221518117295807,
            "f1_weighted": 0.827334671757499
          },
          {
            "accuracy": 0.8014135886912904,
            "f1": 0.795832402537327,
            "f1_weighted": 0.7992598920079271
          },
          {
            "accuracy": 0.8148654810761514,
            "f1": 0.8116332374044913,
            "f1_weighted": 0.8183221278142732
          },
          {
            "accuracy": 0.8194254445964432,
            "f1": 0.8157755316322043,
            "f1_weighted": 0.8211995027008462
          },
          {
            "accuracy": 0.8255813953488372,
            "f1": 0.8173221208604212,
            "f1_weighted": 0.8256928855174794
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.8149888143176733,
        "f1": 0.8127543127399413,
        "f1_weighted": 0.815762377913116,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8149888143176733,
        "scores_per_experiment": [
          {
            "accuracy": 0.7736017897091723,
            "f1": 0.7738997520059125,
            "f1_weighted": 0.7728845147709649
          },
          {
            "accuracy": 0.8237136465324385,
            "f1": 0.8252402231888568,
            "f1_weighted": 0.8250415783437753
          },
          {
            "accuracy": 0.821923937360179,
            "f1": 0.81446255203244,
            "f1_weighted": 0.8236895944594317
          },
          {
            "accuracy": 0.8268456375838926,
            "f1": 0.8265567791994272,
            "f1_weighted": 0.8296097623314588
          },
          {
            "accuracy": 0.8411633109619687,
            "f1": 0.8394909412037715,
            "f1_weighted": 0.8426582187294319
          },
          {
            "accuracy": 0.8246085011185682,
            "f1": 0.8238881842285671,
            "f1_weighted": 0.8244918296164149
          },
          {
            "accuracy": 0.8058165548098434,
            "f1": 0.7993142881220622,
            "f1_weighted": 0.803156142279842
          },
          {
            "accuracy": 0.7955257270693512,
            "f1": 0.7954537365644581,
            "f1_weighted": 0.7990379429562969
          },
          {
            "accuracy": 0.8174496644295302,
            "f1": 0.8148758082000795,
            "f1_weighted": 0.8182627611675762
          },
          {
            "accuracy": 0.8192393736017897,
            "f1": 0.8143608626538377,
            "f1_weighted": 0.8187914344759682
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}