{
  "dataset_revision": "ae001d0e6b1228650b7bd1c2c65fb50ad11a8aba",
  "evaluation_time": 49.56391787528992,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.5011399908800731,
        "f1": 0.33734492365296564,
        "f1_weighted": 0.553308600322983,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5011399908800731,
        "scores_per_experiment": [
          {
            "accuracy": 0.5015959872321022,
            "f1": 0.35119315553617425,
            "f1_weighted": 0.5538063260850516
          },
          {
            "accuracy": 0.5063839489284085,
            "f1": 0.3390149852731095,
            "f1_weighted": 0.5552625966728166
          },
          {
            "accuracy": 0.4840401276789786,
            "f1": 0.31881300523901707,
            "f1_weighted": 0.53851383255336
          },
          {
            "accuracy": 0.4858641130870953,
            "f1": 0.33326380896722535,
            "f1_weighted": 0.5333332174674832
          },
          {
            "accuracy": 0.4993160054719562,
            "f1": 0.33823297843308353,
            "f1_weighted": 0.5533575377708444
          },
          {
            "accuracy": 0.5159598723210215,
            "f1": 0.3561445193057247,
            "f1_weighted": 0.5669605872407613
          },
          {
            "accuracy": 0.5079799361605107,
            "f1": 0.3483887559793751,
            "f1_weighted": 0.5599504421206668
          },
          {
            "accuracy": 0.5227998176014592,
            "f1": 0.3480571064313939,
            "f1_weighted": 0.5749155453308148
          },
          {
            "accuracy": 0.5077519379844961,
            "f1": 0.3367861632143877,
            "f1_weighted": 0.565514013769512
          },
          {
            "accuracy": 0.4797081623347013,
            "f1": 0.3035547581501648,
            "f1_weighted": 0.5314719042185198
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.5058165548098434,
        "f1": 0.33078562629934305,
        "f1_weighted": 0.5583928691095997,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5058165548098434,
        "scores_per_experiment": [
          {
            "accuracy": 0.47651006711409394,
            "f1": 0.3068729053774306,
            "f1_weighted": 0.5253000422847232
          },
          {
            "accuracy": 0.5158836689038031,
            "f1": 0.34252267901531586,
            "f1_weighted": 0.5649959800599964
          },
          {
            "accuracy": 0.5020134228187919,
            "f1": 0.32169354158873825,
            "f1_weighted": 0.5566872872054214
          },
          {
            "accuracy": 0.483668903803132,
            "f1": 0.32169787164187064,
            "f1_weighted": 0.529886644907941
          },
          {
            "accuracy": 0.5203579418344519,
            "f1": 0.35500655154029404,
            "f1_weighted": 0.5779772758051356
          },
          {
            "accuracy": 0.5145413870246085,
            "f1": 0.340584842028914,
            "f1_weighted": 0.5643081716359309
          },
          {
            "accuracy": 0.5140939597315436,
            "f1": 0.33774248390649075,
            "f1_weighted": 0.5695208030153294
          },
          {
            "accuracy": 0.5288590604026846,
            "f1": 0.33513314224628943,
            "f1_weighted": 0.5823228829714135
          },
          {
            "accuracy": 0.5024608501118568,
            "f1": 0.325997315279637,
            "f1_weighted": 0.5613205103392791
          },
          {
            "accuracy": 0.49977628635346755,
            "f1": 0.3206049303684503,
            "f1_weighted": 0.5516090928708275
          }
        ]
      }
    ]
  },
  "task_name": "MTOPIntentClassification"
}