{
  "dataset_revision": "edfaf9da55d3dd50d43143d90c1ac476895ae6de",
  "evaluation_time": 30.874367237091064,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.539306640625,
        "ap": 0.08506525756971761,
        "ap_weighted": 0.08506525756971761,
        "f1": 0.41694705552780464,
        "f1_weighted": 0.6385881372880359,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.539306640625,
        "scores_per_experiment": [
          {
            "accuracy": 0.60107421875,
            "ap": 0.08974158771612475,
            "ap_weighted": 0.08974158771612475,
            "f1": 0.4524485284613106,
            "f1_weighted": 0.6925897562567187
          },
          {
            "accuracy": 0.61767578125,
            "ap": 0.07816712312941068,
            "ap_weighted": 0.07816712312941068,
            "f1": 0.44026430288021023,
            "f1_weighted": 0.705535238447875
          },
          {
            "accuracy": 0.6376953125,
            "ap": 0.09342578255338671,
            "ap_weighted": 0.09342578255338671,
            "f1": 0.47253650483792364,
            "f1_weighted": 0.720995304497103
          },
          {
            "accuracy": 0.47509765625,
            "ap": 0.08470712409132908,
            "ap_weighted": 0.08470712409132908,
            "f1": 0.3868391552884983,
            "f1_weighted": 0.5826662539469653
          },
          {
            "accuracy": 0.46044921875,
            "ap": 0.08053897195452255,
            "ap_weighted": 0.08053897195452255,
            "f1": 0.3745438023029537,
            "f1_weighted": 0.5696702027702895
          },
          {
            "accuracy": 0.42236328125,
            "ap": 0.08082904361116167,
            "ap_weighted": 0.08082904361116167,
            "f1": 0.3542822525858331,
            "f1_weighted": 0.530781039679102
          },
          {
            "accuracy": 0.568359375,
            "ap": 0.08702476396691636,
            "ap_weighted": 0.08702476396691636,
            "f1": 0.43464422937599617,
            "f1_weighted": 0.6660949432874245
          },
          {
            "accuracy": 0.5263671875,
            "ap": 0.0822340661401691,
            "ap_weighted": 0.0822340661401691,
            "f1": 0.40921202893033876,
            "f1_weighted": 0.6306763857001808
          },
          {
            "accuracy": 0.56201171875,
            "ap": 0.08919881572797925,
            "ap_weighted": 0.08919881572797925,
            "f1": 0.4343299230964643,
            "f1_weighted": 0.6605615939152676
          },
          {
            "accuracy": 0.52197265625,
            "ap": 0.08478529680617594,
            "ap_weighted": 0.08478529680617594,
            "f1": 0.4103698275185175,
            "f1_weighted": 0.626310654379433
          }
        ]
      }
    ]
  },
  "task_name": "ToxicConversationsClassification"
}