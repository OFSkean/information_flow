{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 53.631229639053345,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.2835,
        "f1": 0.2819966632082436,
        "f1_weighted": 0.2819966632082436,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.2835,
        "scores_per_experiment": [
          {
            "accuracy": 0.2986,
            "f1": 0.29806959254239007,
            "f1_weighted": 0.29806959254239007
          },
          {
            "accuracy": 0.3004,
            "f1": 0.3026136798640666,
            "f1_weighted": 0.3026136798640666
          },
          {
            "accuracy": 0.2762,
            "f1": 0.2735676186422565,
            "f1_weighted": 0.2735676186422565
          },
          {
            "accuracy": 0.2576,
            "f1": 0.25434961460598726,
            "f1_weighted": 0.25434961460598726
          },
          {
            "accuracy": 0.3202,
            "f1": 0.3114365793281654,
            "f1_weighted": 0.31143657932816543
          },
          {
            "accuracy": 0.2668,
            "f1": 0.26479820245965147,
            "f1_weighted": 0.26479820245965147
          },
          {
            "accuracy": 0.2442,
            "f1": 0.244059466051984,
            "f1_weighted": 0.24405946605198406
          },
          {
            "accuracy": 0.3076,
            "f1": 0.3085454380940704,
            "f1_weighted": 0.3085454380940704
          },
          {
            "accuracy": 0.2666,
            "f1": 0.263247292775019,
            "f1_weighted": 0.263247292775019
          },
          {
            "accuracy": 0.2968,
            "f1": 0.29927914771884556,
            "f1_weighted": 0.2992791477188455
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.28331999999999996,
        "f1": 0.2815087102679266,
        "f1_weighted": 0.2815087102679266,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.28331999999999996,
        "scores_per_experiment": [
          {
            "accuracy": 0.2926,
            "f1": 0.2917828944323803,
            "f1_weighted": 0.29178289443238037
          },
          {
            "accuracy": 0.293,
            "f1": 0.29686924599011805,
            "f1_weighted": 0.29686924599011805
          },
          {
            "accuracy": 0.2748,
            "f1": 0.2737492498528601,
            "f1_weighted": 0.2737492498528601
          },
          {
            "accuracy": 0.2464,
            "f1": 0.24394738563976368,
            "f1_weighted": 0.24394738563976365
          },
          {
            "accuracy": 0.3206,
            "f1": 0.30908255083673974,
            "f1_weighted": 0.3090825508367398
          },
          {
            "accuracy": 0.2612,
            "f1": 0.2589813745782893,
            "f1_weighted": 0.25898137457828935
          },
          {
            "accuracy": 0.2624,
            "f1": 0.26022907511088755,
            "f1_weighted": 0.2602290751108875
          },
          {
            "accuracy": 0.3006,
            "f1": 0.30122683177829745,
            "f1_weighted": 0.3012268317782975
          },
          {
            "accuracy": 0.2782,
            "f1": 0.2743590313522001,
            "f1_weighted": 0.2743590313522001
          },
          {
            "accuracy": 0.3034,
            "f1": 0.3048594631077298,
            "f1_weighted": 0.3048594631077298
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}