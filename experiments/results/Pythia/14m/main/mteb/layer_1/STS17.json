{
  "dataset_revision": "faeb762787bd10488a50c8b5be4a3b82e411949c",
  "evaluation_time": 26.49127197265625,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.013921250383224677,
        "cosine_spearman": 0.041768913636242785,
        "euclidean_pearson": -0.04039880406349709,
        "euclidean_spearman": -0.017686085314910872,
        "hf_subset": "en-de",
        "languages": [
          "eng-Latn",
          "deu-Latn"
        ],
        "main_score": 0.041768913636242785,
        "manhattan_pearson": -0.020396777906458646,
        "manhattan_spearman": 0.00040092560277009436,
        "pearson": 0.013921250383224677,
        "spearman": 0.041768913636242785
      },
      {
        "cosine_pearson": 0.0032140477369439523,
        "cosine_spearman": 0.018732028330383,
        "euclidean_pearson": -0.047232743306465506,
        "euclidean_spearman": -0.03710848985102263,
        "hf_subset": "fr-en",
        "languages": [
          "fra-Latn",
          "eng-Latn"
        ],
        "main_score": 0.018732028330383,
        "manhattan_pearson": -0.06113186395939967,
        "manhattan_spearman": -0.06419653040865042,
        "pearson": 0.0032140477369439523,
        "spearman": 0.018732028330383
      },
      {
        "cosine_pearson": 0.02183872544854608,
        "cosine_spearman": 0.007580299987177622,
        "euclidean_pearson": -0.02131489818763334,
        "euclidean_spearman": -0.029024630381938175,
        "hf_subset": "it-en",
        "languages": [
          "ita-Latn",
          "eng-Latn"
        ],
        "main_score": 0.007580299987177622,
        "manhattan_pearson": -0.03826771250723369,
        "manhattan_spearman": -0.03469140433786984,
        "pearson": 0.02183872544854608,
        "spearman": 0.007580299987177622
      },
      {
        "cosine_pearson": -0.11868464326922067,
        "cosine_spearman": -0.10477714233698823,
        "euclidean_pearson": -0.18037576981989661,
        "euclidean_spearman": -0.16661965882934626,
        "hf_subset": "en-tr",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ],
        "main_score": -0.10477714233698823,
        "manhattan_pearson": -0.1567366255650823,
        "manhattan_spearman": -0.14868409489521778,
        "pearson": -0.11868464326922067,
        "spearman": -0.10477714233698823
      },
      {
        "cosine_pearson": 0.042333617829827745,
        "cosine_spearman": 0.04219828904999025,
        "euclidean_pearson": 0.00901839147283165,
        "euclidean_spearman": -0.005505829529316015,
        "hf_subset": "es-en",
        "languages": [
          "spa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.04219828904999025,
        "manhattan_pearson": 0.02811483127165643,
        "manhattan_spearman": 0.014911333318189468,
        "pearson": 0.042333617829827745,
        "spearman": 0.04219828904999025
      },
      {
        "cosine_pearson": 0.43756177379057504,
        "cosine_spearman": 0.5364703614201254,
        "euclidean_pearson": 0.462641559627401,
        "euclidean_spearman": 0.5134442392176958,
        "hf_subset": "en-en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5364703614201254,
        "manhattan_pearson": 0.47685525446780896,
        "manhattan_spearman": 0.5193604865352743,
        "pearson": 0.43756177379057504,
        "spearman": 0.5364703614201254
      },
      {
        "cosine_pearson": 0.059411399450671365,
        "cosine_spearman": 0.05153482529643813,
        "euclidean_pearson": 0.016064031192560037,
        "euclidean_spearman": 0.00662165575579523,
        "hf_subset": "en-ar",
        "languages": [
          "eng-Latn",
          "ara-Arab"
        ],
        "main_score": 0.05153482529643813,
        "manhattan_pearson": 0.008544658763137222,
        "manhattan_spearman": 0.009119864321737016,
        "pearson": 0.059411399450671365,
        "spearman": 0.05153482529643813
      },
      {
        "cosine_pearson": 0.010745353550892438,
        "cosine_spearman": 0.036202082783590335,
        "euclidean_pearson": -0.028811946065627342,
        "euclidean_spearman": -0.021739931342536392,
        "hf_subset": "nl-en",
        "languages": [
          "nld-Latn",
          "eng-Latn"
        ],
        "main_score": 0.036202082783590335,
        "manhattan_pearson": -0.057258414686497124,
        "manhattan_spearman": -0.05262580982477447,
        "pearson": 0.010745353550892438,
        "spearman": 0.036202082783590335
      }
    ]
  },
  "task_name": "STS17"
}