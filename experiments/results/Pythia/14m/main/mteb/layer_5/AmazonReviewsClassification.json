{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 62.186768770217896,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.30096,
        "f1": 0.29835004664550313,
        "f1_weighted": 0.2983500466455032,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.30096,
        "scores_per_experiment": [
          {
            "accuracy": 0.3168,
            "f1": 0.31539236883059996,
            "f1_weighted": 0.3153923688305999
          },
          {
            "accuracy": 0.286,
            "f1": 0.2888715337229089,
            "f1_weighted": 0.28887153372290897
          },
          {
            "accuracy": 0.2808,
            "f1": 0.27657551442096284,
            "f1_weighted": 0.2765755144209629
          },
          {
            "accuracy": 0.2984,
            "f1": 0.29532843703738915,
            "f1_weighted": 0.2953284370373892
          },
          {
            "accuracy": 0.3382,
            "f1": 0.3350865230031762,
            "f1_weighted": 0.3350865230031762
          },
          {
            "accuracy": 0.301,
            "f1": 0.29577239674079453,
            "f1_weighted": 0.29577239674079453
          },
          {
            "accuracy": 0.2692,
            "f1": 0.2671963446389731,
            "f1_weighted": 0.26719634463897307
          },
          {
            "accuracy": 0.3254,
            "f1": 0.320906782371745,
            "f1_weighted": 0.3209067823717451
          },
          {
            "accuracy": 0.2956,
            "f1": 0.29034638379100375,
            "f1_weighted": 0.2903463837910038
          },
          {
            "accuracy": 0.2982,
            "f1": 0.2980241818974777,
            "f1_weighted": 0.2980241818974777
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.30042,
        "f1": 0.2979585178224154,
        "f1_weighted": 0.2979585178224154,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.30042,
        "scores_per_experiment": [
          {
            "accuracy": 0.3086,
            "f1": 0.3082583039228949,
            "f1_weighted": 0.3082583039228949
          },
          {
            "accuracy": 0.2794,
            "f1": 0.28281067032533197,
            "f1_weighted": 0.28281067032533197
          },
          {
            "accuracy": 0.2812,
            "f1": 0.27827256375895526,
            "f1_weighted": 0.2782725637589553
          },
          {
            "accuracy": 0.2984,
            "f1": 0.2954127454449049,
            "f1_weighted": 0.29541274544490487
          },
          {
            "accuracy": 0.3294,
            "f1": 0.3247531730587304,
            "f1_weighted": 0.3247531730587304
          },
          {
            "accuracy": 0.29,
            "f1": 0.28389552893265824,
            "f1_weighted": 0.2838955289326583
          },
          {
            "accuracy": 0.2742,
            "f1": 0.2738247453254262,
            "f1_weighted": 0.27382474532542617
          },
          {
            "accuracy": 0.3344,
            "f1": 0.32932394974886026,
            "f1_weighted": 0.3293239497488602
          },
          {
            "accuracy": 0.3124,
            "f1": 0.3069109729630085,
            "f1_weighted": 0.30691097296300857
          },
          {
            "accuracy": 0.2962,
            "f1": 0.2961225247433831,
            "f1_weighted": 0.29612252474338313
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}