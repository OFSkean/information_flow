{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 63.91016221046448,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.30236,
        "f1": 0.30075593756657004,
        "f1_weighted": 0.30075593756657,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.30236,
        "scores_per_experiment": [
          {
            "accuracy": 0.3116,
            "f1": 0.3101957133422221,
            "f1_weighted": 0.3101957133422221
          },
          {
            "accuracy": 0.2782,
            "f1": 0.28003091599878255,
            "f1_weighted": 0.28003091599878255
          },
          {
            "accuracy": 0.2746,
            "f1": 0.27294949060038104,
            "f1_weighted": 0.2729494906003811
          },
          {
            "accuracy": 0.2926,
            "f1": 0.29548744339401756,
            "f1_weighted": 0.29548744339401756
          },
          {
            "accuracy": 0.344,
            "f1": 0.338203067724264,
            "f1_weighted": 0.338203067724264
          },
          {
            "accuracy": 0.3144,
            "f1": 0.3121018531821415,
            "f1_weighted": 0.3121018531821415
          },
          {
            "accuracy": 0.2812,
            "f1": 0.276809390972856,
            "f1_weighted": 0.27680939097285595
          },
          {
            "accuracy": 0.3202,
            "f1": 0.31982956747499525,
            "f1_weighted": 0.3198295674749952
          },
          {
            "accuracy": 0.2984,
            "f1": 0.2934548980268342,
            "f1_weighted": 0.2934548980268342
          },
          {
            "accuracy": 0.3084,
            "f1": 0.30849703494920566,
            "f1_weighted": 0.30849703494920566
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.3049,
        "f1": 0.30337285611620485,
        "f1_weighted": 0.30337285611620485,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.3049,
        "scores_per_experiment": [
          {
            "accuracy": 0.3108,
            "f1": 0.31108197703264884,
            "f1_weighted": 0.31108197703264884
          },
          {
            "accuracy": 0.2784,
            "f1": 0.27986233401184546,
            "f1_weighted": 0.27986233401184546
          },
          {
            "accuracy": 0.2884,
            "f1": 0.28769426563062067,
            "f1_weighted": 0.2876942656306206
          },
          {
            "accuracy": 0.2938,
            "f1": 0.2968627602439128,
            "f1_weighted": 0.29686276024391284
          },
          {
            "accuracy": 0.3392,
            "f1": 0.33251026026611646,
            "f1_weighted": 0.33251026026611646
          },
          {
            "accuracy": 0.3062,
            "f1": 0.3032883752629624,
            "f1_weighted": 0.3032883752629623
          },
          {
            "accuracy": 0.2932,
            "f1": 0.28923361893611266,
            "f1_weighted": 0.28923361893611266
          },
          {
            "accuracy": 0.322,
            "f1": 0.32101484632331057,
            "f1_weighted": 0.32101484632331057
          },
          {
            "accuracy": 0.3058,
            "f1": 0.30113812517229344,
            "f1_weighted": 0.30113812517229344
          },
          {
            "accuracy": 0.3112,
            "f1": 0.31104199828222584,
            "f1_weighted": 0.31104199828222584
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}