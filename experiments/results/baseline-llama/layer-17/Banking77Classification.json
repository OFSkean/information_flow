{"dataset_revision": "0fd18e25b25c072e09e0d92ab615fda904d66300", "evaluation_time": 139.901020526886, "kg_co2_emissions": null, "mteb_version": "1.12.49", "scores": {"test": [{"accuracy": 0.6619155844155845, "f1": 0.6606439687469325, "f1_weighted": 0.6606439687469325, "hf_subset": "default", "languages": ["eng-Latn"], "main_score": 0.6619155844155845, "scores_per_experiment": [{"accuracy": 0.6532467532467533, "f1": 0.6512308383562584, "f1_weighted": 0.6512308383562584}, {"accuracy": 0.6590909090909091, "f1": 0.6605188403874259, "f1_weighted": 0.6605188403874257}, {"accuracy": 0.6701298701298701, "f1": 0.6694638217315263, "f1_weighted": 0.6694638217315263}, {"accuracy": 0.672077922077922, "f1": 0.6722529201408496, "f1_weighted": 0.6722529201408498}, {"accuracy": 0.6688311688311688, "f1": 0.6677009731292471, "f1_weighted": 0.6677009731292471}, {"accuracy": 0.6496753246753246, "f1": 0.6466223697935741, "f1_weighted": 0.646622369793574}, {"accuracy": 0.6698051948051948, "f1": 0.6674979555406979, "f1_weighted": 0.6674979555406979}, {"accuracy": 0.6568181818181819, "f1": 0.6544227290857209, "f1_weighted": 0.6544227290857207}, {"accuracy": 0.6701298701298701, "f1": 0.6693422464176845, "f1_weighted": 0.6693422464176846}, {"accuracy": 0.6493506493506493, "f1": 0.6473869928863404, "f1_weighted": 0.6473869928863405}]}]}, "task_name": "Banking77Classification", "avg_layerwise_entropy": 0.41870240589591023, "num_samples": 64}