{"dataset_revision": "0fd18e25b25c072e09e0d92ab615fda904d66300", "evaluation_time": 144.15025067329407, "kg_co2_emissions": null, "mteb_version": "1.12.49", "scores": {"test": [{"accuracy": 0.736168831168831, "f1": 0.7351868694765501, "f1_weighted": 0.7351868694765502, "hf_subset": "default", "languages": ["eng-Latn"], "main_score": 0.736168831168831, "scores_per_experiment": [{"accuracy": 0.7237012987012987, "f1": 0.7214915872643404, "f1_weighted": 0.7214915872643404}, {"accuracy": 0.7350649350649351, "f1": 0.7362362244020726, "f1_weighted": 0.7362362244020726}, {"accuracy": 0.75, "f1": 0.7494856790447393, "f1_weighted": 0.749485679044739}, {"accuracy": 0.750974025974026, "f1": 0.7508451898778408, "f1_weighted": 0.750845189877841}, {"accuracy": 0.7396103896103896, "f1": 0.7394815349302235, "f1_weighted": 0.7394815349302235}, {"accuracy": 0.7311688311688311, "f1": 0.7282030614607405, "f1_weighted": 0.7282030614607405}, {"accuracy": 0.7399350649350649, "f1": 0.738278600795754, "f1_weighted": 0.7382786007957541}, {"accuracy": 0.7295454545454545, "f1": 0.7276819408175695, "f1_weighted": 0.7276819408175694}, {"accuracy": 0.7314935064935065, "f1": 0.7309610543589069, "f1_weighted": 0.730961054358907}, {"accuracy": 0.7301948051948052, "f1": 0.7292038218133138, "f1_weighted": 0.7292038218133139}]}]}, "task_name": "Banking77Classification", "avg_layerwise_entropy": 0.7829414041210354, "num_samples": 64}