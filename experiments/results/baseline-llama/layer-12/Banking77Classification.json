{"dataset_revision": "0fd18e25b25c072e09e0d92ab615fda904d66300", "evaluation_time": 121.21986317634583, "kg_co2_emissions": null, "mteb_version": "1.12.49", "scores": {"test": [{"accuracy": 0.5231493506493506, "f1": 0.5199299336182481, "f1_weighted": 0.5199299336182481, "hf_subset": "default", "languages": ["eng-Latn"], "main_score": 0.5231493506493506, "scores_per_experiment": [{"accuracy": 0.5243506493506493, "f1": 0.520854354565623, "f1_weighted": 0.520854354565623}, {"accuracy": 0.5100649350649351, "f1": 0.5102190591914748, "f1_weighted": 0.5102190591914749}, {"accuracy": 0.5396103896103897, "f1": 0.5343471297515026, "f1_weighted": 0.5343471297515026}, {"accuracy": 0.5409090909090909, "f1": 0.5387335638891192, "f1_weighted": 0.5387335638891193}, {"accuracy": 0.525974025974026, "f1": 0.5217547071509347, "f1_weighted": 0.5217547071509349}, {"accuracy": 0.5146103896103896, "f1": 0.5131828569539518, "f1_weighted": 0.5131828569539517}, {"accuracy": 0.525974025974026, "f1": 0.520981089578322, "f1_weighted": 0.520981089578322}, {"accuracy": 0.5172077922077922, "f1": 0.51460643070282, "f1_weighted": 0.5146064307028201}, {"accuracy": 0.5324675324675324, "f1": 0.5286742395806073, "f1_weighted": 0.5286742395806072}, {"accuracy": 0.5003246753246753, "f1": 0.4959459048181255, "f1_weighted": 0.4959459048181255}]}]}, "task_name": "Banking77Classification", "avg_layerwise_entropy": 0.22226358502586513, "num_samples": 64}