{"dataset_revision": "0fd18e25b25c072e09e0d92ab615fda904d66300", "evaluation_time": 115.69423127174377, "kg_co2_emissions": null, "mteb_version": "1.12.49", "scores": {"test": [{"accuracy": 0.5932142857142857, "f1": 0.5899493739300136, "f1_weighted": 0.5899493739300135, "hf_subset": "default", "languages": ["eng-Latn"], "main_score": 0.5932142857142857, "scores_per_experiment": [{"accuracy": 0.5844155844155844, "f1": 0.5787543895225441, "f1_weighted": 0.5787543895225441}, {"accuracy": 0.5808441558441558, "f1": 0.5829630967110926, "f1_weighted": 0.5829630967110925}, {"accuracy": 0.6168831168831169, "f1": 0.6113377403251257, "f1_weighted": 0.6113377403251257}, {"accuracy": 0.6126623376623377, "f1": 0.6110930716682799, "f1_weighted": 0.6110930716682798}, {"accuracy": 0.6048701298701299, "f1": 0.6020589799222852, "f1_weighted": 0.6020589799222852}, {"accuracy": 0.5866883116883117, "f1": 0.5839352395042746, "f1_weighted": 0.5839352395042747}, {"accuracy": 0.5798701298701299, "f1": 0.5743371419283952, "f1_weighted": 0.5743371419283952}, {"accuracy": 0.5915584415584415, "f1": 0.5879343874060122, "f1_weighted": 0.5879343874060123}, {"accuracy": 0.5964285714285714, "f1": 0.594129462328734, "f1_weighted": 0.5941294623287339}, {"accuracy": 0.577922077922078, "f1": 0.5729502299833914, "f1_weighted": 0.5729502299833913}]}]}, "task_name": "Banking77Classification", "avg_layerwise_entropy": 0.18037387319523962, "num_samples": 64}