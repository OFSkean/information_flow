{"dataset_revision": "0fd18e25b25c072e09e0d92ab615fda904d66300", "evaluation_time": 121.79599213600159, "kg_co2_emissions": null, "mteb_version": "1.12.49", "scores": {"test": [{"accuracy": 0.5271428571428571, "f1": 0.5237349652378411, "f1_weighted": 0.5237349652378412, "hf_subset": "default", "languages": ["eng-Latn"], "main_score": 0.5271428571428571, "scores_per_experiment": [{"accuracy": 0.5214285714285715, "f1": 0.5168427959041711, "f1_weighted": 0.5168427959041713}, {"accuracy": 0.5230519480519481, "f1": 0.5248490636871191, "f1_weighted": 0.524849063687119}, {"accuracy": 0.5405844155844156, "f1": 0.535828658131693, "f1_weighted": 0.535828658131693}, {"accuracy": 0.5451298701298701, "f1": 0.54321261679865, "f1_weighted": 0.5432126167986501}, {"accuracy": 0.5246753246753246, "f1": 0.5190312440467278, "f1_weighted": 0.519031244046728}, {"accuracy": 0.5214285714285715, "f1": 0.5193400771543536, "f1_weighted": 0.5193400771543537}, {"accuracy": 0.5246753246753246, "f1": 0.5199465688541516, "f1_weighted": 0.5199465688541517}, {"accuracy": 0.5295454545454545, "f1": 0.5263010548538674, "f1_weighted": 0.5263010548538675}, {"accuracy": 0.535064935064935, "f1": 0.5297343555563847, "f1_weighted": 0.5297343555563846}, {"accuracy": 0.5058441558441559, "f1": 0.5022632173912933, "f1_weighted": 0.5022632173912932}]}]}, "task_name": "Banking77Classification", "avg_layerwise_entropy": 0.21375836724317782, "num_samples": 64}