{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "evaluation_time": 142.29298424720764,
  "kg_co2_emissions": null,
  "mteb_version": "1.12.49",
  "scores": {
    "test": [
      {
        "cosine": {
          "accuracy": 0.8193956011205817,
          "accuracy_threshold": 0.8917682766914368,
          "ap": 0.5775840371798838,
          "f1": 0.543879472693032,
          "f1_threshold": 0.8662393093109131,
          "precision": 0.5188023952095808,
          "recall": 0.5715039577836412
        },
        "dot": {
          "accuracy": 0.7778506288370984,
          "accuracy_threshold": 845.6642456054688,
          "ap": 0.33617042803194175,
          "f1": 0.3800272243534216,
          "f1_threshold": 646.6900634765625,
          "precision": 0.24822179114128679,
          "recall": 0.8102902374670184
        },
        "euclidean": {
          "accuracy": 0.8118257137748107,
          "accuracy_threshold": 13.151795387268066,
          "ap": 0.5538504453610157,
          "f1": 0.535436778902755,
          "f1_threshold": 15.17629337310791,
          "precision": 0.48341836734693877,
          "recall": 0.6
        },
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5775840371798838,
        "manhattan": {
          "accuracy": 0.8122429516600107,
          "accuracy_threshold": 649.7582397460938,
          "ap": 0.5568787500414412,
          "f1": 0.5394371300881748,
          "f1_threshold": 749.1148681640625,
          "precision": 0.4974381822232123,
          "recall": 0.5891820580474934
        },
        "max": {
          "accuracy": 0.8193956011205817,
          "ap": 0.5775840371798838,
          "f1": 0.543879472693032
        },
        "similarity": {
          "accuracy": 0.8193956011205817,
          "accuracy_threshold": 0.8917682766914368,
          "ap": 0.5775840371798838,
          "f1": 0.543879472693032,
          "f1_threshold": 0.8662393093109131,
          "precision": 0.5188023952095808,
          "recall": 0.5715039577836412
        }
      }
    ]
  },
  "task_name": "TwitterSemEval2015"
}