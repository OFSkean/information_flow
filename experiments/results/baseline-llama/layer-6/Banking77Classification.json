{"dataset_revision": "0fd18e25b25c072e09e0d92ab615fda904d66300", "evaluation_time": 107.18014073371887, "kg_co2_emissions": null, "mteb_version": "1.12.49", "scores": {"test": [{"accuracy": 0.5661038961038961, "f1": 0.5620297283592672, "f1_weighted": 0.5620297283592672, "hf_subset": "default", "languages": ["eng-Latn"], "main_score": 0.5661038961038961, "scores_per_experiment": [{"accuracy": 0.5642857142857143, "f1": 0.5603993881011966, "f1_weighted": 0.5603993881011966}, {"accuracy": 0.55, "f1": 0.5521529347925512, "f1_weighted": 0.5521529347925513}, {"accuracy": 0.5798701298701299, "f1": 0.5751210685159351, "f1_weighted": 0.5751210685159353}, {"accuracy": 0.5909090909090909, "f1": 0.5905959534642417, "f1_weighted": 0.5905959534642418}, {"accuracy": 0.5714285714285714, "f1": 0.5653224097906099, "f1_weighted": 0.5653224097906098}, {"accuracy": 0.5681818181818182, "f1": 0.5631108428322937, "f1_weighted": 0.563110842832294}, {"accuracy": 0.5512987012987013, "f1": 0.5476508661705474, "f1_weighted": 0.5476508661705475}, {"accuracy": 0.561038961038961, "f1": 0.5572693365598952, "f1_weighted": 0.5572693365598952}, {"accuracy": 0.5808441558441558, "f1": 0.5756568022275096, "f1_weighted": 0.5756568022275094}, {"accuracy": 0.5431818181818182, "f1": 0.5330176811378917, "f1_weighted": 0.5330176811378918}]}]}, "task_name": "Banking77Classification", "avg_layerwise_entropy": 0.13082223190931752, "num_samples": 64}