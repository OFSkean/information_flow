{"dataset_revision": "0fd18e25b25c072e09e0d92ab615fda904d66300", "evaluation_time": 103.49521350860596, "kg_co2_emissions": null, "mteb_version": "1.12.49", "scores": {"test": [{"accuracy": 0.5091233766233766, "f1": 0.5059721771097122, "f1_weighted": 0.5059721771097122, "hf_subset": "default", "languages": ["eng-Latn"], "main_score": 0.5091233766233766, "scores_per_experiment": [{"accuracy": 0.48733766233766235, "f1": 0.48283253672410587, "f1_weighted": 0.4828325367241057}, {"accuracy": 0.4863636363636364, "f1": 0.49333102933404394, "f1_weighted": 0.49333102933404394}, {"accuracy": 0.5295454545454545, "f1": 0.5229671866563631, "f1_weighted": 0.5229671866563631}, {"accuracy": 0.548051948051948, "f1": 0.546564439030388, "f1_weighted": 0.546564439030388}, {"accuracy": 0.512987012987013, "f1": 0.50390176937035, "f1_weighted": 0.5039017693703501}, {"accuracy": 0.5230519480519481, "f1": 0.522117600445677, "f1_weighted": 0.522117600445677}, {"accuracy": 0.48928571428571427, "f1": 0.4879115615497708, "f1_weighted": 0.4879115615497707}, {"accuracy": 0.5029220779220779, "f1": 0.49893155979091025, "f1_weighted": 0.4989315597909103}, {"accuracy": 0.5175324675324675, "f1": 0.512981221350183, "f1_weighted": 0.512981221350183}, {"accuracy": 0.4941558441558442, "f1": 0.48818286684532947, "f1_weighted": 0.4881828668453295}]}]}, "task_name": "Banking77Classification", "avg_layerwise_entropy": 0.08618838787798037, "num_samples": 64}