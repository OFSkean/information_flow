{"dataset_revision": "0fd18e25b25c072e09e0d92ab615fda904d66300", "evaluation_time": 105.77543091773987, "kg_co2_emissions": null, "mteb_version": "1.12.49", "scores": {"test": [{"accuracy": 0.5464610389610389, "f1": 0.5428911394156571, "f1_weighted": 0.542891139415657, "hf_subset": "default", "languages": ["eng-Latn"], "main_score": 0.5464610389610389, "scores_per_experiment": [{"accuracy": 0.5308441558441559, "f1": 0.5274543609187359, "f1_weighted": 0.5274543609187358}, {"accuracy": 0.5360389610389611, "f1": 0.5397409543978361, "f1_weighted": 0.5397409543978362}, {"accuracy": 0.5665584415584416, "f1": 0.5602659738266366, "f1_weighted": 0.5602659738266368}, {"accuracy": 0.5737012987012987, "f1": 0.5729685079104151, "f1_weighted": 0.5729685079104151}, {"accuracy": 0.5451298701298701, "f1": 0.536600427830469, "f1_weighted": 0.5366004278304691}, {"accuracy": 0.550974025974026, "f1": 0.5472486709393152, "f1_weighted": 0.5472486709393152}, {"accuracy": 0.5331168831168831, "f1": 0.5310661481933046, "f1_weighted": 0.5310661481933046}, {"accuracy": 0.5360389610389611, "f1": 0.5339518179042223, "f1_weighted": 0.5339518179042224}, {"accuracy": 0.5584415584415584, "f1": 0.5540955668865131, "f1_weighted": 0.5540955668865132}, {"accuracy": 0.5337662337662338, "f1": 0.5255189653491228, "f1_weighted": 0.5255189653491227}]}]}, "task_name": "Banking77Classification", "avg_layerwise_entropy": 0.1064855355105591, "num_samples": 64}