{"dataset_revision": "0fd18e25b25c072e09e0d92ab615fda904d66300", "evaluation_time": 145.90107560157776, "kg_co2_emissions": null, "mteb_version": "1.12.49", "scores": {"test": [{"accuracy": 0.7369480519480518, "f1": 0.7362791435225369, "f1_weighted": 0.7362791435225369, "hf_subset": "default", "languages": ["eng-Latn"], "main_score": 0.7369480519480518, "scores_per_experiment": [{"accuracy": 0.7243506493506493, "f1": 0.7227685904502691, "f1_weighted": 0.7227685904502691}, {"accuracy": 0.7340909090909091, "f1": 0.7352554676277145, "f1_weighted": 0.7352554676277143}, {"accuracy": 0.7477272727272727, "f1": 0.7478359509112119, "f1_weighted": 0.7478359509112117}, {"accuracy": 0.7412337662337662, "f1": 0.7417865989657698, "f1_weighted": 0.7417865989657696}, {"accuracy": 0.7383116883116884, "f1": 0.7384725619513293, "f1_weighted": 0.7384725619513294}, {"accuracy": 0.7318181818181818, "f1": 0.7297784418892592, "f1_weighted": 0.7297784418892593}, {"accuracy": 0.7415584415584415, "f1": 0.73899991941168, "f1_weighted": 0.7389999194116799}, {"accuracy": 0.7337662337662337, "f1": 0.7322763793893535, "f1_weighted": 0.7322763793893539}, {"accuracy": 0.7392857142857143, "f1": 0.7390529376110122, "f1_weighted": 0.7390529376110123}, {"accuracy": 0.7373376623376623, "f1": 0.7365645870177698, "f1_weighted": 0.73656458701777}]}]}, "task_name": "Banking77Classification", "avg_layerwise_entropy": 0.6952689112087338, "num_samples": 64}