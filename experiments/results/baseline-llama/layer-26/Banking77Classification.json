{"dataset_revision": "0fd18e25b25c072e09e0d92ab615fda904d66300", "evaluation_time": 143.628271818161, "kg_co2_emissions": null, "mteb_version": "1.12.49", "scores": {"test": [{"accuracy": 0.7380519480519481, "f1": 0.7372876952977101, "f1_weighted": 0.7372876952977103, "hf_subset": "default", "languages": ["eng-Latn"], "main_score": 0.7380519480519481, "scores_per_experiment": [{"accuracy": 0.7262987012987013, "f1": 0.7245977611401716, "f1_weighted": 0.7245977611401716}, {"accuracy": 0.737012987012987, "f1": 0.7378762634623856, "f1_weighted": 0.7378762634623856}, {"accuracy": 0.7487012987012988, "f1": 0.7485740381933987, "f1_weighted": 0.7485740381933987}, {"accuracy": 0.7474025974025974, "f1": 0.7480512733510306, "f1_weighted": 0.7480512733510308}, {"accuracy": 0.7402597402597403, "f1": 0.740067715610064, "f1_weighted": 0.7400677156100641}, {"accuracy": 0.7308441558441559, "f1": 0.7279061416591553, "f1_weighted": 0.7279061416591553}, {"accuracy": 0.7457792207792208, "f1": 0.7443323020224414, "f1_weighted": 0.7443323020224415}, {"accuracy": 0.7314935064935065, "f1": 0.730109138907565, "f1_weighted": 0.7301091389075652}, {"accuracy": 0.736038961038961, "f1": 0.7355073308037712, "f1_weighted": 0.7355073308037715}, {"accuracy": 0.7366883116883117, "f1": 0.7358549878271188, "f1_weighted": 0.735854987827119}]}]}, "task_name": "Banking77Classification", "avg_layerwise_entropy": 0.7432858498657748, "num_samples": 64}