{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "evaluation_time": 40.41071176528931,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.21",
  "scores": {
    "test": [
      {
        "accuracy": 0.38760000000000006,
        "f1": 0.3482919835157965,
        "f1_weighted": 0.4139214371025168,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.38760000000000006,
        "scores_per_experiment": [
          {
            "accuracy": 0.411,
            "f1": 0.36765015163607845,
            "f1_weighted": 0.43999180055850035
          },
          {
            "accuracy": 0.37,
            "f1": 0.3466764074906126,
            "f1_weighted": 0.3915969595518648
          },
          {
            "accuracy": 0.385,
            "f1": 0.3528390067729641,
            "f1_weighted": 0.40939483519850783
          },
          {
            "accuracy": 0.3925,
            "f1": 0.35308242288023517,
            "f1_weighted": 0.421136650381133
          },
          {
            "accuracy": 0.3995,
            "f1": 0.3472672357646849,
            "f1_weighted": 0.4217653239256884
          },
          {
            "accuracy": 0.396,
            "f1": 0.35716321743512824,
            "f1_weighted": 0.42384507173997377
          },
          {
            "accuracy": 0.352,
            "f1": 0.3187894899140253,
            "f1_weighted": 0.3787909202812994
          },
          {
            "accuracy": 0.4045,
            "f1": 0.3647192691950086,
            "f1_weighted": 0.42745939765133295
          },
          {
            "accuracy": 0.3925,
            "f1": 0.34240604555226456,
            "f1_weighted": 0.42457765782574136
          },
          {
            "accuracy": 0.373,
            "f1": 0.33232658851696345,
            "f1_weighted": 0.40065575391112646
          }
        ]
      }
    ]
  },
  "task_name": "EmotionClassification"
}