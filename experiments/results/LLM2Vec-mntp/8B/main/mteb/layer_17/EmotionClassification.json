{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "evaluation_time": 77.25097250938416,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.21",
  "scores": {
    "test": [
      {
        "accuracy": 0.4021,
        "f1": 0.35913914292478044,
        "f1_weighted": 0.42878395079337067,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.4021,
        "scores_per_experiment": [
          {
            "accuracy": 0.428,
            "f1": 0.37519091941804855,
            "f1_weighted": 0.4634138581631783
          },
          {
            "accuracy": 0.3985,
            "f1": 0.3482097108567999,
            "f1_weighted": 0.4230787932203498
          },
          {
            "accuracy": 0.395,
            "f1": 0.3522442547137988,
            "f1_weighted": 0.4208534684556572
          },
          {
            "accuracy": 0.3815,
            "f1": 0.3487059819551395,
            "f1_weighted": 0.4110924671957681
          },
          {
            "accuracy": 0.3985,
            "f1": 0.35954923898716334,
            "f1_weighted": 0.42670645914305994
          },
          {
            "accuracy": 0.393,
            "f1": 0.350084262233928,
            "f1_weighted": 0.42140304103745163
          },
          {
            "accuracy": 0.4125,
            "f1": 0.360935788621283,
            "f1_weighted": 0.43577472649523485
          },
          {
            "accuracy": 0.4105,
            "f1": 0.36576615470660806,
            "f1_weighted": 0.4343152653102707
          },
          {
            "accuracy": 0.432,
            "f1": 0.3896529446008607,
            "f1_weighted": 0.4527187769438823
          },
          {
            "accuracy": 0.3715,
            "f1": 0.3410521731541751,
            "f1_weighted": 0.39848265196885363
          }
        ]
      }
    ]
  },
  "task_name": "EmotionClassification"
}