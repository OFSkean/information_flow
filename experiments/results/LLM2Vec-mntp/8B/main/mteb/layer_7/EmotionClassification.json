{
  "dataset_revision": "4f58c6b202a23cf9a4da393831edf4f9183cad37",
  "evaluation_time": 43.28455853462219,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.21",
  "scores": {
    "test": [
      {
        "accuracy": 0.3907,
        "f1": 0.35606094700458774,
        "f1_weighted": 0.41338891634836694,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.3907,
        "scores_per_experiment": [
          {
            "accuracy": 0.3605,
            "f1": 0.33495425461938955,
            "f1_weighted": 0.37944797217748993
          },
          {
            "accuracy": 0.374,
            "f1": 0.3485480964462186,
            "f1_weighted": 0.3900268771259424
          },
          {
            "accuracy": 0.3935,
            "f1": 0.3543129212263496,
            "f1_weighted": 0.4211966630112361
          },
          {
            "accuracy": 0.399,
            "f1": 0.3581710238746076,
            "f1_weighted": 0.4224878297082687
          },
          {
            "accuracy": 0.3815,
            "f1": 0.34846396620543674,
            "f1_weighted": 0.4012259966535589
          },
          {
            "accuracy": 0.419,
            "f1": 0.382404300245993,
            "f1_weighted": 0.4405073604418882
          },
          {
            "accuracy": 0.4095,
            "f1": 0.37297049997053905,
            "f1_weighted": 0.45003707283304456
          },
          {
            "accuracy": 0.3985,
            "f1": 0.3699720843300432,
            "f1_weighted": 0.41385650226727455
          },
          {
            "accuracy": 0.382,
            "f1": 0.3403930298698717,
            "f1_weighted": 0.40205006168755475
          },
          {
            "accuracy": 0.3895,
            "f1": 0.35041929325742865,
            "f1_weighted": 0.4130528275774117
          }
        ]
      }
    ]
  },
  "task_name": "EmotionClassification"
}