{
  "dataset_revision": "faeb762787bd10488a50c8b5be4a3b82e411949c",
  "evaluation_time": 14.977177858352661,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.021564888577389002,
        "cosine_spearman": 0.029809568139231107,
        "euclidean_pearson": 0.02134604468014769,
        "euclidean_spearman": 0.013242076787945332,
        "hf_subset": "it-en",
        "languages": [
          "ita-Latn",
          "eng-Latn"
        ],
        "main_score": 0.029809568139231107,
        "manhattan_pearson": -0.06382519885559457,
        "manhattan_spearman": -0.07198863289546976,
        "pearson": 0.021564888577389002,
        "spearman": 0.029809568139231107
      },
      {
        "cosine_pearson": 0.47450860386733806,
        "cosine_spearman": 0.5417600423594535,
        "euclidean_pearson": 0.5507571050928654,
        "euclidean_spearman": 0.5794547369508639,
        "hf_subset": "en-en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5417600423594535,
        "manhattan_pearson": 0.5611590615394784,
        "manhattan_spearman": 0.5923585447738642,
        "pearson": 0.47450860386733806,
        "spearman": 0.5417600423594535
      },
      {
        "cosine_pearson": 0.050505383472777846,
        "cosine_spearman": 0.06618193859494718,
        "euclidean_pearson": -0.03750698231798871,
        "euclidean_spearman": -0.0242907868554629,
        "hf_subset": "en-de",
        "languages": [
          "eng-Latn",
          "deu-Latn"
        ],
        "main_score": 0.06618193859494718,
        "manhattan_pearson": -0.08604664366408202,
        "manhattan_spearman": -0.08398026770277164,
        "pearson": 0.050505383472777846,
        "spearman": 0.06618193859494718
      },
      {
        "cosine_pearson": -0.049494995784388096,
        "cosine_spearman": -0.05659909718908938,
        "euclidean_pearson": -0.06200998860910922,
        "euclidean_spearman": -0.09471433810118929,
        "hf_subset": "es-en",
        "languages": [
          "spa-Latn",
          "eng-Latn"
        ],
        "main_score": -0.05659909718908938,
        "manhattan_pearson": -0.0876979631211686,
        "manhattan_spearman": -0.1506925782389,
        "pearson": -0.049494995784388096,
        "spearman": -0.05659909718908938
      },
      {
        "cosine_pearson": 0.029616712502106658,
        "cosine_spearman": 0.06002659662260057,
        "euclidean_pearson": 0.016577243994547016,
        "euclidean_spearman": 0.05190391310185764,
        "hf_subset": "fr-en",
        "languages": [
          "fra-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06002659662260057,
        "manhattan_pearson": -0.07425306526345221,
        "manhattan_spearman": -0.05035556379413192,
        "pearson": 0.029616712502106658,
        "spearman": 0.06002659662260057
      },
      {
        "cosine_pearson": 0.09657046223732084,
        "cosine_spearman": 0.08969047846897467,
        "euclidean_pearson": 0.07129452417785992,
        "euclidean_spearman": 0.07813128978163093,
        "hf_subset": "nl-en",
        "languages": [
          "nld-Latn",
          "eng-Latn"
        ],
        "main_score": 0.08969047846897467,
        "manhattan_pearson": -0.028630890393863365,
        "manhattan_spearman": -0.005221258353237001,
        "pearson": 0.09657046223732084,
        "spearman": 0.08969047846897467
      },
      {
        "cosine_pearson": 0.04382278276213605,
        "cosine_spearman": 0.05866311882572333,
        "euclidean_pearson": -0.11208754038758346,
        "euclidean_spearman": -0.09717028040338425,
        "hf_subset": "en-ar",
        "languages": [
          "eng-Latn",
          "ara-Arab"
        ],
        "main_score": 0.05866311882572333,
        "manhattan_pearson": -0.161249644439985,
        "manhattan_spearman": -0.15840733438183047,
        "pearson": 0.04382278276213605,
        "spearman": 0.05866311882572333
      },
      {
        "cosine_pearson": -0.01678079524974015,
        "cosine_spearman": 0.0020288525376290696,
        "euclidean_pearson": -0.15941501523773927,
        "euclidean_spearman": -0.14316424727673369,
        "hf_subset": "en-tr",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ],
        "main_score": 0.0020288525376290696,
        "manhattan_pearson": -0.22675007946157472,
        "manhattan_spearman": -0.21774658898926927,
        "pearson": -0.01678079524974015,
        "spearman": 0.0020288525376290696
      }
    ]
  },
  "task_name": "STS17"
}