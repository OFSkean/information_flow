{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 30.852774381637573,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.29098,
        "f1": 0.28628186053880766,
        "f1_weighted": 0.28628186053880766,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.29098,
        "scores_per_experiment": [
          {
            "accuracy": 0.3264,
            "f1": 0.32545942976888,
            "f1_weighted": 0.32545942976888004
          },
          {
            "accuracy": 0.2962,
            "f1": 0.29326011384133066,
            "f1_weighted": 0.29326011384133066
          },
          {
            "accuracy": 0.2964,
            "f1": 0.29438086439062205,
            "f1_weighted": 0.29438086439062205
          },
          {
            "accuracy": 0.2902,
            "f1": 0.2880381047118446,
            "f1_weighted": 0.2880381047118445
          },
          {
            "accuracy": 0.335,
            "f1": 0.32406518427081443,
            "f1_weighted": 0.3240651842708145
          },
          {
            "accuracy": 0.2376,
            "f1": 0.23487032525153637,
            "f1_weighted": 0.23487032525153637
          },
          {
            "accuracy": 0.2416,
            "f1": 0.23661143732760131,
            "f1_weighted": 0.2366114373276013
          },
          {
            "accuracy": 0.2992,
            "f1": 0.2892366016883504,
            "f1_weighted": 0.28923660168835047
          },
          {
            "accuracy": 0.2844,
            "f1": 0.2815537254503787,
            "f1_weighted": 0.2815537254503787
          },
          {
            "accuracy": 0.3028,
            "f1": 0.295342818686718,
            "f1_weighted": 0.2953428186867181
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.28886,
        "f1": 0.28378102142485095,
        "f1_weighted": 0.28378102142485095,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.28886,
        "scores_per_experiment": [
          {
            "accuracy": 0.319,
            "f1": 0.31883657712780705,
            "f1_weighted": 0.31883657712780705
          },
          {
            "accuracy": 0.3002,
            "f1": 0.29924891618727134,
            "f1_weighted": 0.29924891618727134
          },
          {
            "accuracy": 0.2944,
            "f1": 0.2926250875078872,
            "f1_weighted": 0.2926250875078872
          },
          {
            "accuracy": 0.2806,
            "f1": 0.2775918106974956,
            "f1_weighted": 0.27759181069749556
          },
          {
            "accuracy": 0.3306,
            "f1": 0.31794673421303477,
            "f1_weighted": 0.31794673421303477
          },
          {
            "accuracy": 0.2414,
            "f1": 0.23866893843463366,
            "f1_weighted": 0.23866893843463363
          },
          {
            "accuracy": 0.2498,
            "f1": 0.24248190396003028,
            "f1_weighted": 0.24248190396003033
          },
          {
            "accuracy": 0.2932,
            "f1": 0.2839670312499135,
            "f1_weighted": 0.28396703124991346
          },
          {
            "accuracy": 0.2712,
            "f1": 0.2673631032836773,
            "f1_weighted": 0.2673631032836773
          },
          {
            "accuracy": 0.3082,
            "f1": 0.2990801115867593,
            "f1_weighted": 0.2990801115867593
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}