{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 30.865583658218384,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.7871637026903786,
        "f1": 0.7808667033653516,
        "f1_weighted": 0.7899747918369737,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7871637026903786,
        "scores_per_experiment": [
          {
            "accuracy": 0.764249886000912,
            "f1": 0.7566301421353644,
            "f1_weighted": 0.7653800011094186
          },
          {
            "accuracy": 0.7843137254901961,
            "f1": 0.7845433625973737,
            "f1_weighted": 0.7889152715759928
          },
          {
            "accuracy": 0.792749658002736,
            "f1": 0.7808895479464991,
            "f1_weighted": 0.7915028076121947
          },
          {
            "accuracy": 0.803921568627451,
            "f1": 0.793548085369699,
            "f1_weighted": 0.8079035002607149
          },
          {
            "accuracy": 0.8255813953488372,
            "f1": 0.8169092717541949,
            "f1_weighted": 0.8296544334704145
          },
          {
            "accuracy": 0.7831737346101231,
            "f1": 0.7790977256668825,
            "f1_weighted": 0.7865018709212243
          },
          {
            "accuracy": 0.7808937528499772,
            "f1": 0.7780915781007899,
            "f1_weighted": 0.7820864948639357
          },
          {
            "accuracy": 0.7423620611035112,
            "f1": 0.7376931210011776,
            "f1_weighted": 0.7474966500341288
          },
          {
            "accuracy": 0.7948016415868673,
            "f1": 0.7963593175693128,
            "f1_weighted": 0.7993787355325424
          },
          {
            "accuracy": 0.7995896032831737,
            "f1": 0.7849048815122213,
            "f1_weighted": 0.8009281529891702
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7804921700223714,
        "f1": 0.7781523830523983,
        "f1_weighted": 0.7829980223098173,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7804921700223714,
        "scores_per_experiment": [
          {
            "accuracy": 0.7548098434004474,
            "f1": 0.7495382948809767,
            "f1_weighted": 0.7540771748485987
          },
          {
            "accuracy": 0.7834451901565995,
            "f1": 0.7859755399831122,
            "f1_weighted": 0.7879786215188035
          },
          {
            "accuracy": 0.7888143176733781,
            "f1": 0.7817414706609618,
            "f1_weighted": 0.7882236046234881
          },
          {
            "accuracy": 0.7910514541387025,
            "f1": 0.7890693533727628,
            "f1_weighted": 0.7951786249495911
          },
          {
            "accuracy": 0.8228187919463087,
            "f1": 0.8162750071568812,
            "f1_weighted": 0.8260090956899362
          },
          {
            "accuracy": 0.7829977628635347,
            "f1": 0.7843977047205989,
            "f1_weighted": 0.7880994305250065
          },
          {
            "accuracy": 0.7642058165548098,
            "f1": 0.7615191396095409,
            "f1_weighted": 0.7651231866118485
          },
          {
            "accuracy": 0.7342281879194631,
            "f1": 0.737886864740269,
            "f1_weighted": 0.738464751574481
          },
          {
            "accuracy": 0.7941834451901566,
            "f1": 0.7971490455255588,
            "f1_weighted": 0.7972371691323966
          },
          {
            "accuracy": 0.7883668903803132,
            "f1": 0.7779714098733213,
            "f1_weighted": 0.7895885636240226
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}