{
  "dataset_revision": "edfaf9da55d3dd50d43143d90c1ac476895ae6de",
  "evaluation_time": 110.67584085464478,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.549462890625,
        "ap": 0.09115996203772164,
        "ap_weighted": 0.09115996203772164,
        "f1": 0.4275790595385132,
        "f1_weighted": 0.6443011782782192,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.549462890625,
        "scores_per_experiment": [
          {
            "accuracy": 0.4873046875,
            "ap": 0.0892376775536181,
            "ap_weighted": 0.0892376775536181,
            "f1": 0.3976814770248423,
            "f1_weighted": 0.5932642806440472
          },
          {
            "accuracy": 0.5166015625,
            "ap": 0.09214288226159348,
            "ap_weighted": 0.09214288226159348,
            "f1": 0.41543074616537884,
            "f1_weighted": 0.6201472806265137
          },
          {
            "accuracy": 0.48779296875,
            "ap": 0.09104515040864927,
            "ap_weighted": 0.09104515040864927,
            "f1": 0.39957949503071344,
            "f1_weighted": 0.5933120156575288
          },
          {
            "accuracy": 0.73681640625,
            "ap": 0.08771812387642078,
            "ap_weighted": 0.08771812387642078,
            "f1": 0.5015602881712953,
            "f1_weighted": 0.7898200945449179
          },
          {
            "accuracy": 0.56005859375,
            "ap": 0.09532948822705443,
            "ap_weighted": 0.09532948822705443,
            "f1": 0.43976490897934634,
            "f1_weighted": 0.6582963236733473
          },
          {
            "accuracy": 0.4716796875,
            "ap": 0.09209946351873435,
            "ap_weighted": 0.09209946351873435,
            "f1": 0.39185122978039044,
            "f1_weighted": 0.5773286706275694
          },
          {
            "accuracy": 0.71240234375,
            "ap": 0.09912126325899348,
            "ap_weighted": 0.09912126325899348,
            "f1": 0.5096086494309531,
            "f1_weighted": 0.7750728324271846
          },
          {
            "accuracy": 0.4951171875,
            "ap": 0.08622256540908091,
            "ap_weighted": 0.08622256540908091,
            "f1": 0.39872523498653,
            "f1_weighted": 0.6013834375880206
          },
          {
            "accuracy": 0.48095703125,
            "ap": 0.08529188752715036,
            "ap_weighted": 0.08529188752715036,
            "f1": 0.3904937673985234,
            "f1_weighted": 0.588160011859798
          },
          {
            "accuracy": 0.5458984375,
            "ap": 0.09339111833592133,
            "ap_weighted": 0.09339111833592133,
            "f1": 0.4310947984171589,
            "f1_weighted": 0.6462268351332654
          }
        ]
      }
    ]
  },
  "task_name": "ToxicConversationsClassification"
}