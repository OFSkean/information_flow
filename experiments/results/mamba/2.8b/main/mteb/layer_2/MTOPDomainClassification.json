{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 37.83873248100281,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.7998404012767898,
        "f1": 0.7930365192375367,
        "f1_weighted": 0.8022576879446458,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7998404012767898,
        "scores_per_experiment": [
          {
            "accuracy": 0.781577747378021,
            "f1": 0.7741765760182516,
            "f1_weighted": 0.7813268531824594
          },
          {
            "accuracy": 0.7982216142270862,
            "f1": 0.7966096963671085,
            "f1_weighted": 0.8020418992875838
          },
          {
            "accuracy": 0.7936616507067944,
            "f1": 0.7811568913449303,
            "f1_weighted": 0.7941641185822947
          },
          {
            "accuracy": 0.8075695394436845,
            "f1": 0.79660391888433,
            "f1_weighted": 0.8118811188356692
          },
          {
            "accuracy": 0.8365253077975376,
            "f1": 0.827869501841885,
            "f1_weighted": 0.8392310309130209
          },
          {
            "accuracy": 0.8014135886912904,
            "f1": 0.7975978899625169,
            "f1_weighted": 0.8040256587012664
          },
          {
            "accuracy": 0.7991336069311445,
            "f1": 0.7963941746362934,
            "f1_weighted": 0.7995548537056296
          },
          {
            "accuracy": 0.7558139534883721,
            "f1": 0.7506465181392311,
            "f1_weighted": 0.7618738238052919
          },
          {
            "accuracy": 0.820109439124487,
            "f1": 0.8184917345484357,
            "f1_weighted": 0.8232558966324793
          },
          {
            "accuracy": 0.8043775649794802,
            "f1": 0.7908182906323851,
            "f1_weighted": 0.8052216258007618
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7942729306487696,
        "f1": 0.7907672485510846,
        "f1_weighted": 0.7962535551031953,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7942729306487696,
        "scores_per_experiment": [
          {
            "accuracy": 0.7695749440715883,
            "f1": 0.7647776027615163,
            "f1_weighted": 0.7685518378313619
          },
          {
            "accuracy": 0.796420581655481,
            "f1": 0.7977993772160997,
            "f1_weighted": 0.8005412658225596
          },
          {
            "accuracy": 0.785234899328859,
            "f1": 0.7772914520577262,
            "f1_weighted": 0.7856959764682239
          },
          {
            "accuracy": 0.8085011185682327,
            "f1": 0.8040548439926635,
            "f1_weighted": 0.8123188023657263
          },
          {
            "accuracy": 0.8313199105145413,
            "f1": 0.8266092343431722,
            "f1_weighted": 0.8338088693367661
          },
          {
            "accuracy": 0.7991051454138702,
            "f1": 0.7993727317612295,
            "f1_weighted": 0.8025124948014115
          },
          {
            "accuracy": 0.7888143176733781,
            "f1": 0.7854575305979435,
            "f1_weighted": 0.7884453288379828
          },
          {
            "accuracy": 0.7521252796420582,
            "f1": 0.7508985429869225,
            "f1_weighted": 0.7559508937557824
          },
          {
            "accuracy": 0.8192393736017897,
            "f1": 0.818645888618125,
            "f1_weighted": 0.821042721300295
          },
          {
            "accuracy": 0.7923937360178971,
            "f1": 0.782765281175448,
            "f1_weighted": 0.793667360511843
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}