{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 188.02188324928284,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.30774,
        "f1": 0.3035534864578413,
        "f1_weighted": 0.3035534864578413,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.30774,
        "scores_per_experiment": [
          {
            "accuracy": 0.3416,
            "f1": 0.3379185779961086,
            "f1_weighted": 0.33791857799610864
          },
          {
            "accuracy": 0.3176,
            "f1": 0.3199272509777624,
            "f1_weighted": 0.3199272509777624
          },
          {
            "accuracy": 0.2822,
            "f1": 0.28580943867240255,
            "f1_weighted": 0.28580943867240255
          },
          {
            "accuracy": 0.3074,
            "f1": 0.3027750849962497,
            "f1_weighted": 0.30277508499624967
          },
          {
            "accuracy": 0.3548,
            "f1": 0.34162540100438277,
            "f1_weighted": 0.34162540100438277
          },
          {
            "accuracy": 0.2786,
            "f1": 0.27611951306046045,
            "f1_weighted": 0.2761195130604605
          },
          {
            "accuracy": 0.2682,
            "f1": 0.2627119371691403,
            "f1_weighted": 0.2627119371691403
          },
          {
            "accuracy": 0.322,
            "f1": 0.3127407170380865,
            "f1_weighted": 0.3127407170380865
          },
          {
            "accuracy": 0.2836,
            "f1": 0.2785253435740544,
            "f1_weighted": 0.2785253435740544
          },
          {
            "accuracy": 0.3214,
            "f1": 0.3173816000897654,
            "f1_weighted": 0.3173816000897654
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.30074,
        "f1": 0.2956683238262915,
        "f1_weighted": 0.2956683238262915,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.30074,
        "scores_per_experiment": [
          {
            "accuracy": 0.3158,
            "f1": 0.3124710086075394,
            "f1_weighted": 0.3124710086075394
          },
          {
            "accuracy": 0.3106,
            "f1": 0.3143588569254692,
            "f1_weighted": 0.3143588569254692
          },
          {
            "accuracy": 0.289,
            "f1": 0.29350609392097204,
            "f1_weighted": 0.2935060939209721
          },
          {
            "accuracy": 0.2908,
            "f1": 0.2859315295222903,
            "f1_weighted": 0.28593152952229023
          },
          {
            "accuracy": 0.349,
            "f1": 0.33021364498641964,
            "f1_weighted": 0.33021364498641964
          },
          {
            "accuracy": 0.28,
            "f1": 0.2749786116587579,
            "f1_weighted": 0.2749786116587579
          },
          {
            "accuracy": 0.2676,
            "f1": 0.2587040634875547,
            "f1_weighted": 0.25870406348755476
          },
          {
            "accuracy": 0.2928,
            "f1": 0.28411788479353717,
            "f1_weighted": 0.2841178847935372
          },
          {
            "accuracy": 0.2888,
            "f1": 0.2837482381657504,
            "f1_weighted": 0.2837482381657504
          },
          {
            "accuracy": 0.323,
            "f1": 0.318653306194624,
            "f1_weighted": 0.318653306194624
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}