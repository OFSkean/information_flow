{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 26.90694832801819,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.7938212494300045,
        "f1": 0.7879079193112019,
        "f1_weighted": 0.7962026082604917,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7938212494300045,
        "scores_per_experiment": [
          {
            "accuracy": 0.7528499772001824,
            "f1": 0.747542999520487,
            "f1_weighted": 0.7530658783295044
          },
          {
            "accuracy": 0.7879616963064295,
            "f1": 0.7924189973758531,
            "f1_weighted": 0.7919388484969404
          },
          {
            "accuracy": 0.7929776561787506,
            "f1": 0.7828681054492265,
            "f1_weighted": 0.7950770314893819
          },
          {
            "accuracy": 0.8093935248518012,
            "f1": 0.8033747875989964,
            "f1_weighted": 0.8113425787401862
          },
          {
            "accuracy": 0.7979936160510716,
            "f1": 0.7943541698684153,
            "f1_weighted": 0.8023538263690464
          },
          {
            "accuracy": 0.8064295485636115,
            "f1": 0.8031111816757978,
            "f1_weighted": 0.8097748660234036
          },
          {
            "accuracy": 0.7948016415868673,
            "f1": 0.783273020948424,
            "f1_weighted": 0.7934130274732998
          },
          {
            "accuracy": 0.7797537619699042,
            "f1": 0.7740973308818354,
            "f1_weighted": 0.7842190690162493
          },
          {
            "accuracy": 0.8125854993160054,
            "f1": 0.8111039852513634,
            "f1_weighted": 0.8162677949755711
          },
          {
            "accuracy": 0.8034655722754218,
            "f1": 0.7869346145416197,
            "f1_weighted": 0.8045731616913337
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7869798657718121,
        "f1": 0.7848728859869453,
        "f1_weighted": 0.7885708422479516,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7869798657718121,
        "scores_per_experiment": [
          {
            "accuracy": 0.745413870246085,
            "f1": 0.7454418084508287,
            "f1_weighted": 0.743205665231575
          },
          {
            "accuracy": 0.7834451901565995,
            "f1": 0.7882591189289472,
            "f1_weighted": 0.7855212284568162
          },
          {
            "accuracy": 0.7950782997762863,
            "f1": 0.7894516661999272,
            "f1_weighted": 0.7967753742264395
          },
          {
            "accuracy": 0.8044742729306488,
            "f1": 0.8030365064693549,
            "f1_weighted": 0.806069146150457
          },
          {
            "accuracy": 0.7901565995525727,
            "f1": 0.7901380157007409,
            "f1_weighted": 0.793195018076028
          },
          {
            "accuracy": 0.8004474272930648,
            "f1": 0.7996005153404174,
            "f1_weighted": 0.8035746853028863
          },
          {
            "accuracy": 0.7861297539149888,
            "f1": 0.7762670925388876,
            "f1_weighted": 0.7838830855928914
          },
          {
            "accuracy": 0.7651006711409396,
            "f1": 0.7668589024889855,
            "f1_weighted": 0.7684037169719904
          },
          {
            "accuracy": 0.8053691275167785,
            "f1": 0.8040497726746167,
            "f1_weighted": 0.8086426928994814
          },
          {
            "accuracy": 0.7941834451901566,
            "f1": 0.7856254610767461,
            "f1_weighted": 0.796437809570952
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}