{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 143.8968141078949,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.29938,
        "f1": 0.29638449753207036,
        "f1_weighted": 0.2963844975320703,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.29938,
        "scores_per_experiment": [
          {
            "accuracy": 0.3312,
            "f1": 0.331639176378242,
            "f1_weighted": 0.331639176378242
          },
          {
            "accuracy": 0.3082,
            "f1": 0.3102709598122792,
            "f1_weighted": 0.31027095981227915
          },
          {
            "accuracy": 0.2754,
            "f1": 0.27995061123845566,
            "f1_weighted": 0.27995061123845566
          },
          {
            "accuracy": 0.3036,
            "f1": 0.2983727585176262,
            "f1_weighted": 0.2983727585176262
          },
          {
            "accuracy": 0.3488,
            "f1": 0.3367002104849292,
            "f1_weighted": 0.33670021048492926
          },
          {
            "accuracy": 0.2638,
            "f1": 0.2644463338323329,
            "f1_weighted": 0.26444633383233296
          },
          {
            "accuracy": 0.2508,
            "f1": 0.246294614214475,
            "f1_weighted": 0.24629461421447504
          },
          {
            "accuracy": 0.3098,
            "f1": 0.3032302299808329,
            "f1_weighted": 0.3032302299808329
          },
          {
            "accuracy": 0.2912,
            "f1": 0.28585967703246995,
            "f1_weighted": 0.2858596770324699
          },
          {
            "accuracy": 0.311,
            "f1": 0.3070804038290603,
            "f1_weighted": 0.3070804038290604
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.29506000000000004,
        "f1": 0.2909996693740945,
        "f1_weighted": 0.2909996693740945,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.29506000000000004,
        "scores_per_experiment": [
          {
            "accuracy": 0.3094,
            "f1": 0.31011373045430474,
            "f1_weighted": 0.31011373045430474
          },
          {
            "accuracy": 0.3048,
            "f1": 0.3082573110309371,
            "f1_weighted": 0.3082573110309371
          },
          {
            "accuracy": 0.2734,
            "f1": 0.27753875665520283,
            "f1_weighted": 0.27753875665520283
          },
          {
            "accuracy": 0.2848,
            "f1": 0.2786002581185799,
            "f1_weighted": 0.27860025811857997
          },
          {
            "accuracy": 0.3426,
            "f1": 0.3256986749180749,
            "f1_weighted": 0.32569867491807497
          },
          {
            "accuracy": 0.2718,
            "f1": 0.2712406971151059,
            "f1_weighted": 0.2712406971151059
          },
          {
            "accuracy": 0.2536,
            "f1": 0.24568990777225616,
            "f1_weighted": 0.24568990777225616
          },
          {
            "accuracy": 0.2944,
            "f1": 0.28679150483413707,
            "f1_weighted": 0.28679150483413707
          },
          {
            "accuracy": 0.294,
            "f1": 0.2896161129655286,
            "f1_weighted": 0.2896161129655286
          },
          {
            "accuracy": 0.3218,
            "f1": 0.3164497398768177,
            "f1_weighted": 0.3164497398768177
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}