{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 24.138489961624146,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.7904240766073871,
        "f1": 0.784815563564196,
        "f1_weighted": 0.79280667138499,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7904240766073871,
        "scores_per_experiment": [
          {
            "accuracy": 0.7439580483356133,
            "f1": 0.739307478813528,
            "f1_weighted": 0.7443593420729266
          },
          {
            "accuracy": 0.7738258093935249,
            "f1": 0.7773197670240262,
            "f1_weighted": 0.7780006381128276
          },
          {
            "accuracy": 0.7893296853625171,
            "f1": 0.776982640469924,
            "f1_weighted": 0.7919830784944211
          },
          {
            "accuracy": 0.8084815321477428,
            "f1": 0.8051047219465491,
            "f1_weighted": 0.8114083288936407
          },
          {
            "accuracy": 0.7941176470588235,
            "f1": 0.7914660304451865,
            "f1_weighted": 0.798634424534587
          },
          {
            "accuracy": 0.7979936160510716,
            "f1": 0.7945849217525128,
            "f1_weighted": 0.8006655861782385
          },
          {
            "accuracy": 0.7886456908344733,
            "f1": 0.777493739957534,
            "f1_weighted": 0.7871824009944804
          },
          {
            "accuracy": 0.7758777929776561,
            "f1": 0.772430938707311,
            "f1_weighted": 0.7805694792566048
          },
          {
            "accuracy": 0.81281349749202,
            "f1": 0.8092663238498186,
            "f1_weighted": 0.8159876457816233
          },
          {
            "accuracy": 0.8191974464204287,
            "f1": 0.8041990726755691,
            "f1_weighted": 0.8192757895305494
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7846979865771812,
        "f1": 0.7835505045471052,
        "f1_weighted": 0.7864557505968236,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7846979865771812,
        "scores_per_experiment": [
          {
            "accuracy": 0.7413870246085011,
            "f1": 0.7412218852881526,
            "f1_weighted": 0.7393487982824583
          },
          {
            "accuracy": 0.7718120805369127,
            "f1": 0.7784359456723831,
            "f1_weighted": 0.7740999557219993
          },
          {
            "accuracy": 0.7919463087248322,
            "f1": 0.7849005633880654,
            "f1_weighted": 0.7940773172603586
          },
          {
            "accuracy": 0.8076062639821029,
            "f1": 0.807922328890682,
            "f1_weighted": 0.8106088157476915
          },
          {
            "accuracy": 0.778076062639821,
            "f1": 0.7803732152881652,
            "f1_weighted": 0.7819116093866244
          },
          {
            "accuracy": 0.7932885906040269,
            "f1": 0.7934579178760395,
            "f1_weighted": 0.7958325102064165
          },
          {
            "accuracy": 0.7758389261744967,
            "f1": 0.7655074977885711,
            "f1_weighted": 0.7732889090155826
          },
          {
            "accuracy": 0.7736017897091723,
            "f1": 0.7770062688034993,
            "f1_weighted": 0.7768830708962692
          },
          {
            "accuracy": 0.8022371364653244,
            "f1": 0.8027705096031199,
            "f1_weighted": 0.80628069656428
          },
          {
            "accuracy": 0.8111856823266219,
            "f1": 0.8039089128723752,
            "f1_weighted": 0.8122258228865556
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}