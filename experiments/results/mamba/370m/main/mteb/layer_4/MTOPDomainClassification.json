{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 29.63452911376953,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.7995896032831737,
        "f1": 0.7933632725123333,
        "f1_weighted": 0.8019293069821425,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7995896032831737,
        "scores_per_experiment": [
          {
            "accuracy": 0.7615139078887369,
            "f1": 0.7566660514021205,
            "f1_weighted": 0.7622238484903919
          },
          {
            "accuracy": 0.791609667122663,
            "f1": 0.7934410390829985,
            "f1_weighted": 0.7955478099352613
          },
          {
            "accuracy": 0.791609667122663,
            "f1": 0.7814177303192715,
            "f1_weighted": 0.794601102789819
          },
          {
            "accuracy": 0.8169174646602827,
            "f1": 0.8099016261100115,
            "f1_weighted": 0.818907769142869
          },
          {
            "accuracy": 0.8011855905152758,
            "f1": 0.7975553692484115,
            "f1_weighted": 0.8050133744327347
          },
          {
            "accuracy": 0.8182854537163703,
            "f1": 0.8124060071345572,
            "f1_weighted": 0.8212434331923102
          },
          {
            "accuracy": 0.7995896032831737,
            "f1": 0.7893892864075526,
            "f1_weighted": 0.799022085550782
          },
          {
            "accuracy": 0.7847697218422253,
            "f1": 0.7795541829428434,
            "f1_weighted": 0.7893180052878463
          },
          {
            "accuracy": 0.8205654354765162,
            "f1": 0.8188745585239048,
            "f1_weighted": 0.8234495913279448
          },
          {
            "accuracy": 0.8098495212038304,
            "f1": 0.794426873951662,
            "f1_weighted": 0.8099660496714639
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7942281879194631,
        "f1": 0.7917928721596651,
        "f1_weighted": 0.7955940114267703,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7942281879194631,
        "scores_per_experiment": [
          {
            "accuracy": 0.7498881431767338,
            "f1": 0.747622836851281,
            "f1_weighted": 0.7473137773582131
          },
          {
            "accuracy": 0.7937360178970917,
            "f1": 0.7988300325473557,
            "f1_weighted": 0.7959511085159897
          },
          {
            "accuracy": 0.7937360178970917,
            "f1": 0.7881098076687167,
            "f1_weighted": 0.7958532809350449
          },
          {
            "accuracy": 0.8174496644295302,
            "f1": 0.8152545187365554,
            "f1_weighted": 0.8193413691589244
          },
          {
            "accuracy": 0.7959731543624161,
            "f1": 0.7955809141272319,
            "f1_weighted": 0.798607751404357
          },
          {
            "accuracy": 0.8147651006711409,
            "f1": 0.8122154946358591,
            "f1_weighted": 0.8159513480268452
          },
          {
            "accuracy": 0.7879194630872484,
            "f1": 0.7774016005256205,
            "f1_weighted": 0.7855536969155559
          },
          {
            "accuracy": 0.7767337807606264,
            "f1": 0.7791290370160482,
            "f1_weighted": 0.7808956002438385
          },
          {
            "accuracy": 0.8085011185682327,
            "f1": 0.8065137434882304,
            "f1_weighted": 0.8112327492840755
          },
          {
            "accuracy": 0.8035794183445191,
            "f1": 0.797270735999753,
            "f1_weighted": 0.8052394324248601
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}