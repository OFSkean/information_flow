{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 481.4575688838959,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.30152,
        "f1": 0.3000791736091616,
        "f1_weighted": 0.30007917360916164,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.30152,
        "scores_per_experiment": [
          {
            "accuracy": 0.3404,
            "f1": 0.3344046961192185,
            "f1_weighted": 0.3344046961192186
          },
          {
            "accuracy": 0.3258,
            "f1": 0.3284657147704652,
            "f1_weighted": 0.32846571477046527
          },
          {
            "accuracy": 0.2742,
            "f1": 0.2741852186280199,
            "f1_weighted": 0.2741852186280199
          },
          {
            "accuracy": 0.2858,
            "f1": 0.28383222170691236,
            "f1_weighted": 0.28383222170691236
          },
          {
            "accuracy": 0.3282,
            "f1": 0.32314783791157675,
            "f1_weighted": 0.3231478379115768
          },
          {
            "accuracy": 0.2828,
            "f1": 0.2842940337655828,
            "f1_weighted": 0.2842940337655828
          },
          {
            "accuracy": 0.2476,
            "f1": 0.2465156038390754,
            "f1_weighted": 0.24651560383907536
          },
          {
            "accuracy": 0.3172,
            "f1": 0.31544461021015546,
            "f1_weighted": 0.3154446102101555
          },
          {
            "accuracy": 0.3026,
            "f1": 0.2962939306421707,
            "f1_weighted": 0.29629393064217074
          },
          {
            "accuracy": 0.3106,
            "f1": 0.31420786849843907,
            "f1_weighted": 0.31420786849843907
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.2951,
        "f1": 0.2918993271217105,
        "f1_weighted": 0.2918993271217105,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.2951,
        "scores_per_experiment": [
          {
            "accuracy": 0.3328,
            "f1": 0.3268386177041151,
            "f1_weighted": 0.32683861770411515
          },
          {
            "accuracy": 0.3188,
            "f1": 0.32398509000472975,
            "f1_weighted": 0.32398509000472975
          },
          {
            "accuracy": 0.2686,
            "f1": 0.2656668595868802,
            "f1_weighted": 0.26566685958688024
          },
          {
            "accuracy": 0.2664,
            "f1": 0.25819729945719233,
            "f1_weighted": 0.25819729945719233
          },
          {
            "accuracy": 0.3242,
            "f1": 0.3185242788699787,
            "f1_weighted": 0.31852427886997864
          },
          {
            "accuracy": 0.2914,
            "f1": 0.293811107931268,
            "f1_weighted": 0.293811107931268
          },
          {
            "accuracy": 0.2372,
            "f1": 0.2328478106728556,
            "f1_weighted": 0.23284781067285557
          },
          {
            "accuracy": 0.2946,
            "f1": 0.29293727250522716,
            "f1_weighted": 0.2929372725052271
          },
          {
            "accuracy": 0.3028,
            "f1": 0.2901789298617993,
            "f1_weighted": 0.2901789298617993
          },
          {
            "accuracy": 0.3142,
            "f1": 0.3160060046230592,
            "f1_weighted": 0.3160060046230592
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}