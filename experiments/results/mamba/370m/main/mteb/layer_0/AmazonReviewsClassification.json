{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 28.95310926437378,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.28914,
        "f1": 0.28603473337228263,
        "f1_weighted": 0.2860347333722827,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.28914,
        "scores_per_experiment": [
          {
            "accuracy": 0.3298,
            "f1": 0.3266730512104678,
            "f1_weighted": 0.32667305121046786
          },
          {
            "accuracy": 0.3024,
            "f1": 0.30388028802625555,
            "f1_weighted": 0.30388028802625555
          },
          {
            "accuracy": 0.2758,
            "f1": 0.2722534113286675,
            "f1_weighted": 0.2722534113286675
          },
          {
            "accuracy": 0.2904,
            "f1": 0.29120439957219374,
            "f1_weighted": 0.29120439957219374
          },
          {
            "accuracy": 0.3262,
            "f1": 0.3187092382356845,
            "f1_weighted": 0.3187092382356845
          },
          {
            "accuracy": 0.253,
            "f1": 0.2489597921976007,
            "f1_weighted": 0.24895979219760075
          },
          {
            "accuracy": 0.2356,
            "f1": 0.2340363387127483,
            "f1_weighted": 0.2340363387127483
          },
          {
            "accuracy": 0.2978,
            "f1": 0.2891287915160782,
            "f1_weighted": 0.2891287915160782
          },
          {
            "accuracy": 0.2866,
            "f1": 0.2833052981699603,
            "f1_weighted": 0.28330529816996025
          },
          {
            "accuracy": 0.2938,
            "f1": 0.29219672475317016,
            "f1_weighted": 0.29219672475317016
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.28864,
        "f1": 0.28524382408985227,
        "f1_weighted": 0.28524382408985227,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.28864,
        "scores_per_experiment": [
          {
            "accuracy": 0.3222,
            "f1": 0.31990563358838886,
            "f1_weighted": 0.31990563358838886
          },
          {
            "accuracy": 0.3036,
            "f1": 0.30781105537738285,
            "f1_weighted": 0.30781105537738285
          },
          {
            "accuracy": 0.2742,
            "f1": 0.271301460648108,
            "f1_weighted": 0.271301460648108
          },
          {
            "accuracy": 0.2846,
            "f1": 0.2842871201819781,
            "f1_weighted": 0.2842871201819781
          },
          {
            "accuracy": 0.3156,
            "f1": 0.30695401422610236,
            "f1_weighted": 0.30695401422610236
          },
          {
            "accuracy": 0.2534,
            "f1": 0.24902973071364606,
            "f1_weighted": 0.2490297307136461
          },
          {
            "accuracy": 0.256,
            "f1": 0.2523194930179265,
            "f1_weighted": 0.25231949301792644
          },
          {
            "accuracy": 0.2936,
            "f1": 0.284052706897559,
            "f1_weighted": 0.284052706897559
          },
          {
            "accuracy": 0.2778,
            "f1": 0.2749407454455192,
            "f1_weighted": 0.2749407454455192
          },
          {
            "accuracy": 0.3054,
            "f1": 0.3018362808019116,
            "f1_weighted": 0.30183628080191155
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}