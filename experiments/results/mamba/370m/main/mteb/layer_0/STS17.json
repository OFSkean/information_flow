{
  "dataset_revision": "faeb762787bd10488a50c8b5be4a3b82e411949c",
  "evaluation_time": 14.162612915039062,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "cosine_pearson": -0.0027642302778058004,
        "cosine_spearman": -0.0017509262901416872,
        "euclidean_pearson": 0.09050061103170909,
        "euclidean_spearman": 0.06963689479599953,
        "hf_subset": "nl-en",
        "languages": [
          "nld-Latn",
          "eng-Latn"
        ],
        "main_score": -0.0017509262901416872,
        "manhattan_pearson": 0.012169551798119703,
        "manhattan_spearman": 0.018389915399927213,
        "pearson": -0.0027642302778058004,
        "spearman": -0.0017509262901416872
      },
      {
        "cosine_pearson": 0.06621415705552414,
        "cosine_spearman": 0.06874778557336557,
        "euclidean_pearson": 0.08992844788204128,
        "euclidean_spearman": 0.08807947252342388,
        "hf_subset": "en-de",
        "languages": [
          "eng-Latn",
          "deu-Latn"
        ],
        "main_score": 0.06874778557336557,
        "manhattan_pearson": -0.03280587054048517,
        "manhattan_spearman": -0.02937865960547725,
        "pearson": 0.06621415705552414,
        "spearman": 0.06874778557336557
      },
      {
        "cosine_pearson": 0.27095946585207714,
        "cosine_spearman": 0.457842815691058,
        "euclidean_pearson": 0.5070211569124432,
        "euclidean_spearman": 0.5324799408234271,
        "hf_subset": "en-en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.457842815691058,
        "manhattan_pearson": 0.5621431989564039,
        "manhattan_spearman": 0.5854855344406625,
        "pearson": 0.27095946585207714,
        "spearman": 0.457842815691058
      },
      {
        "cosine_pearson": -0.0822664036946048,
        "cosine_spearman": -0.07652418757482106,
        "euclidean_pearson": -0.04126932886517006,
        "euclidean_spearman": -0.04498234277511987,
        "hf_subset": "es-en",
        "languages": [
          "spa-Latn",
          "eng-Latn"
        ],
        "main_score": -0.07652418757482106,
        "manhattan_pearson": -0.086700255579241,
        "manhattan_spearman": -0.12477612119946142,
        "pearson": -0.0822664036946048,
        "spearman": -0.07652418757482106
      },
      {
        "cosine_pearson": -0.08018440012885257,
        "cosine_spearman": -0.04564632164692538,
        "euclidean_pearson": 0.03751693188682391,
        "euclidean_spearman": 0.043993416477307534,
        "hf_subset": "it-en",
        "languages": [
          "ita-Latn",
          "eng-Latn"
        ],
        "main_score": -0.04564632164692538,
        "manhattan_pearson": -0.04498307811554271,
        "manhattan_spearman": -0.04479103932078591,
        "pearson": -0.08018440012885257,
        "spearman": -0.04564632164692538
      },
      {
        "cosine_pearson": 0.05495967256105585,
        "cosine_spearman": 0.0836400898523884,
        "euclidean_pearson": 0.002139716923377999,
        "euclidean_spearman": 0.006896637638808081,
        "hf_subset": "en-tr",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ],
        "main_score": 0.0836400898523884,
        "manhattan_pearson": -0.16480386958406038,
        "manhattan_spearman": -0.13855290421508445,
        "pearson": 0.05495967256105585,
        "spearman": 0.0836400898523884
      },
      {
        "cosine_pearson": 0.14510570815356932,
        "cosine_spearman": 0.12635307743510737,
        "euclidean_pearson": 0.0035170497714438163,
        "euclidean_spearman": 0.005597617039120523,
        "hf_subset": "en-ar",
        "languages": [
          "eng-Latn",
          "ara-Arab"
        ],
        "main_score": 0.12635307743510737,
        "manhattan_pearson": -0.09127964904010014,
        "manhattan_spearman": -0.08052619166716124,
        "pearson": 0.14510570815356932,
        "spearman": 0.12635307743510737
      },
      {
        "cosine_pearson": -0.06919497137669244,
        "cosine_spearman": -0.06614388333639087,
        "euclidean_pearson": 0.024274122615933848,
        "euclidean_spearman": 0.0440249369944956,
        "hf_subset": "fr-en",
        "languages": [
          "fra-Latn",
          "eng-Latn"
        ],
        "main_score": -0.06614388333639087,
        "manhattan_pearson": -0.06885286887089043,
        "manhattan_spearman": -0.04837054000438622,
        "pearson": -0.06919497137669244,
        "spearman": -0.06614388333639087
      }
    ]
  },
  "task_name": "STS17"
}