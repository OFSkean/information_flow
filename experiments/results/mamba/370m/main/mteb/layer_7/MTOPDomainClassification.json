{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 38.24247145652771,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.8028043775649794,
        "f1": 0.7970324111179737,
        "f1_weighted": 0.8046335703576103,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8028043775649794,
        "scores_per_experiment": [
          {
            "accuracy": 0.7660738714090287,
            "f1": 0.7620886854317802,
            "f1_weighted": 0.7668785097916969
          },
          {
            "accuracy": 0.7902416780665754,
            "f1": 0.7942493818120027,
            "f1_weighted": 0.7950337921332691
          },
          {
            "accuracy": 0.7852257181942545,
            "f1": 0.7769195609315862,
            "f1_weighted": 0.7878052790930636
          },
          {
            "accuracy": 0.8226174190606476,
            "f1": 0.8160238936214288,
            "f1_weighted": 0.823692906045778
          },
          {
            "accuracy": 0.8132694938440492,
            "f1": 0.8078779025223777,
            "f1_weighted": 0.8155249390681371
          },
          {
            "accuracy": 0.82124943000456,
            "f1": 0.814727392024963,
            "f1_weighted": 0.8233904836055732
          },
          {
            "accuracy": 0.8018695850433196,
            "f1": 0.7941116645658309,
            "f1_weighted": 0.8005031491688934
          },
          {
            "accuracy": 0.7893296853625171,
            "f1": 0.7841507855114421,
            "f1_weighted": 0.7933371358799753
          },
          {
            "accuracy": 0.8292293661650707,
            "f1": 0.8239231191226453,
            "f1_weighted": 0.8313004656268322
          },
          {
            "accuracy": 0.808937528499772,
            "f1": 0.7962517256356794,
            "f1_weighted": 0.8088690431628847
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.8017002237136465,
        "f1": 0.798387800750276,
        "f1_weighted": 0.8026974427144806,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8017002237136465,
        "scores_per_experiment": [
          {
            "accuracy": 0.7570469798657719,
            "f1": 0.7548848095256965,
            "f1_weighted": 0.7568899305719293
          },
          {
            "accuracy": 0.7968680089485458,
            "f1": 0.8028678676297965,
            "f1_weighted": 0.7996452063751387
          },
          {
            "accuracy": 0.7906040268456376,
            "f1": 0.784744773631949,
            "f1_weighted": 0.792735756314031
          },
          {
            "accuracy": 0.8268456375838926,
            "f1": 0.8217603064683693,
            "f1_weighted": 0.8268714532462673
          },
          {
            "accuracy": 0.8138702460850112,
            "f1": 0.8128938369612375,
            "f1_weighted": 0.8153662918393111
          },
          {
            "accuracy": 0.8192393736017897,
            "f1": 0.8158247358614432,
            "f1_weighted": 0.8201924627318085
          },
          {
            "accuracy": 0.7959731543624161,
            "f1": 0.7878509825707318,
            "f1_weighted": 0.7947894334261038
          },
          {
            "accuracy": 0.789261744966443,
            "f1": 0.7881497841898124,
            "f1_weighted": 0.7921064517726799
          },
          {
            "accuracy": 0.8228187919463087,
            "f1": 0.8163734414400838,
            "f1_weighted": 0.8238756330679163
          },
          {
            "accuracy": 0.8044742729306488,
            "f1": 0.7985274692236399,
            "f1_weighted": 0.8045018077996198
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}