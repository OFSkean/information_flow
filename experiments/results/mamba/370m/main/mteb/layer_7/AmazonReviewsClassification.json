{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 374.5364167690277,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.30122,
        "f1": 0.30040683351851594,
        "f1_weighted": 0.3004068335185159,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.30122,
        "scores_per_experiment": [
          {
            "accuracy": 0.3456,
            "f1": 0.3421312562951944,
            "f1_weighted": 0.3421312562951945
          },
          {
            "accuracy": 0.319,
            "f1": 0.3249241053669627,
            "f1_weighted": 0.3249241053669627
          },
          {
            "accuracy": 0.273,
            "f1": 0.27527399958729715,
            "f1_weighted": 0.27527399958729715
          },
          {
            "accuracy": 0.282,
            "f1": 0.28298881396506304,
            "f1_weighted": 0.282988813965063
          },
          {
            "accuracy": 0.338,
            "f1": 0.329438398110347,
            "f1_weighted": 0.329438398110347
          },
          {
            "accuracy": 0.285,
            "f1": 0.2847610881120909,
            "f1_weighted": 0.2847610881120909
          },
          {
            "accuracy": 0.2456,
            "f1": 0.24427379722369463,
            "f1_weighted": 0.2442737972236946
          },
          {
            "accuracy": 0.3186,
            "f1": 0.31542865549980226,
            "f1_weighted": 0.31542865549980226
          },
          {
            "accuracy": 0.2982,
            "f1": 0.29455157178485863,
            "f1_weighted": 0.2945515717848586
          },
          {
            "accuracy": 0.3072,
            "f1": 0.3102966492398488,
            "f1_weighted": 0.31029664923984873
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.2947,
        "f1": 0.2919850822753462,
        "f1_weighted": 0.2919850822753462,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.2947,
        "scores_per_experiment": [
          {
            "accuracy": 0.335,
            "f1": 0.33143326798539063,
            "f1_weighted": 0.33143326798539063
          },
          {
            "accuracy": 0.3098,
            "f1": 0.3156445704737765,
            "f1_weighted": 0.3156445704737765
          },
          {
            "accuracy": 0.262,
            "f1": 0.2606995723370177,
            "f1_weighted": 0.2606995723370177
          },
          {
            "accuracy": 0.2612,
            "f1": 0.2579076032812423,
            "f1_weighted": 0.2579076032812423
          },
          {
            "accuracy": 0.3422,
            "f1": 0.3279471033768667,
            "f1_weighted": 0.32794710337686667
          },
          {
            "accuracy": 0.2836,
            "f1": 0.2829537458389747,
            "f1_weighted": 0.2829537458389747
          },
          {
            "accuracy": 0.242,
            "f1": 0.2375735710012956,
            "f1_weighted": 0.23757357100129567
          },
          {
            "accuracy": 0.2984,
            "f1": 0.2986256876692584,
            "f1_weighted": 0.2986256876692584
          },
          {
            "accuracy": 0.3034,
            "f1": 0.2952582020800999,
            "f1_weighted": 0.29525820208009984
          },
          {
            "accuracy": 0.3094,
            "f1": 0.3118074987095398,
            "f1_weighted": 0.3118074987095398
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}