{
  "dataset_revision": "4672e20407010da34463acc759c162ca9734bca6",
  "evaluation_time": 63.191263914108276,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.5672494956287829,
        "f1": 0.5443298902172027,
        "f1_weighted": 0.5722096495624057,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5672494956287829,
        "scores_per_experiment": [
          {
            "accuracy": 0.5793544048419637,
            "f1": 0.5682203387824727,
            "f1_weighted": 0.5844002740469377
          },
          {
            "accuracy": 0.5780094149293881,
            "f1": 0.5500278450938787,
            "f1_weighted": 0.5823186475446633
          },
          {
            "accuracy": 0.5672494956287828,
            "f1": 0.5300197182043399,
            "f1_weighted": 0.5659825731863203
          },
          {
            "accuracy": 0.5884330867518494,
            "f1": 0.5518601348958032,
            "f1_weighted": 0.5946922594395193
          },
          {
            "accuracy": 0.5719569603227975,
            "f1": 0.5401264213085945,
            "f1_weighted": 0.5743180854939228
          },
          {
            "accuracy": 0.5322797579018157,
            "f1": 0.5154669624435838,
            "f1_weighted": 0.5408718359295597
          },
          {
            "accuracy": 0.5477471418964358,
            "f1": 0.5422451411578777,
            "f1_weighted": 0.5503640344495146
          },
          {
            "accuracy": 0.5648957632817754,
            "f1": 0.5420274885693875,
            "f1_weighted": 0.5729564773981513
          },
          {
            "accuracy": 0.5679219905850706,
            "f1": 0.5481982896535016,
            "f1_weighted": 0.5731409929414415
          },
          {
            "accuracy": 0.5746469401479489,
            "f1": 0.5551065620625859,
            "f1_weighted": 0.5830513151940255
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.5788489916379735,
        "f1": 0.5594647391798974,
        "f1_weighted": 0.5823654072814384,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5788489916379735,
        "scores_per_experiment": [
          {
            "accuracy": 0.573044761436301,
            "f1": 0.5612315586795424,
            "f1_weighted": 0.5744849310372386
          },
          {
            "accuracy": 0.5966551893753075,
            "f1": 0.5628362233309334,
            "f1_weighted": 0.6002068402437696
          },
          {
            "accuracy": 0.5937038858829317,
            "f1": 0.5635771663878953,
            "f1_weighted": 0.5946062112627668
          },
          {
            "accuracy": 0.5986227250368913,
            "f1": 0.5747836814517059,
            "f1_weighted": 0.6000976504738088
          },
          {
            "accuracy": 0.5823905558288244,
            "f1": 0.5628185379672745,
            "f1_weighted": 0.583248137601501
          },
          {
            "accuracy": 0.5602557796360059,
            "f1": 0.5563733141637499,
            "f1_weighted": 0.5647432861185702
          },
          {
            "accuracy": 0.5400885391047713,
            "f1": 0.5303040553069481,
            "f1_weighted": 0.545389281963506
          },
          {
            "accuracy": 0.5705853418593212,
            "f1": 0.5445223250783161,
            "f1_weighted": 0.5772443579837917
          },
          {
            "accuracy": 0.5784554845056566,
            "f1": 0.5670981089535647,
            "f1_weighted": 0.5841490539418137
          },
          {
            "accuracy": 0.5946876537137236,
            "f1": 0.5711024204790429,
            "f1_weighted": 0.5994843221876177
          }
        ]
      }
    ]
  },
  "task_name": "MassiveIntentClassification"
}