{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 530.6741321086884,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.30296,
        "f1": 0.30133855183997993,
        "f1_weighted": 0.30133855183997993,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.30296,
        "scores_per_experiment": [
          {
            "accuracy": 0.3362,
            "f1": 0.3307607756211215,
            "f1_weighted": 0.3307607756211215
          },
          {
            "accuracy": 0.325,
            "f1": 0.32837629582086664,
            "f1_weighted": 0.3283762958208666
          },
          {
            "accuracy": 0.274,
            "f1": 0.2741061810502471,
            "f1_weighted": 0.27410618105024703
          },
          {
            "accuracy": 0.2894,
            "f1": 0.2910117247688454,
            "f1_weighted": 0.2910117247688454
          },
          {
            "accuracy": 0.3312,
            "f1": 0.3239774345169014,
            "f1_weighted": 0.3239774345169014
          },
          {
            "accuracy": 0.2782,
            "f1": 0.27656685012316007,
            "f1_weighted": 0.2765668501231601
          },
          {
            "accuracy": 0.2538,
            "f1": 0.25271866249391944,
            "f1_weighted": 0.25271866249391944
          },
          {
            "accuracy": 0.316,
            "f1": 0.31463874788416846,
            "f1_weighted": 0.31463874788416846
          },
          {
            "accuracy": 0.3114,
            "f1": 0.3037535913869889,
            "f1_weighted": 0.30375359138698893
          },
          {
            "accuracy": 0.3144,
            "f1": 0.31747525473358035,
            "f1_weighted": 0.3174752547335804
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.30001999999999995,
        "f1": 0.296981718157263,
        "f1_weighted": 0.296981718157263,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.30001999999999995,
        "scores_per_experiment": [
          {
            "accuracy": 0.333,
            "f1": 0.328407183075589,
            "f1_weighted": 0.328407183075589
          },
          {
            "accuracy": 0.3184,
            "f1": 0.32319322532243877,
            "f1_weighted": 0.3231932253224388
          },
          {
            "accuracy": 0.2792,
            "f1": 0.2784092063764471,
            "f1_weighted": 0.2784092063764471
          },
          {
            "accuracy": 0.2736,
            "f1": 0.26951858012188445,
            "f1_weighted": 0.2695185801218845
          },
          {
            "accuracy": 0.3306,
            "f1": 0.3216715577310483,
            "f1_weighted": 0.3216715577310482
          },
          {
            "accuracy": 0.292,
            "f1": 0.2918020958479385,
            "f1_weighted": 0.2918020958479385
          },
          {
            "accuracy": 0.2416,
            "f1": 0.23737815024626366,
            "f1_weighted": 0.2373781502462637
          },
          {
            "accuracy": 0.301,
            "f1": 0.2999447173100215,
            "f1_weighted": 0.2999447173100214
          },
          {
            "accuracy": 0.3154,
            "f1": 0.3016948537825905,
            "f1_weighted": 0.30169485378259053
          },
          {
            "accuracy": 0.3154,
            "f1": 0.31779761175840787,
            "f1_weighted": 0.31779761175840787
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}