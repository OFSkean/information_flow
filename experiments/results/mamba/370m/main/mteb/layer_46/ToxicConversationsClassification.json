{
  "dataset_revision": "edfaf9da55d3dd50d43143d90c1ac476895ae6de",
  "evaluation_time": 109.01007723808289,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.63779296875,
        "ap": 0.10375308060922799,
        "ap_weighted": 0.10375308060922799,
        "f1": 0.481900932289731,
        "f1_weighted": 0.7177047141016695,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.63779296875,
        "scores_per_experiment": [
          {
            "accuracy": 0.654296875,
            "ap": 0.11301927538435441,
            "ap_weighted": 0.11301927538435441,
            "f1": 0.49909075332054675,
            "f1_weighted": 0.7338059759305269
          },
          {
            "accuracy": 0.61474609375,
            "ap": 0.10409505208333333,
            "ap_weighted": 0.10409505208333333,
            "f1": 0.4734142762310812,
            "f1_weighted": 0.7030618289196918
          },
          {
            "accuracy": 0.73974609375,
            "ap": 0.11776358813179644,
            "ap_weighted": 0.11776358813179644,
            "f1": 0.5402894837361755,
            "f1_weighted": 0.7951917785203365
          },
          {
            "accuracy": 0.72705078125,
            "ap": 0.10792634805054223,
            "ap_weighted": 0.10792634805054223,
            "f1": 0.5253754126626864,
            "f1_weighted": 0.7858161133701985
          },
          {
            "accuracy": 0.53369140625,
            "ap": 0.093070719870572,
            "ap_weighted": 0.093070719870572,
            "f1": 0.4248244997754691,
            "f1_weighted": 0.6354715780718678
          },
          {
            "accuracy": 0.4609375,
            "ap": 0.08585358880312513,
            "ap_weighted": 0.08585358880312513,
            "f1": 0.3804924294317827,
            "f1_weighted": 0.5684156024122795
          },
          {
            "accuracy": 0.6416015625,
            "ap": 0.09925141844466787,
            "ap_weighted": 0.09925141844466787,
            "f1": 0.48069578098486065,
            "f1_weighted": 0.7240304891709135
          },
          {
            "accuracy": 0.65380859375,
            "ap": 0.10224964394647644,
            "ap_weighted": 0.10224964394647644,
            "f1": 0.4890332842436047,
            "f1_weighted": 0.7332917826004623
          },
          {
            "accuracy": 0.62744140625,
            "ap": 0.09765465179961708,
            "ap_weighted": 0.09765465179961708,
            "f1": 0.4728741478527187,
            "f1_weighted": 0.7131572438643625
          },
          {
            "accuracy": 0.724609375,
            "ap": 0.11664651957779498,
            "ap_weighted": 0.11664651957779498,
            "f1": 0.5329192546583851,
            "f1_weighted": 0.7848047481560559
          }
        ]
      }
    ]
  },
  "task_name": "ToxicConversationsClassification"
}