{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 73.11361861228943,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.5856821589205397,
        "ap": 0.14330200299625306,
        "ap_weighted": 0.14330200299625306,
        "f1": 0.48500019782412174,
        "f1_weighted": 0.6647017137825488,
        "hf_subset": "en-ext",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5856821589205397,
        "scores_per_experiment": [
          {
            "accuracy": 0.5877061469265368,
            "ap": 0.12486390263775242,
            "ap_weighted": 0.12486390263775242,
            "f1": 0.47222661813578104,
            "f1_weighted": 0.6676535130124447
          },
          {
            "accuracy": 0.5847076461769115,
            "ap": 0.13467009014083126,
            "ap_weighted": 0.13467009014083126,
            "f1": 0.479389330184931,
            "f1_weighted": 0.6647495663308166
          },
          {
            "accuracy": 0.6004497751124438,
            "ap": 0.1581279486334189,
            "ap_weighted": 0.1581279486334189,
            "f1": 0.5036963357728941,
            "f1_weighted": 0.677162603926654
          },
          {
            "accuracy": 0.5704647676161919,
            "ap": 0.13163942130825712,
            "ap_weighted": 0.13163942130825712,
            "f1": 0.4699135572592138,
            "f1_weighted": 0.6526710067204339
          },
          {
            "accuracy": 0.616191904047976,
            "ap": 0.1534715072631634,
            "ap_weighted": 0.1534715072631634,
            "f1": 0.5086909608827634,
            "f1_weighted": 0.6906156339315848
          },
          {
            "accuracy": 0.6004497751124438,
            "ap": 0.1581279486334189,
            "ap_weighted": 0.1581279486334189,
            "f1": 0.5036963357728941,
            "f1_weighted": 0.677162603926654
          },
          {
            "accuracy": 0.5652173913043478,
            "ap": 0.12852623336781407,
            "ap_weighted": 0.12852623336781407,
            "f1": 0.46472847623475233,
            "f1_weighted": 0.6483206809293764
          },
          {
            "accuracy": 0.6611694152923538,
            "ap": 0.18506063083296312,
            "ap_weighted": 0.18506063083296312,
            "f1": 0.5504640232846645,
            "f1_weighted": 0.7270575186927006
          },
          {
            "accuracy": 0.5854572713643178,
            "ap": 0.14640548987100432,
            "ap_weighted": 0.14640548987100432,
            "f1": 0.48841570185749605,
            "f1_weighted": 0.6647941827511343
          },
          {
            "accuracy": 0.48500749625187406,
            "ap": 0.11212685727390717,
            "ap_weighted": 0.11212685727390717,
            "f1": 0.40878063885582683,
            "f1_weighted": 0.5768298276036888
          }
        ]
      },
      {
        "accuracy": 0.6205970149253732,
        "ap": 0.2554577639126613,
        "ap_weighted": 0.2554577639126613,
        "f1": 0.5599899720329768,
        "f1_weighted": 0.6591678598541502,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.6205970149253732,
        "scores_per_experiment": [
          {
            "accuracy": 0.5701492537313433,
            "ap": 0.23162990474891093,
            "ap_weighted": 0.23162990474891093,
            "f1": 0.5182022471910113,
            "f1_weighted": 0.614540332047627
          },
          {
            "accuracy": 0.5746268656716418,
            "ap": 0.23312043993002424,
            "ap_weighted": 0.23312043993002424,
            "f1": 0.5216335856061688,
            "f1_weighted": 0.6185899007035365
          },
          {
            "accuracy": 0.6164179104477612,
            "ap": 0.250128274133413,
            "ap_weighted": 0.250128274133413,
            "f1": 0.5549484490784417,
            "f1_weighted": 0.6556694942137122
          },
          {
            "accuracy": 0.6253731343283582,
            "ap": 0.26219758041076746,
            "ap_weighted": 0.26219758041076746,
            "f1": 0.567547412407586,
            "f1_weighted": 0.6638449411572801
          },
          {
            "accuracy": 0.6582089552238806,
            "ap": 0.2726402139563332,
            "ap_weighted": 0.2726402139563332,
            "f1": 0.5901659049445603,
            "f1_weighted": 0.691856617449918
          },
          {
            "accuracy": 0.6388059701492538,
            "ap": 0.24809906770438409,
            "ap_weighted": 0.24809906770438409,
            "f1": 0.5636893998105571,
            "f1_weighted": 0.6739324239047594
          },
          {
            "accuracy": 0.6238805970149254,
            "ap": 0.2516020227940759,
            "ap_weighted": 0.2516020227940759,
            "f1": 0.5595830594422011,
            "f1_weighted": 0.6620572599487303
          },
          {
            "accuracy": 0.6388059701492538,
            "ap": 0.2684036626829692,
            "ap_weighted": 0.2684036626829692,
            "f1": 0.5781822344322345,
            "f1_weighted": 0.6755620933792577
          },
          {
            "accuracy": 0.6402985074626866,
            "ap": 0.28701083273867706,
            "ap_weighted": 0.28701083273867706,
            "f1": 0.5898393344764082,
            "f1_weighted": 0.6774450475759894
          },
          {
            "accuracy": 0.6194029850746269,
            "ap": 0.24974564002705738,
            "ap_weighted": 0.24974564002705738,
            "f1": 0.5561080929405988,
            "f1_weighted": 0.6581804881606915
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}