{
  "dataset_revision": "edfaf9da55d3dd50d43143d90c1ac476895ae6de",
  "evaluation_time": 113.58315944671631,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.59814453125,
        "ap": 0.0961830313844331,
        "ap_weighted": 0.0961830313844331,
        "f1": 0.45644756018595534,
        "f1_weighted": 0.6864163471568981,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.59814453125,
        "scores_per_experiment": [
          {
            "accuracy": 0.64111328125,
            "ap": 0.10403249833022252,
            "ap_weighted": 0.10403249833022252,
            "f1": 0.48522916720100545,
            "f1_weighted": 0.7236889831907719
          },
          {
            "accuracy": 0.5625,
            "ap": 0.0949961834594451,
            "ap_weighted": 0.0949961834594451,
            "f1": 0.4406091023933901,
            "f1_weighted": 0.6604207210898291
          },
          {
            "accuracy": 0.72900390625,
            "ap": 0.10353562907355679,
            "ap_weighted": 0.10353562907355679,
            "f1": 0.521314565616468,
            "f1_weighted": 0.7867381558701444
          },
          {
            "accuracy": 0.68994140625,
            "ap": 0.09821437279851078,
            "ap_weighted": 0.09821437279851078,
            "f1": 0.4996489216604755,
            "f1_weighted": 0.7593989164604281
          },
          {
            "accuracy": 0.494140625,
            "ap": 0.088872220289631,
            "ap_weighted": 0.088872220289631,
            "f1": 0.4008855154965212,
            "f1_weighted": 0.5998605263678052
          },
          {
            "accuracy": 0.4482421875,
            "ap": 0.08560414971821353,
            "ap_weighted": 0.08560414971821353,
            "f1": 0.3733509520611745,
            "f1_weighted": 0.5557132259263371
          },
          {
            "accuracy": 0.57470703125,
            "ap": 0.08893039768746233,
            "ap_weighted": 0.08893039768746233,
            "f1": 0.43980788115614233,
            "f1_weighted": 0.6712169704713766
          },
          {
            "accuracy": 0.6240234375,
            "ap": 0.11014069497397723,
            "ap_weighted": 0.11014069497397723,
            "f1": 0.4828628807465327,
            "f1_weighted": 0.7103028805997827
          },
          {
            "accuracy": 0.58837890625,
            "ap": 0.09390004748767936,
            "ap_weighted": 0.09390004748767936,
            "f1": 0.45152877826401194,
            "f1_weighted": 0.6821540183889812
          },
          {
            "accuracy": 0.62939453125,
            "ap": 0.09360412002563229,
            "ap_weighted": 0.09360412002563229,
            "f1": 0.4692378372638313,
            "f1_weighted": 0.7146690732035246
          }
        ]
      }
    ]
  },
  "task_name": "ToxicConversationsClassification"
}