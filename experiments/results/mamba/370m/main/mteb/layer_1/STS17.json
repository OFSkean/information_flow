{
  "dataset_revision": "faeb762787bd10488a50c8b5be4a3b82e411949c",
  "evaluation_time": 16.444440841674805,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.4176084352057267,
        "cosine_spearman": 0.5738014168742198,
        "euclidean_pearson": 0.5577642539177012,
        "euclidean_spearman": 0.6064651294051747,
        "hf_subset": "en-en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5738014168742198,
        "manhattan_pearson": 0.6031157249354959,
        "manhattan_spearman": 0.6369308624570891,
        "pearson": 0.4176084352057267,
        "spearman": 0.5738014168742198
      },
      {
        "cosine_pearson": -0.07680526317779311,
        "cosine_spearman": -0.05712670904129895,
        "euclidean_pearson": -0.10528639018833331,
        "euclidean_spearman": -0.08420513968514988,
        "hf_subset": "en-de",
        "languages": [
          "eng-Latn",
          "deu-Latn"
        ],
        "main_score": -0.05712670904129895,
        "manhattan_pearson": -0.12140726724174568,
        "manhattan_spearman": -0.11842488945485205,
        "pearson": -0.07680526317779311,
        "spearman": -0.05712670904129895
      },
      {
        "cosine_pearson": 0.07326333807804541,
        "cosine_spearman": 0.09915339441964732,
        "euclidean_pearson": -0.08334719326747599,
        "euclidean_spearman": -0.07160044879884792,
        "hf_subset": "en-ar",
        "languages": [
          "eng-Latn",
          "ara-Arab"
        ],
        "main_score": 0.09915339441964732,
        "manhattan_pearson": -0.1660794750182007,
        "manhattan_spearman": -0.18287201909806358,
        "pearson": 0.07326333807804541,
        "spearman": 0.09915339441964732
      },
      {
        "cosine_pearson": -0.0927439150140667,
        "cosine_spearman": -0.05065693069017387,
        "euclidean_pearson": -0.03322047526385312,
        "euclidean_spearman": -0.017875592814590315,
        "hf_subset": "fr-en",
        "languages": [
          "fra-Latn",
          "eng-Latn"
        ],
        "main_score": -0.05065693069017387,
        "manhattan_pearson": -0.1457263024099799,
        "manhattan_spearman": -0.1331607312402706,
        "pearson": -0.0927439150140667,
        "spearman": -0.05065693069017387
      },
      {
        "cosine_pearson": 0.017746798445979702,
        "cosine_spearman": 0.05483685878655163,
        "euclidean_pearson": 0.05874979159051661,
        "euclidean_spearman": 0.06574449531982507,
        "hf_subset": "nl-en",
        "languages": [
          "nld-Latn",
          "eng-Latn"
        ],
        "main_score": 0.05483685878655163,
        "manhattan_pearson": -0.08409888734286008,
        "manhattan_spearman": -0.07829273633308198,
        "pearson": 0.017746798445979702,
        "spearman": 0.05483685878655163
      },
      {
        "cosine_pearson": -0.028099801422203093,
        "cosine_spearman": -0.010382166447955397,
        "euclidean_pearson": 0.021024692706756457,
        "euclidean_spearman": -0.0003363469821896765,
        "hf_subset": "it-en",
        "languages": [
          "ita-Latn",
          "eng-Latn"
        ],
        "main_score": -0.010382166447955397,
        "manhattan_pearson": -0.1205504930008615,
        "manhattan_spearman": -0.12916108512634653,
        "pearson": -0.028099801422203093,
        "spearman": -0.010382166447955397
      },
      {
        "cosine_pearson": -0.039819760105927984,
        "cosine_spearman": -0.101064379447736,
        "euclidean_pearson": -0.059322005070310796,
        "euclidean_spearman": -0.09950550926610101,
        "hf_subset": "es-en",
        "languages": [
          "spa-Latn",
          "eng-Latn"
        ],
        "main_score": -0.101064379447736,
        "manhattan_pearson": -0.0829762468306855,
        "manhattan_spearman": -0.17319451371156125,
        "pearson": -0.039819760105927984,
        "spearman": -0.101064379447736
      },
      {
        "cosine_pearson": -0.10648173313128065,
        "cosine_spearman": -0.06163413330581362,
        "euclidean_pearson": -0.21851997719351646,
        "euclidean_spearman": -0.21408681121672973,
        "hf_subset": "en-tr",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ],
        "main_score": -0.06163413330581362,
        "manhattan_pearson": -0.25457951502003356,
        "manhattan_spearman": -0.24244691706961408,
        "pearson": -0.10648173313128065,
        "spearman": -0.06163413330581362
      }
    ]
  },
  "task_name": "STS17"
}