{
  "dataset_revision": "edfaf9da55d3dd50d43143d90c1ac476895ae6de",
  "evaluation_time": 42.93576121330261,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.590673828125,
        "ap": 0.09118620401952067,
        "ap_weighted": 0.09118620401952067,
        "f1": 0.4469013508963924,
        "f1_weighted": 0.6796927405134437,
        "hf_subset": "default",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.590673828125,
        "scores_per_experiment": [
          {
            "accuracy": 0.44384765625,
            "ap": 0.09354716244978545,
            "ap_weighted": 0.09354716244978545,
            "f1": 0.3774133961149724,
            "f1_weighted": 0.54861319353319
          },
          {
            "accuracy": 0.5458984375,
            "ap": 0.09148582175925926,
            "ap_weighted": 0.09148582175925926,
            "f1": 0.42920641998928327,
            "f1_weighted": 0.646460240927162
          },
          {
            "accuracy": 0.61572265625,
            "ap": 0.09369673226521857,
            "ap_weighted": 0.09369673226521857,
            "f1": 0.46346083235714236,
            "f1_weighted": 0.7040652176837111
          },
          {
            "accuracy": 0.70361328125,
            "ap": 0.08779628047908276,
            "ap_weighted": 0.08779628047908276,
            "f1": 0.4902420531771504,
            "f1_weighted": 0.7678662020055224
          },
          {
            "accuracy": 0.57080078125,
            "ap": 0.09216738292757704,
            "ap_weighted": 0.09216738292757704,
            "f1": 0.44164147342543403,
            "f1_weighted": 0.6677030436686336
          },
          {
            "accuracy": 0.49462890625,
            "ap": 0.09067187940840772,
            "ap_weighted": 0.09067187940840772,
            "f1": 0.40282209159331117,
            "f1_weighted": 0.5999266351401749
          },
          {
            "accuracy": 0.7236328125,
            "ap": 0.09456625884433964,
            "ap_weighted": 0.09456625884433964,
            "f1": 0.5079029771163472,
            "f1_weighted": 0.7821789625156226
          },
          {
            "accuracy": 0.57275390625,
            "ap": 0.08810588437242216,
            "ap_weighted": 0.08810588437242216,
            "f1": 0.4379441049212824,
            "f1_weighted": 0.6696610515720394
          },
          {
            "accuracy": 0.57763671875,
            "ap": 0.08318647369985019,
            "ap_weighted": 0.08318647369985019,
            "f1": 0.43351512447976875,
            "f1_weighted": 0.6740433224680347
          },
          {
            "accuracy": 0.658203125,
            "ap": 0.09663816398926386,
            "ap_weighted": 0.09663816398926386,
            "f1": 0.4848650357892316,
            "f1_weighted": 0.7364095356203467
          }
        ]
      }
    ]
  },
  "task_name": "ToxicConversationsClassification"
}