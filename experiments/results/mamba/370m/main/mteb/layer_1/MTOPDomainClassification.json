{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 22.835954666137695,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.7921796625626996,
        "f1": 0.7867819479359657,
        "f1_weighted": 0.7949751402719663,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7921796625626996,
        "scores_per_experiment": [
          {
            "accuracy": 0.7512539899680802,
            "f1": 0.74561194217953,
            "f1_weighted": 0.7536432370716883
          },
          {
            "accuracy": 0.7747378020975833,
            "f1": 0.7764834459437701,
            "f1_weighted": 0.7790100416351186
          },
          {
            "accuracy": 0.7902416780665754,
            "f1": 0.7796008574434581,
            "f1_weighted": 0.7917704621471572
          },
          {
            "accuracy": 0.8059735522115823,
            "f1": 0.8013679179551584,
            "f1_weighted": 0.809931174797597
          },
          {
            "accuracy": 0.7995896032831737,
            "f1": 0.7968714090953589,
            "f1_weighted": 0.8050121570896727
          },
          {
            "accuracy": 0.7966256269949841,
            "f1": 0.7926325570498016,
            "f1_weighted": 0.7988742531463392
          },
          {
            "accuracy": 0.7998176014591883,
            "f1": 0.7915298947974944,
            "f1_weighted": 0.7989595620357366
          },
          {
            "accuracy": 0.7701778385772914,
            "f1": 0.7680235268136854,
            "f1_weighted": 0.7758662575807244
          },
          {
            "accuracy": 0.8185134518923849,
            "f1": 0.8151168743811797,
            "f1_weighted": 0.8216831578344262
          },
          {
            "accuracy": 0.8148654810761514,
            "f1": 0.8005810537002215,
            "f1_weighted": 0.8150010993812021
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7886353467561521,
        "f1": 0.7874877353423081,
        "f1_weighted": 0.79062827362462,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7886353467561521,
        "scores_per_experiment": [
          {
            "accuracy": 0.745413870246085,
            "f1": 0.7445572488578253,
            "f1_weighted": 0.7447764784083524
          },
          {
            "accuracy": 0.7776286353467562,
            "f1": 0.7832167452399253,
            "f1_weighted": 0.7808300673337373
          },
          {
            "accuracy": 0.7861297539149888,
            "f1": 0.7800520416223123,
            "f1_weighted": 0.7871634725530242
          },
          {
            "accuracy": 0.8085011185682327,
            "f1": 0.8085734927714231,
            "f1_weighted": 0.8118756845883787
          },
          {
            "accuracy": 0.7856823266219239,
            "f1": 0.7883717665233614,
            "f1_weighted": 0.790237904917632
          },
          {
            "accuracy": 0.7950782997762863,
            "f1": 0.7950612214869949,
            "f1_weighted": 0.7974972976773089
          },
          {
            "accuracy": 0.7870246085011185,
            "f1": 0.7804953270666583,
            "f1_weighted": 0.7862509409998805
          },
          {
            "accuracy": 0.7736017897091723,
            "f1": 0.7749855078171985,
            "f1_weighted": 0.7773936175719933
          },
          {
            "accuracy": 0.81834451901566,
            "f1": 0.8184860478617608,
            "f1_weighted": 0.8207246558080554
          },
          {
            "accuracy": 0.8089485458612975,
            "f1": 0.8010779541756203,
            "f1_weighted": 0.8095326163878375
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}