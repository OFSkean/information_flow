{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 32.72579884529114,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.7963976288189695,
        "f1": 0.7900304171505379,
        "f1_weighted": 0.7986785198507615,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7963976288189695,
        "scores_per_experiment": [
          {
            "accuracy": 0.7562699498404013,
            "f1": 0.7519723962736421,
            "f1_weighted": 0.7558347481618142
          },
          {
            "accuracy": 0.7900136798905609,
            "f1": 0.7928715482153303,
            "f1_weighted": 0.7935473071424675
          },
          {
            "accuracy": 0.7854537163702691,
            "f1": 0.7748535225041622,
            "f1_weighted": 0.788760553446221
          },
          {
            "accuracy": 0.820109439124487,
            "f1": 0.811000889093242,
            "f1_weighted": 0.821658289757052
          },
          {
            "accuracy": 0.7945736434108527,
            "f1": 0.7912093131693887,
            "f1_weighted": 0.7990688680607374
          },
          {
            "accuracy": 0.8210214318285454,
            "f1": 0.8145937755629149,
            "f1_weighted": 0.8238020718442536
          },
          {
            "accuracy": 0.8011855905152758,
            "f1": 0.7915693771829868,
            "f1_weighted": 0.8003234795105343
          },
          {
            "accuracy": 0.7767897856817145,
            "f1": 0.7732707222870148,
            "f1_weighted": 0.7809992954476662
          },
          {
            "accuracy": 0.8141814865481076,
            "f1": 0.8092494994037268,
            "f1_weighted": 0.8174543844339993
          },
          {
            "accuracy": 0.8043775649794802,
            "f1": 0.7897131278129698,
            "f1_weighted": 0.8053362007028704
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.789351230425056,
        "f1": 0.7862319078134778,
        "f1_weighted": 0.7908001439988301,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.789351230425056,
        "scores_per_experiment": [
          {
            "accuracy": 0.7449664429530202,
            "f1": 0.7435941128375763,
            "f1_weighted": 0.7419226786338188
          },
          {
            "accuracy": 0.7865771812080536,
            "f1": 0.7920911533323047,
            "f1_weighted": 0.7894007280136084
          },
          {
            "accuracy": 0.7838926174496644,
            "f1": 0.7777158298063817,
            "f1_weighted": 0.7862103881856923
          },
          {
            "accuracy": 0.8210290827740492,
            "f1": 0.8180494967308174,
            "f1_weighted": 0.8228766952423092
          },
          {
            "accuracy": 0.7923937360178971,
            "f1": 0.7930758119421352,
            "f1_weighted": 0.7962531956996183
          },
          {
            "accuracy": 0.8058165548098434,
            "f1": 0.8030478303057295,
            "f1_weighted": 0.8072124173427864
          },
          {
            "accuracy": 0.789261744966443,
            "f1": 0.7786390119189761,
            "f1_weighted": 0.7876806831214498
          },
          {
            "accuracy": 0.7749440715883669,
            "f1": 0.7751794962104395,
            "f1_weighted": 0.7781786733158542
          },
          {
            "accuracy": 0.7986577181208053,
            "f1": 0.7925076033733959,
            "f1_weighted": 0.8004860249947845
          },
          {
            "accuracy": 0.7959731543624161,
            "f1": 0.7884187316770214,
            "f1_weighted": 0.7977799554383801
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}