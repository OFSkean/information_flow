{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 36.199177503585815,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.7936844505243958,
        "f1": 0.7877542241802367,
        "f1_weighted": 0.796002577917051,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7936844505243958,
        "scores_per_experiment": [
          {
            "accuracy": 0.7551299589603283,
            "f1": 0.7513656529074964,
            "f1_weighted": 0.7558473592879107
          },
          {
            "accuracy": 0.7772457820337437,
            "f1": 0.7822225276597181,
            "f1_weighted": 0.7819831747827849
          },
          {
            "accuracy": 0.7806657546739626,
            "f1": 0.770115875951166,
            "f1_weighted": 0.7832150545060081
          },
          {
            "accuracy": 0.8173734610123119,
            "f1": 0.8100873826166289,
            "f1_weighted": 0.81898947269238
          },
          {
            "accuracy": 0.7975376196990424,
            "f1": 0.7928305904947042,
            "f1_weighted": 0.8011417793667731
          },
          {
            "accuracy": 0.8114455084359325,
            "f1": 0.8057409644723489,
            "f1_weighted": 0.8140562070822324
          },
          {
            "accuracy": 0.7975376196990424,
            "f1": 0.788854418761212,
            "f1_weighted": 0.7960827634758596
          },
          {
            "accuracy": 0.7767897856817145,
            "f1": 0.7725624135894137,
            "f1_weighted": 0.7814491679869919
          },
          {
            "accuracy": 0.8185134518923849,
            "f1": 0.8129102723248713,
            "f1_weighted": 0.8216544872524372
          },
          {
            "accuracy": 0.8046055631554948,
            "f1": 0.7908521430248069,
            "f1_weighted": 0.8056063127371333
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7876957494407159,
        "f1": 0.7846702907761077,
        "f1_weighted": 0.7889844425383277,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7876957494407159,
        "scores_per_experiment": [
          {
            "accuracy": 0.7413870246085011,
            "f1": 0.7390758123189646,
            "f1_weighted": 0.7397241658234915
          },
          {
            "accuracy": 0.7821029082774049,
            "f1": 0.789895990865194,
            "f1_weighted": 0.7846036184182921
          },
          {
            "accuracy": 0.7789709172259508,
            "f1": 0.7731719471370837,
            "f1_weighted": 0.7807842833845481
          },
          {
            "accuracy": 0.8170022371364654,
            "f1": 0.8138828722436148,
            "f1_weighted": 0.818092657524768
          },
          {
            "accuracy": 0.7946308724832215,
            "f1": 0.7946166576063944,
            "f1_weighted": 0.7972681611603658
          },
          {
            "accuracy": 0.8031319910514542,
            "f1": 0.8000645779055813,
            "f1_weighted": 0.8042701516753461
          },
          {
            "accuracy": 0.7861297539149888,
            "f1": 0.77627588076123,
            "f1_weighted": 0.7849346953394982
          },
          {
            "accuracy": 0.7740492170022372,
            "f1": 0.7735423390550121,
            "f1_weighted": 0.7774906977403335
          },
          {
            "accuracy": 0.8098434004474273,
            "f1": 0.8045447191292243,
            "f1_weighted": 0.8117989405830732
          },
          {
            "accuracy": 0.7897091722595079,
            "f1": 0.7816321107387775,
            "f1_weighted": 0.7908770537335609
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}