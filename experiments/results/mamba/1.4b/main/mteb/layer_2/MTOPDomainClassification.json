{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 35.36244058609009,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.8109439124487003,
        "f1": 0.8053727146708678,
        "f1_weighted": 0.8135329463008644,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8109439124487003,
        "scores_per_experiment": [
          {
            "accuracy": 0.7818057455540356,
            "f1": 0.7738989331145032,
            "f1_weighted": 0.7834091826698825
          },
          {
            "accuracy": 0.7957136342909257,
            "f1": 0.7958389713878404,
            "f1_weighted": 0.8004320186299466
          },
          {
            "accuracy": 0.8075695394436845,
            "f1": 0.7985515964634655,
            "f1_weighted": 0.8081798847002738
          },
          {
            "accuracy": 0.8244414044687642,
            "f1": 0.8194231827890515,
            "f1_weighted": 0.8287013627085021
          },
          {
            "accuracy": 0.8394892840857273,
            "f1": 0.8339046345567489,
            "f1_weighted": 0.8431167689236274
          },
          {
            "accuracy": 0.8123575011399908,
            "f1": 0.8085932362218493,
            "f1_weighted": 0.8148324511505233
          },
          {
            "accuracy": 0.8077975376196991,
            "f1": 0.8024979130306179,
            "f1_weighted": 0.808441463557246
          },
          {
            "accuracy": 0.7822617419060648,
            "f1": 0.7763676501170576,
            "f1_weighted": 0.7875891500372612
          },
          {
            "accuracy": 0.826265389876881,
            "f1": 0.8233855980612859,
            "f1_weighted": 0.8288750645124567
          },
          {
            "accuracy": 0.8317373461012312,
            "f1": 0.821265430966256,
            "f1_weighted": 0.8317521161189241
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.8064876957494407,
        "f1": 0.8038282818056384,
        "f1_weighted": 0.8079495370217288,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8064876957494407,
        "scores_per_experiment": [
          {
            "accuracy": 0.7785234899328859,
            "f1": 0.7719586706894177,
            "f1_weighted": 0.7776020373985137
          },
          {
            "accuracy": 0.7874720357941835,
            "f1": 0.789921056215518,
            "f1_weighted": 0.7908505193976949
          },
          {
            "accuracy": 0.8058165548098434,
            "f1": 0.8000327607148502,
            "f1_weighted": 0.8058229368837481
          },
          {
            "accuracy": 0.8196868008948546,
            "f1": 0.8214607375186237,
            "f1_weighted": 0.8242708262242032
          },
          {
            "accuracy": 0.8322147651006712,
            "f1": 0.8288977344129678,
            "f1_weighted": 0.8349838452203525
          },
          {
            "accuracy": 0.810738255033557,
            "f1": 0.8109089759693674,
            "f1_weighted": 0.8123573348591733
          },
          {
            "accuracy": 0.8004474272930648,
            "f1": 0.7963895072762637,
            "f1_weighted": 0.8001681009450857
          },
          {
            "accuracy": 0.778076062639821,
            "f1": 0.7759684457446664,
            "f1_weighted": 0.7812289142808706
          },
          {
            "accuracy": 0.8210290827740492,
            "f1": 0.8200108951665293,
            "f1_weighted": 0.8221165447240404
          },
          {
            "accuracy": 0.8308724832214766,
            "f1": 0.82273403434818,
            "f1_weighted": 0.8300943102836041
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}