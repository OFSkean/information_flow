{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 33.60398769378662,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.28684000000000004,
        "f1": 0.28247908797622656,
        "f1_weighted": 0.28247908797622656,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.28684000000000004,
        "scores_per_experiment": [
          {
            "accuracy": 0.319,
            "f1": 0.3180722862976054,
            "f1_weighted": 0.3180722862976054
          },
          {
            "accuracy": 0.295,
            "f1": 0.29460432562167044,
            "f1_weighted": 0.29460432562167044
          },
          {
            "accuracy": 0.2916,
            "f1": 0.2908016042235565,
            "f1_weighted": 0.2908016042235565
          },
          {
            "accuracy": 0.2904,
            "f1": 0.287809011126963,
            "f1_weighted": 0.287809011126963
          },
          {
            "accuracy": 0.325,
            "f1": 0.3107572987637828,
            "f1_weighted": 0.31075729876378283
          },
          {
            "accuracy": 0.2344,
            "f1": 0.232812834252573,
            "f1_weighted": 0.232812834252573
          },
          {
            "accuracy": 0.2464,
            "f1": 0.24229509820129938,
            "f1_weighted": 0.24229509820129932
          },
          {
            "accuracy": 0.2888,
            "f1": 0.2804256776625117,
            "f1_weighted": 0.2804256776625117
          },
          {
            "accuracy": 0.2872,
            "f1": 0.2826374116299453,
            "f1_weighted": 0.28263741162994527
          },
          {
            "accuracy": 0.2906,
            "f1": 0.2845753319823581,
            "f1_weighted": 0.2845753319823581
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.28490000000000004,
        "f1": 0.2798796905324232,
        "f1_weighted": 0.2798796905324232,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.28490000000000004,
        "scores_per_experiment": [
          {
            "accuracy": 0.316,
            "f1": 0.31529134086795507,
            "f1_weighted": 0.3152913408679551
          },
          {
            "accuracy": 0.2982,
            "f1": 0.29917894567496006,
            "f1_weighted": 0.2991789456749601
          },
          {
            "accuracy": 0.28,
            "f1": 0.2780724678985954,
            "f1_weighted": 0.27807246789859547
          },
          {
            "accuracy": 0.2836,
            "f1": 0.2793982177854605,
            "f1_weighted": 0.2793982177854605
          },
          {
            "accuracy": 0.3242,
            "f1": 0.3090129739774728,
            "f1_weighted": 0.30901297397747274
          },
          {
            "accuracy": 0.235,
            "f1": 0.23323762207290274,
            "f1_weighted": 0.23323762207290274
          },
          {
            "accuracy": 0.2482,
            "f1": 0.2423031817312029,
            "f1_weighted": 0.2423031817312029
          },
          {
            "accuracy": 0.2838,
            "f1": 0.27550718493406257,
            "f1_weighted": 0.27550718493406257
          },
          {
            "accuracy": 0.2742,
            "f1": 0.26879431434880124,
            "f1_weighted": 0.26879431434880124
          },
          {
            "accuracy": 0.3058,
            "f1": 0.2980006560328182,
            "f1_weighted": 0.29800065603281817
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}