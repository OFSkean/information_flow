{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 22.42034339904785,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.7744186046511629,
        "f1": 0.7687535498140724,
        "f1_weighted": 0.7778653314217582,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7744186046511629,
        "scores_per_experiment": [
          {
            "accuracy": 0.7405380756953944,
            "f1": 0.730885324497607,
            "f1_weighted": 0.7409765100961238
          },
          {
            "accuracy": 0.7560419516643867,
            "f1": 0.7587037532373031,
            "f1_weighted": 0.7621087235204895
          },
          {
            "accuracy": 0.7756497948016415,
            "f1": 0.7648966184577755,
            "f1_weighted": 0.7757485759137266
          },
          {
            "accuracy": 0.797765617875057,
            "f1": 0.7930826166303947,
            "f1_weighted": 0.8020079908771571
          },
          {
            "accuracy": 0.815093479252166,
            "f1": 0.808627294088112,
            "f1_weighted": 0.8199124598623845
          },
          {
            "accuracy": 0.7729138166894665,
            "f1": 0.7694612066812067,
            "f1_weighted": 0.7774497603183956
          },
          {
            "accuracy": 0.7797537619699042,
            "f1": 0.7759790416680962,
            "f1_weighted": 0.7816516650007099
          },
          {
            "accuracy": 0.7309621523027816,
            "f1": 0.7270343040046918,
            "f1_weighted": 0.7378782158099005
          },
          {
            "accuracy": 0.791609667122663,
            "f1": 0.7884965908270256,
            "f1_weighted": 0.7947896118400946
          },
          {
            "accuracy": 0.7838577291381669,
            "f1": 0.7703687480485102,
            "f1_weighted": 0.7861298009785996
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7677404921700224,
        "f1": 0.7659463238413263,
        "f1_weighted": 0.7703156119683057,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7677404921700224,
        "scores_per_experiment": [
          {
            "accuracy": 0.7266219239373601,
            "f1": 0.7218873293180448,
            "f1_weighted": 0.7246760703039522
          },
          {
            "accuracy": 0.7552572706935123,
            "f1": 0.760783807191255,
            "f1_weighted": 0.7599512082260799
          },
          {
            "accuracy": 0.7722595078299777,
            "f1": 0.7674219183555678,
            "f1_weighted": 0.7724254533549132
          },
          {
            "accuracy": 0.7865771812080536,
            "f1": 0.787075966733429,
            "f1_weighted": 0.7908433709550803
          },
          {
            "accuracy": 0.8170022371364654,
            "f1": 0.8127096944840382,
            "f1_weighted": 0.8203241326773325
          },
          {
            "accuracy": 0.7704697986577181,
            "f1": 0.7705549582631961,
            "f1_weighted": 0.7750383874968786
          },
          {
            "accuracy": 0.7668903803131991,
            "f1": 0.7642494143008128,
            "f1_weighted": 0.7686143448058887
          },
          {
            "accuracy": 0.7302013422818792,
            "f1": 0.7301253073605177,
            "f1_weighted": 0.7338822354396514
          },
          {
            "accuracy": 0.7825503355704698,
            "f1": 0.7839627344205503,
            "f1_weighted": 0.7851592833475162
          },
          {
            "accuracy": 0.7695749440715883,
            "f1": 0.7606921079858521,
            "f1_weighted": 0.7722416330757631
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}