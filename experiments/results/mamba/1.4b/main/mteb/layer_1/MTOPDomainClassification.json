{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 29.135290145874023,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.8021659826721386,
        "f1": 0.7963998219160747,
        "f1_weighted": 0.8051419639132279,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8021659826721386,
        "scores_per_experiment": [
          {
            "accuracy": 0.7667578659370725,
            "f1": 0.758811978121972,
            "f1_weighted": 0.7684878452431065
          },
          {
            "accuracy": 0.7861377108983129,
            "f1": 0.7865194364878384,
            "f1_weighted": 0.7913812225967065
          },
          {
            "accuracy": 0.8041495668034656,
            "f1": 0.7953508263887561,
            "f1_weighted": 0.8049424039516582
          },
          {
            "accuracy": 0.8134974920200638,
            "f1": 0.808805025962227,
            "f1_weighted": 0.8185159873177469
          },
          {
            "accuracy": 0.831281349749202,
            "f1": 0.8246379871674285,
            "f1_weighted": 0.8351241881428236
          },
          {
            "accuracy": 0.7986776105791153,
            "f1": 0.7958536970064383,
            "f1_weighted": 0.8017376148560745
          },
          {
            "accuracy": 0.8030095759233926,
            "f1": 0.7982372690897861,
            "f1_weighted": 0.8035880517856885
          },
          {
            "accuracy": 0.7790697674418605,
            "f1": 0.7724466368909632,
            "f1_weighted": 0.7849985977403461
          },
          {
            "accuracy": 0.8169174646602827,
            "f1": 0.8135219488465869,
            "f1_weighted": 0.8201475145172568
          },
          {
            "accuracy": 0.8221614227086184,
            "f1": 0.809813413198751,
            "f1_weighted": 0.8224962129808706
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.8008053691275168,
        "f1": 0.7985160906232247,
        "f1_weighted": 0.8025923037635433,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.8008053691275168,
        "scores_per_experiment": [
          {
            "accuracy": 0.763758389261745,
            "f1": 0.7573975733565341,
            "f1_weighted": 0.7639930250386175
          },
          {
            "accuracy": 0.7821029082774049,
            "f1": 0.7865493282064665,
            "f1_weighted": 0.7865393282203345
          },
          {
            "accuracy": 0.8067114093959732,
            "f1": 0.8028926722162081,
            "f1_weighted": 0.8069223111022599
          },
          {
            "accuracy": 0.8089485458612975,
            "f1": 0.8113706690086251,
            "f1_weighted": 0.8138751613088969
          },
          {
            "accuracy": 0.8340044742729307,
            "f1": 0.8305360688372745,
            "f1_weighted": 0.8363806476249729
          },
          {
            "accuracy": 0.8049217002237137,
            "f1": 0.8060642896569988,
            "f1_weighted": 0.807407891066346
          },
          {
            "accuracy": 0.7955257270693512,
            "f1": 0.7924938073912446,
            "f1_weighted": 0.7958028214336463
          },
          {
            "accuracy": 0.7794183445190157,
            "f1": 0.7754732336964864,
            "f1_weighted": 0.7812667310837883
          },
          {
            "accuracy": 0.8125279642058165,
            "f1": 0.8114104669091052,
            "f1_weighted": 0.813949424695763
          },
          {
            "accuracy": 0.8201342281879195,
            "f1": 0.8109727969533025,
            "f1_weighted": 0.819785696060808
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}