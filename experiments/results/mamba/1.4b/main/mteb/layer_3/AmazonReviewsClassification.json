{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 382.7567939758301,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.3161,
        "f1": 0.314223231220056,
        "f1_weighted": 0.314223231220056,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.3161,
        "scores_per_experiment": [
          {
            "accuracy": 0.356,
            "f1": 0.3532284126567901,
            "f1_weighted": 0.3532284126567901
          },
          {
            "accuracy": 0.3262,
            "f1": 0.326908682256364,
            "f1_weighted": 0.326908682256364
          },
          {
            "accuracy": 0.3108,
            "f1": 0.31276203338233677,
            "f1_weighted": 0.3127620333823368
          },
          {
            "accuracy": 0.3212,
            "f1": 0.3203573424859606,
            "f1_weighted": 0.32035734248596065
          },
          {
            "accuracy": 0.3648,
            "f1": 0.35868179504250836,
            "f1_weighted": 0.3586817950425083
          },
          {
            "accuracy": 0.2682,
            "f1": 0.26736913514002536,
            "f1_weighted": 0.26736913514002536
          },
          {
            "accuracy": 0.2604,
            "f1": 0.25965868665431724,
            "f1_weighted": 0.25965868665431724
          },
          {
            "accuracy": 0.3326,
            "f1": 0.3263908454357928,
            "f1_weighted": 0.32639084543579283
          },
          {
            "accuracy": 0.3028,
            "f1": 0.301009041958916,
            "f1_weighted": 0.30100904195891603
          },
          {
            "accuracy": 0.318,
            "f1": 0.31586633718754864,
            "f1_weighted": 0.31586633718754864
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.31171999999999994,
        "f1": 0.310406300979782,
        "f1_weighted": 0.310406300979782,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.31171999999999994,
        "scores_per_experiment": [
          {
            "accuracy": 0.3382,
            "f1": 0.3359983174059637,
            "f1_weighted": 0.3359983174059637
          },
          {
            "accuracy": 0.3252,
            "f1": 0.328466374636167,
            "f1_weighted": 0.32846637463616707
          },
          {
            "accuracy": 0.308,
            "f1": 0.3112144960797713,
            "f1_weighted": 0.3112144960797713
          },
          {
            "accuracy": 0.3002,
            "f1": 0.3007568942078949,
            "f1_weighted": 0.3007568942078949
          },
          {
            "accuracy": 0.3616,
            "f1": 0.35389797890300956,
            "f1_weighted": 0.3538979789030095
          },
          {
            "accuracy": 0.266,
            "f1": 0.26581267506311895,
            "f1_weighted": 0.2658126750631189
          },
          {
            "accuracy": 0.2698,
            "f1": 0.2692940030132095,
            "f1_weighted": 0.26929400301320955
          },
          {
            "accuracy": 0.3162,
            "f1": 0.310069232390556,
            "f1_weighted": 0.31006923239055595
          },
          {
            "accuracy": 0.304,
            "f1": 0.3026444546117306,
            "f1_weighted": 0.3026444546117306
          },
          {
            "accuracy": 0.328,
            "f1": 0.3259085834863985,
            "f1_weighted": 0.32590858348639856
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}