{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 19.753584623336792,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.735750113999088,
        "f1": 0.7303578837282142,
        "f1_weighted": 0.7393397325930305,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.735750113999088,
        "scores_per_experiment": [
          {
            "accuracy": 0.6988144094847242,
            "f1": 0.6895793407639533,
            "f1_weighted": 0.6996576016523123
          },
          {
            "accuracy": 0.7154582763337893,
            "f1": 0.7196713546650195,
            "f1_weighted": 0.7225554407085046
          },
          {
            "accuracy": 0.7412220702234382,
            "f1": 0.729290869445854,
            "f1_weighted": 0.7427098924462597
          },
          {
            "accuracy": 0.7658458732330141,
            "f1": 0.7597621885361261,
            "f1_weighted": 0.7713542194401748
          },
          {
            "accuracy": 0.7859097127222983,
            "f1": 0.7752564536129334,
            "f1_weighted": 0.7878035965718945
          },
          {
            "accuracy": 0.7366621067031464,
            "f1": 0.7342727111011917,
            "f1_weighted": 0.7385020575614966
          },
          {
            "accuracy": 0.7330141358869129,
            "f1": 0.72934077819064,
            "f1_weighted": 0.733341055382098
          },
          {
            "accuracy": 0.6796625626994984,
            "f1": 0.6811541645463328,
            "f1_weighted": 0.6914905240770274
          },
          {
            "accuracy": 0.7533059735522116,
            "f1": 0.7509196962660507,
            "f1_weighted": 0.7560006928798128
          },
          {
            "accuracy": 0.7476060191518468,
            "f1": 0.734331280154041,
            "f1_weighted": 0.7499822452107253
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7301565995525727,
        "f1": 0.7290827038802657,
        "f1_weighted": 0.7328796038362889,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7301565995525727,
        "scores_per_experiment": [
          {
            "accuracy": 0.6818791946308724,
            "f1": 0.6779261200436438,
            "f1_weighted": 0.6803644869278727
          },
          {
            "accuracy": 0.7208053691275168,
            "f1": 0.7277415630049077,
            "f1_weighted": 0.7259164220107406
          },
          {
            "accuracy": 0.7328859060402685,
            "f1": 0.7289646507937476,
            "f1_weighted": 0.7345931993151023
          },
          {
            "accuracy": 0.7588366890380314,
            "f1": 0.759059028303886,
            "f1_weighted": 0.7627246787839753
          },
          {
            "accuracy": 0.7973154362416107,
            "f1": 0.7932651761571828,
            "f1_weighted": 0.7984103985787652
          },
          {
            "accuracy": 0.7337807606263982,
            "f1": 0.7340798973215357,
            "f1_weighted": 0.7366151864193273
          },
          {
            "accuracy": 0.7208053691275168,
            "f1": 0.716950661018179,
            "f1_weighted": 0.7213909439630113
          },
          {
            "accuracy": 0.6706935123042506,
            "f1": 0.6759818933693781,
            "f1_weighted": 0.6799157962244451
          },
          {
            "accuracy": 0.7507829977628635,
            "f1": 0.752527479795157,
            "f1_weighted": 0.7532470038589555
          },
          {
            "accuracy": 0.7337807606263982,
            "f1": 0.7243305689950388,
            "f1_weighted": 0.7356179222806939
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}