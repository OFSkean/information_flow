{
  "dataset_revision": "4672e20407010da34463acc759c162ca9734bca6",
  "evaluation_time": 36.444212675094604,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.5704102219233356,
        "f1": 0.549369589906282,
        "f1_weighted": 0.5712053994675035,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5704102219233356,
        "scores_per_experiment": [
          {
            "accuracy": 0.5706119704102219,
            "f1": 0.5565159738042736,
            "f1_weighted": 0.5716307617612986
          },
          {
            "accuracy": 0.5773369199731002,
            "f1": 0.5604412609144074,
            "f1_weighted": 0.58000444093061
          },
          {
            "accuracy": 0.5796906523201076,
            "f1": 0.5449795090735462,
            "f1_weighted": 0.5750989989038203
          },
          {
            "accuracy": 0.5864156018829859,
            "f1": 0.5542906633476631,
            "f1_weighted": 0.586387591025809
          },
          {
            "accuracy": 0.5827168796234028,
            "f1": 0.5549549923090671,
            "f1_weighted": 0.5820965706425953
          },
          {
            "accuracy": 0.5453934095494284,
            "f1": 0.5325086327778332,
            "f1_weighted": 0.5492014149687389
          },
          {
            "accuracy": 0.5591795561533288,
            "f1": 0.5471831778480749,
            "f1_weighted": 0.5602929291113999
          },
          {
            "accuracy": 0.5615332885003362,
            "f1": 0.5377746617803008,
            "f1_weighted": 0.5641739220757289
          },
          {
            "accuracy": 0.5685944855413584,
            "f1": 0.5501235437924773,
            "f1_weighted": 0.5681721756610288
          },
          {
            "accuracy": 0.5726294552790854,
            "f1": 0.554923483415177,
            "f1_weighted": 0.5749951895940046
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.5791933103787507,
        "f1": 0.5574659340606501,
        "f1_weighted": 0.5795304136757616,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5791933103787507,
        "scores_per_experiment": [
          {
            "accuracy": 0.5656665027053616,
            "f1": 0.550453823268431,
            "f1_weighted": 0.5637192723506673
          },
          {
            "accuracy": 0.5986227250368913,
            "f1": 0.5705670828928079,
            "f1_weighted": 0.5981026555487695
          },
          {
            "accuracy": 0.5932120019675357,
            "f1": 0.5736136654443934,
            "f1_weighted": 0.5914188499943466
          },
          {
            "accuracy": 0.5887850467289719,
            "f1": 0.5553765233353641,
            "f1_weighted": 0.5889765156253634
          },
          {
            "accuracy": 0.5986227250368913,
            "f1": 0.5793635432397547,
            "f1_weighted": 0.5999039706473875
          },
          {
            "accuracy": 0.5696015740285293,
            "f1": 0.5614676412082145,
            "f1_weighted": 0.5732860278137167
          },
          {
            "accuracy": 0.5558288243974422,
            "f1": 0.5438280172629006,
            "f1_weighted": 0.5584077309183584
          },
          {
            "accuracy": 0.5681259222823414,
            "f1": 0.5315201456577926,
            "f1_weighted": 0.5650528016389477
          },
          {
            "accuracy": 0.5636989670437776,
            "f1": 0.542585431520897,
            "f1_weighted": 0.5661707210141801
          },
          {
            "accuracy": 0.5897688145597639,
            "f1": 0.5658834667759465,
            "f1_weighted": 0.5902655912058791
          }
        ]
      }
    ]
  },
  "task_name": "MassiveIntentClassification"
}