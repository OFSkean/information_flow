{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 23.90631866455078,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.7921112631098952,
        "f1": 0.7856181130775574,
        "f1_weighted": 0.7947084281047918,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7921112631098952,
        "scores_per_experiment": [
          {
            "accuracy": 0.7514819881440948,
            "f1": 0.74323471744599,
            "f1_weighted": 0.7518899317897719
          },
          {
            "accuracy": 0.7984496124031008,
            "f1": 0.7966958035710228,
            "f1_weighted": 0.8021329783787371
          },
          {
            "accuracy": 0.7854537163702691,
            "f1": 0.7737295239365444,
            "f1_weighted": 0.7880758489238567
          },
          {
            "accuracy": 0.8087095303237574,
            "f1": 0.8043338411360133,
            "f1_weighted": 0.812668436616163
          },
          {
            "accuracy": 0.8203374373005016,
            "f1": 0.8115394529189582,
            "f1_weighted": 0.8253341538472062
          },
          {
            "accuracy": 0.7950296397628819,
            "f1": 0.7904437819387812,
            "f1_weighted": 0.796713232510071
          },
          {
            "accuracy": 0.779297765617875,
            "f1": 0.7738928548239798,
            "f1_weighted": 0.7790496779539491
          },
          {
            "accuracy": 0.769265845873233,
            "f1": 0.7647671853349176,
            "f1_weighted": 0.7747557061073329
          },
          {
            "accuracy": 0.8087095303237574,
            "f1": 0.8055669558233632,
            "f1_weighted": 0.8123133984981327
          },
          {
            "accuracy": 0.8043775649794802,
            "f1": 0.7919770138460027,
            "f1_weighted": 0.8041509164226968
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7839373601789709,
        "f1": 0.7810524687580677,
        "f1_weighted": 0.7860062425765554,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7839373601789709,
        "scores_per_experiment": [
          {
            "accuracy": 0.7373601789709172,
            "f1": 0.7338863884695346,
            "f1_weighted": 0.734927095210335
          },
          {
            "accuracy": 0.7906040268456376,
            "f1": 0.7912586834066964,
            "f1_weighted": 0.7936423360210776
          },
          {
            "accuracy": 0.7829977628635347,
            "f1": 0.7758469946352587,
            "f1_weighted": 0.7847551766689511
          },
          {
            "accuracy": 0.8080536912751678,
            "f1": 0.8089576442971126,
            "f1_weighted": 0.8120681939943274
          },
          {
            "accuracy": 0.8116331096196868,
            "f1": 0.8076875025541213,
            "f1_weighted": 0.8153362740455337
          },
          {
            "accuracy": 0.7937360178970917,
            "f1": 0.7931864335685532,
            "f1_weighted": 0.796300734497567
          },
          {
            "accuracy": 0.763758389261745,
            "f1": 0.759425050616014,
            "f1_weighted": 0.7642123272196643
          },
          {
            "accuracy": 0.7574944071588366,
            "f1": 0.7588389861748752,
            "f1_weighted": 0.7633517944563184
          },
          {
            "accuracy": 0.8031319910514542,
            "f1": 0.7999007092600409,
            "f1_weighted": 0.8050313872756708
          },
          {
            "accuracy": 0.7906040268456376,
            "f1": 0.7815362945984691,
            "f1_weighted": 0.7904371063761089
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}