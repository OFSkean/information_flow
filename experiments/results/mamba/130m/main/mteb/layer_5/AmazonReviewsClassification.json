{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 219.43638920783997,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.31524,
        "f1": 0.3141317366379465,
        "f1_weighted": 0.31413173663794647,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.31524,
        "scores_per_experiment": [
          {
            "accuracy": 0.3412,
            "f1": 0.3414435098796903,
            "f1_weighted": 0.34144350987969024
          },
          {
            "accuracy": 0.3418,
            "f1": 0.3408772194774935,
            "f1_weighted": 0.3408772194774935
          },
          {
            "accuracy": 0.3078,
            "f1": 0.30724561206537326,
            "f1_weighted": 0.30724561206537326
          },
          {
            "accuracy": 0.3008,
            "f1": 0.30356962103995405,
            "f1_weighted": 0.303569621039954
          },
          {
            "accuracy": 0.3544,
            "f1": 0.3479769658371782,
            "f1_weighted": 0.34797696583717824
          },
          {
            "accuracy": 0.2896,
            "f1": 0.2863098162405314,
            "f1_weighted": 0.2863098162405314
          },
          {
            "accuracy": 0.28,
            "f1": 0.28090180904812667,
            "f1_weighted": 0.2809018090481266
          },
          {
            "accuracy": 0.3244,
            "f1": 0.32313867629504256,
            "f1_weighted": 0.32313867629504256
          },
          {
            "accuracy": 0.2974,
            "f1": 0.298762209745267,
            "f1_weighted": 0.29876220974526707
          },
          {
            "accuracy": 0.315,
            "f1": 0.31109192675080827,
            "f1_weighted": 0.31109192675080827
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.31472,
        "f1": 0.3133231304399214,
        "f1_weighted": 0.3133231304399214,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.31472,
        "scores_per_experiment": [
          {
            "accuracy": 0.3398,
            "f1": 0.33754256773790703,
            "f1_weighted": 0.337542567737907
          },
          {
            "accuracy": 0.3364,
            "f1": 0.3372666331891585,
            "f1_weighted": 0.3372666331891585
          },
          {
            "accuracy": 0.309,
            "f1": 0.30915793795440816,
            "f1_weighted": 0.30915793795440816
          },
          {
            "accuracy": 0.2896,
            "f1": 0.2920357857282202,
            "f1_weighted": 0.29203578572822014
          },
          {
            "accuracy": 0.3628,
            "f1": 0.35536266482446266,
            "f1_weighted": 0.3553626648244626
          },
          {
            "accuracy": 0.2938,
            "f1": 0.29010468274724593,
            "f1_weighted": 0.2901046827472459
          },
          {
            "accuracy": 0.2874,
            "f1": 0.28835513342690433,
            "f1_weighted": 0.2883551334269043
          },
          {
            "accuracy": 0.3034,
            "f1": 0.30392160285007075,
            "f1_weighted": 0.30392160285007075
          },
          {
            "accuracy": 0.305,
            "f1": 0.30431803669315566,
            "f1_weighted": 0.30431803669315566
          },
          {
            "accuracy": 0.32,
            "f1": 0.3151662592476808,
            "f1_weighted": 0.3151662592476808
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}