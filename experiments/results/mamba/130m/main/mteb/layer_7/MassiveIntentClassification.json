{
  "dataset_revision": "4672e20407010da34463acc759c162ca9734bca6",
  "evaluation_time": 45.31211233139038,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.5566577000672496,
        "f1": 0.5290810883368812,
        "f1_weighted": 0.5588351974410397,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5566577000672496,
        "scores_per_experiment": [
          {
            "accuracy": 0.5501008742434432,
            "f1": 0.5398115900926169,
            "f1_weighted": 0.5519751372267722
          },
          {
            "accuracy": 0.5655682582380632,
            "f1": 0.5404574094460473,
            "f1_weighted": 0.5694334669493288
          },
          {
            "accuracy": 0.5527908540685945,
            "f1": 0.5160451456105566,
            "f1_weighted": 0.5512913356852408
          },
          {
            "accuracy": 0.5810356422326832,
            "f1": 0.5388951145661312,
            "f1_weighted": 0.5832176657438249
          },
          {
            "accuracy": 0.5719569603227975,
            "f1": 0.5365076961146398,
            "f1_weighted": 0.5716669063457986
          },
          {
            "accuracy": 0.5339609952925353,
            "f1": 0.5106124807656375,
            "f1_weighted": 0.5403067131031194
          },
          {
            "accuracy": 0.5400134498991258,
            "f1": 0.5247897192369814,
            "f1_weighted": 0.5387410556782284
          },
          {
            "accuracy": 0.5440484196368527,
            "f1": 0.5122002050519645,
            "f1_weighted": 0.5490037641615345
          },
          {
            "accuracy": 0.5635507733691997,
            "f1": 0.5372591385534218,
            "f1_weighted": 0.5671094311323863
          },
          {
            "accuracy": 0.5635507733691997,
            "f1": 0.5342323839308141,
            "f1_weighted": 0.5656064983841643
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.5666502705361535,
        "f1": 0.5397814998858634,
        "f1_weighted": 0.5679768082144541,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5666502705361535,
        "scores_per_experiment": [
          {
            "accuracy": 0.558288243974422,
            "f1": 0.5456801614217017,
            "f1_weighted": 0.5568248458495507
          },
          {
            "accuracy": 0.5892769306443679,
            "f1": 0.560513806933658,
            "f1_weighted": 0.5930359895555275
          },
          {
            "accuracy": 0.5853418593212002,
            "f1": 0.547157448844944,
            "f1_weighted": 0.5879607071211178
          },
          {
            "accuracy": 0.5759960649286768,
            "f1": 0.5374642135309453,
            "f1_weighted": 0.5763420467477886
          },
          {
            "accuracy": 0.5804230201672406,
            "f1": 0.5574282715462359,
            "f1_weighted": 0.5792474859216357
          },
          {
            "accuracy": 0.5366453516969996,
            "f1": 0.5202927483889207,
            "f1_weighted": 0.5390490310091881
          },
          {
            "accuracy": 0.5341859321200196,
            "f1": 0.5206618634062129,
            "f1_weighted": 0.5345424137807016
          },
          {
            "accuracy": 0.558288243974422,
            "f1": 0.5154461089518207,
            "f1_weighted": 0.5603964766513495
          },
          {
            "accuracy": 0.573536645351697,
            "f1": 0.5557421730054932,
            "f1_weighted": 0.5755080388070682
          },
          {
            "accuracy": 0.5745204131824889,
            "f1": 0.5374282028287026,
            "f1_weighted": 0.5768610467006134
          }
        ]
      }
    ]
  },
  "task_name": "MassiveIntentClassification"
}