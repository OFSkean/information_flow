{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 74.23678851127625,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.2903,
        "f1": 0.2889626645835809,
        "f1_weighted": 0.2889626645835809,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.2903,
        "scores_per_experiment": [
          {
            "accuracy": 0.3298,
            "f1": 0.3324454120843416,
            "f1_weighted": 0.33244541208434164
          },
          {
            "accuracy": 0.2954,
            "f1": 0.29240977562310294,
            "f1_weighted": 0.29240977562310294
          },
          {
            "accuracy": 0.2832,
            "f1": 0.2861840478151686,
            "f1_weighted": 0.28618404781516854
          },
          {
            "accuracy": 0.2866,
            "f1": 0.28949672894722767,
            "f1_weighted": 0.2894967289472277
          },
          {
            "accuracy": 0.3286,
            "f1": 0.3166302523246799,
            "f1_weighted": 0.31663025232467984
          },
          {
            "accuracy": 0.2358,
            "f1": 0.23548342818764884,
            "f1_weighted": 0.2354834281876488
          },
          {
            "accuracy": 0.255,
            "f1": 0.2542117135524167,
            "f1_weighted": 0.2542117135524166
          },
          {
            "accuracy": 0.3052,
            "f1": 0.3017786115146942,
            "f1_weighted": 0.30177861151469426
          },
          {
            "accuracy": 0.2844,
            "f1": 0.28447518284863926,
            "f1_weighted": 0.28447518284863926
          },
          {
            "accuracy": 0.299,
            "f1": 0.29651149293788903,
            "f1_weighted": 0.29651149293788903
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.28845999999999994,
        "f1": 0.2869919711833192,
        "f1_weighted": 0.2869919711833192,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.28845999999999994,
        "scores_per_experiment": [
          {
            "accuracy": 0.3188,
            "f1": 0.32088818576849076,
            "f1_weighted": 0.32088818576849076
          },
          {
            "accuracy": 0.2934,
            "f1": 0.292811329347098,
            "f1_weighted": 0.292811329347098
          },
          {
            "accuracy": 0.2876,
            "f1": 0.2907669056392449,
            "f1_weighted": 0.29076690563924484
          },
          {
            "accuracy": 0.278,
            "f1": 0.2799803843015069,
            "f1_weighted": 0.2799803843015069
          },
          {
            "accuracy": 0.3308,
            "f1": 0.31853846867056224,
            "f1_weighted": 0.31853846867056224
          },
          {
            "accuracy": 0.2448,
            "f1": 0.24483371002451718,
            "f1_weighted": 0.24483371002451718
          },
          {
            "accuracy": 0.2562,
            "f1": 0.2543386853906826,
            "f1_weighted": 0.2543386853906826
          },
          {
            "accuracy": 0.283,
            "f1": 0.2798243477688213,
            "f1_weighted": 0.27982434776882137
          },
          {
            "accuracy": 0.2758,
            "f1": 0.2740306439882331,
            "f1_weighted": 0.2740306439882332
          },
          {
            "accuracy": 0.3162,
            "f1": 0.31390705093403526,
            "f1_weighted": 0.3139070509340352
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}