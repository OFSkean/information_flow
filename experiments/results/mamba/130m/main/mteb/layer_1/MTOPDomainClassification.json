{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 21.123947858810425,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.7859325125398996,
        "f1": 0.7794225629187415,
        "f1_weighted": 0.7889343699675846,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7859325125398996,
        "scores_per_experiment": [
          {
            "accuracy": 0.7660738714090287,
            "f1": 0.7569841159584823,
            "f1_weighted": 0.7660343104025065
          },
          {
            "accuracy": 0.774281805745554,
            "f1": 0.7731318885595879,
            "f1_weighted": 0.7793861026976817
          },
          {
            "accuracy": 0.7888736890104879,
            "f1": 0.7733006221625413,
            "f1_weighted": 0.7904920487477483
          },
          {
            "accuracy": 0.8098495212038304,
            "f1": 0.806113452216237,
            "f1_weighted": 0.8131627184338098
          },
          {
            "accuracy": 0.8137254901960784,
            "f1": 0.8061166553924618,
            "f1_weighted": 0.8174945588186976
          },
          {
            "accuracy": 0.7911536707706338,
            "f1": 0.7875323528888315,
            "f1_weighted": 0.7936221355057804
          },
          {
            "accuracy": 0.771545827633379,
            "f1": 0.763960940441476,
            "f1_weighted": 0.7704608159194786
          },
          {
            "accuracy": 0.7412220702234382,
            "f1": 0.7394073353212126,
            "f1_weighted": 0.7511304111740957
          },
          {
            "accuracy": 0.8123575011399908,
            "f1": 0.8093754029459508,
            "f1_weighted": 0.8159952250786638
          },
          {
            "accuracy": 0.7902416780665754,
            "f1": 0.7783028633006336,
            "f1_weighted": 0.7915653728973837
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7753020134228189,
        "f1": 0.7734867539361552,
        "f1_weighted": 0.777824920066343,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7753020134228189,
        "scores_per_experiment": [
          {
            "accuracy": 0.7395973154362416,
            "f1": 0.7382867165402346,
            "f1_weighted": 0.7373659469511914
          },
          {
            "accuracy": 0.7727069351230426,
            "f1": 0.7741543021440158,
            "f1_weighted": 0.7765232270545062
          },
          {
            "accuracy": 0.7856823266219239,
            "f1": 0.7781153566280732,
            "f1_weighted": 0.7863162520770339
          },
          {
            "accuracy": 0.8098434004474273,
            "f1": 0.8099325515696317,
            "f1_weighted": 0.8125281184158665
          },
          {
            "accuracy": 0.8017897091722596,
            "f1": 0.8003166028667533,
            "f1_weighted": 0.8067407884261435
          },
          {
            "accuracy": 0.7825503355704698,
            "f1": 0.7823611870389299,
            "f1_weighted": 0.7854373538013856
          },
          {
            "accuracy": 0.7498881431767338,
            "f1": 0.7441816369105164,
            "f1_weighted": 0.7495032410941107
          },
          {
            "accuracy": 0.7355704697986577,
            "f1": 0.7392576307360677,
            "f1_weighted": 0.7435981173932145
          },
          {
            "accuracy": 0.8035794183445191,
            "f1": 0.8026124250645243,
            "f1_weighted": 0.8060562136356849
          },
          {
            "accuracy": 0.7718120805369127,
            "f1": 0.7656491298628044,
            "f1_weighted": 0.7741799418142923
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}