{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 255.74437999725342,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.31986,
        "f1": 0.3195117388474869,
        "f1_weighted": 0.31951173884748696,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.31986,
        "scores_per_experiment": [
          {
            "accuracy": 0.333,
            "f1": 0.3366185963885693,
            "f1_weighted": 0.33661859638856934
          },
          {
            "accuracy": 0.3398,
            "f1": 0.33655614254079363,
            "f1_weighted": 0.33655614254079363
          },
          {
            "accuracy": 0.3122,
            "f1": 0.3134308461919864,
            "f1_weighted": 0.3134308461919864
          },
          {
            "accuracy": 0.2996,
            "f1": 0.304121245068517,
            "f1_weighted": 0.30412124506851695
          },
          {
            "accuracy": 0.3618,
            "f1": 0.35778850247684135,
            "f1_weighted": 0.35778850247684135
          },
          {
            "accuracy": 0.3006,
            "f1": 0.2992615449638806,
            "f1_weighted": 0.2992615449638805
          },
          {
            "accuracy": 0.2912,
            "f1": 0.2934793579698049,
            "f1_weighted": 0.29347935796980495
          },
          {
            "accuracy": 0.3358,
            "f1": 0.3327584363504167,
            "f1_weighted": 0.3327584363504167
          },
          {
            "accuracy": 0.3028,
            "f1": 0.3033279147927078,
            "f1_weighted": 0.3033279147927079
          },
          {
            "accuracy": 0.3218,
            "f1": 0.31777480173135164,
            "f1_weighted": 0.31777480173135164
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.31594,
        "f1": 0.3150925070308032,
        "f1_weighted": 0.3150925070308032,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.31594,
        "scores_per_experiment": [
          {
            "accuracy": 0.3398,
            "f1": 0.3422074760716356,
            "f1_weighted": 0.34220747607163565
          },
          {
            "accuracy": 0.3334,
            "f1": 0.3304135128499329,
            "f1_weighted": 0.330413512849933
          },
          {
            "accuracy": 0.3088,
            "f1": 0.31092859416540375,
            "f1_weighted": 0.3109285941654037
          },
          {
            "accuracy": 0.2902,
            "f1": 0.294330415114181,
            "f1_weighted": 0.294330415114181
          },
          {
            "accuracy": 0.3552,
            "f1": 0.3487542641703555,
            "f1_weighted": 0.3487542641703555
          },
          {
            "accuracy": 0.292,
            "f1": 0.2904637054000035,
            "f1_weighted": 0.2904637054000035
          },
          {
            "accuracy": 0.2892,
            "f1": 0.2914183063309105,
            "f1_weighted": 0.2914183063309105
          },
          {
            "accuracy": 0.3162,
            "f1": 0.3134020686546925,
            "f1_weighted": 0.31340206865469256
          },
          {
            "accuracy": 0.3102,
            "f1": 0.3094161198540066,
            "f1_weighted": 0.3094161198540066
          },
          {
            "accuracy": 0.3244,
            "f1": 0.31959060769691044,
            "f1_weighted": 0.3195906076969104
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}