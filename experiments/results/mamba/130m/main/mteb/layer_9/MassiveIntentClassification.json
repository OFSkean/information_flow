{
  "dataset_revision": "4672e20407010da34463acc759c162ca9734bca6",
  "evaluation_time": 51.48040795326233,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.5546065904505717,
        "f1": 0.5287120370983873,
        "f1_weighted": 0.5574207393606463,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5546065904505717,
        "scores_per_experiment": [
          {
            "accuracy": 0.5521183591123067,
            "f1": 0.547132021243237,
            "f1_weighted": 0.5560003162264582
          },
          {
            "accuracy": 0.5655682582380632,
            "f1": 0.545986147704604,
            "f1_weighted": 0.5673754969597289
          },
          {
            "accuracy": 0.5534633490248824,
            "f1": 0.5159361502436599,
            "f1_weighted": 0.5540590885285096
          },
          {
            "accuracy": 0.5837256220578345,
            "f1": 0.5481888767108667,
            "f1_weighted": 0.5872495403607331
          },
          {
            "accuracy": 0.570275722932078,
            "f1": 0.5320739336064143,
            "f1_weighted": 0.5716156630017751
          },
          {
            "accuracy": 0.5363147276395427,
            "f1": 0.5191597686812053,
            "f1_weighted": 0.5419687784706617
          },
          {
            "accuracy": 0.5443846671149967,
            "f1": 0.5221418978464484,
            "f1_weighted": 0.5474269766835513
          },
          {
            "accuracy": 0.5326160053799597,
            "f1": 0.5038256633634857,
            "f1_weighted": 0.5393659637558255
          },
          {
            "accuracy": 0.5578345662407532,
            "f1": 0.5311452334204528,
            "f1_weighted": 0.5601214762384524
          },
          {
            "accuracy": 0.5497646267652992,
            "f1": 0.5215306781634997,
            "f1_weighted": 0.5490240933807676
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.5629611411706836,
        "f1": 0.534946894593574,
        "f1_weighted": 0.5657892456047675,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5629611411706836,
        "scores_per_experiment": [
          {
            "accuracy": 0.5494343334972946,
            "f1": 0.5292443009052715,
            "f1_weighted": 0.5490443981051646
          },
          {
            "accuracy": 0.5710772257747172,
            "f1": 0.5467039673880643,
            "f1_weighted": 0.5774341533799505
          },
          {
            "accuracy": 0.5740285292670929,
            "f1": 0.5487791209469595,
            "f1_weighted": 0.5756148100662086
          },
          {
            "accuracy": 0.5774717166748647,
            "f1": 0.5393424150916932,
            "f1_weighted": 0.5787357489333859
          },
          {
            "accuracy": 0.5769798327594687,
            "f1": 0.5443432759284667,
            "f1_weighted": 0.5784762491890487
          },
          {
            "accuracy": 0.5489424495818986,
            "f1": 0.5298181315839898,
            "f1_weighted": 0.5540020557733067
          },
          {
            "accuracy": 0.529758976881456,
            "f1": 0.5126499337583815,
            "f1_weighted": 0.5301936074516648
          },
          {
            "accuracy": 0.5504181013280866,
            "f1": 0.5175939921998313,
            "f1_weighted": 0.5547077982202316
          },
          {
            "accuracy": 0.5641908509591737,
            "f1": 0.5404581225007244,
            "f1_weighted": 0.5715518287917315
          },
          {
            "accuracy": 0.5873093949827841,
            "f1": 0.5405356856323587,
            "f1_weighted": 0.5881318061369817
          }
        ]
      }
    ]
  },
  "task_name": "MassiveIntentClassification"
}