{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 37.467312812805176,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.7937072503419973,
        "f1": 0.787488514207939,
        "f1_weighted": 0.7945069876718261,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7937072503419973,
        "scores_per_experiment": [
          {
            "accuracy": 0.7416780665754674,
            "f1": 0.7339696384375164,
            "f1_weighted": 0.7395431019843314
          },
          {
            "accuracy": 0.8203374373005016,
            "f1": 0.8195638331328117,
            "f1_weighted": 0.822100370979003
          },
          {
            "accuracy": 0.7886456908344733,
            "f1": 0.7767398133218422,
            "f1_weighted": 0.7909811703881007
          },
          {
            "accuracy": 0.8093935248518012,
            "f1": 0.7970071786040265,
            "f1_weighted": 0.8107193091724375
          },
          {
            "accuracy": 0.8283173734610123,
            "f1": 0.8206176225987889,
            "f1_weighted": 0.829430503373891
          },
          {
            "accuracy": 0.7913816689466484,
            "f1": 0.7856313830897034,
            "f1_weighted": 0.7923332307850447
          },
          {
            "accuracy": 0.7808937528499772,
            "f1": 0.7774957620238848,
            "f1_weighted": 0.7789324140486739
          },
          {
            "accuracy": 0.7795257637938896,
            "f1": 0.774924238872082,
            "f1_weighted": 0.7822738395854116
          },
          {
            "accuracy": 0.7998176014591883,
            "f1": 0.7978021165212724,
            "f1_weighted": 0.8010533967607832
          },
          {
            "accuracy": 0.7970816233470133,
            "f1": 0.7911335554774618,
            "f1_weighted": 0.797702539640585
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7859060402684563,
        "f1": 0.7823688791089787,
        "f1_weighted": 0.7862439277850726,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7859060402684563,
        "scores_per_experiment": [
          {
            "accuracy": 0.7328859060402685,
            "f1": 0.7319611358915235,
            "f1_weighted": 0.7287357826977132
          },
          {
            "accuracy": 0.8098434004474273,
            "f1": 0.8116789132060188,
            "f1_weighted": 0.8111285946562702
          },
          {
            "accuracy": 0.7807606263982103,
            "f1": 0.773352185674746,
            "f1_weighted": 0.7819188122572487
          },
          {
            "accuracy": 0.8232662192393736,
            "f1": 0.8171618735865905,
            "f1_weighted": 0.8244025803350186
          },
          {
            "accuracy": 0.8196868008948546,
            "f1": 0.8170081578041785,
            "f1_weighted": 0.8207274715392081
          },
          {
            "accuracy": 0.7789709172259508,
            "f1": 0.7741974847240239,
            "f1_weighted": 0.7789433362874194
          },
          {
            "accuracy": 0.7798657718120805,
            "f1": 0.7743956867222359,
            "f1_weighted": 0.7787378012002888
          },
          {
            "accuracy": 0.7615212527964206,
            "f1": 0.7588560169582408,
            "f1_weighted": 0.7645239167496799
          },
          {
            "accuracy": 0.7914988814317674,
            "f1": 0.7883788437540759,
            "f1_weighted": 0.792080191830178
          },
          {
            "accuracy": 0.7807606263982103,
            "f1": 0.7766984927681523,
            "f1_weighted": 0.781240790297701
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}