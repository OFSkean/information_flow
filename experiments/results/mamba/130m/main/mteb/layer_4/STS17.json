{
  "dataset_revision": "faeb762787bd10488a50c8b5be4a3b82e411949c",
  "evaluation_time": 17.637706518173218,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "cosine_pearson": 0.053569967757028616,
        "cosine_spearman": 0.015323444004925033,
        "euclidean_pearson": 0.04146679691217907,
        "euclidean_spearman": -0.014511908874609007,
        "hf_subset": "es-en",
        "languages": [
          "spa-Latn",
          "eng-Latn"
        ],
        "main_score": 0.015323444004925033,
        "manhattan_pearson": -0.027709976460388336,
        "manhattan_spearman": -0.10310302027960046,
        "pearson": 0.053569967757028616,
        "spearman": 0.015323444004925033
      },
      {
        "cosine_pearson": -0.06657874370478548,
        "cosine_spearman": -0.05329806313179357,
        "euclidean_pearson": -0.13277890410908774,
        "euclidean_spearman": -0.16074178900884456,
        "hf_subset": "en-ar",
        "languages": [
          "eng-Latn",
          "ara-Arab"
        ],
        "main_score": -0.05329806313179357,
        "manhattan_pearson": -0.19962293292586336,
        "manhattan_spearman": -0.21739104190489114,
        "pearson": -0.06657874370478548,
        "spearman": -0.05329806313179357
      },
      {
        "cosine_pearson": 0.06398774907791446,
        "cosine_spearman": 0.06501952342449965,
        "euclidean_pearson": 0.06893959794811562,
        "euclidean_spearman": 0.05897258127955589,
        "hf_subset": "it-en",
        "languages": [
          "ita-Latn",
          "eng-Latn"
        ],
        "main_score": 0.06501952342449965,
        "manhattan_pearson": -0.07543766031255655,
        "manhattan_spearman": -0.0708004631561003,
        "pearson": 0.06398774907791446,
        "spearman": 0.06501952342449965
      },
      {
        "cosine_pearson": 0.4902074505157522,
        "cosine_spearman": 0.5686308988657246,
        "euclidean_pearson": 0.5655032327706188,
        "euclidean_spearman": 0.6009617239834495,
        "hf_subset": "en-en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5686308988657246,
        "manhattan_pearson": 0.5958737671214613,
        "manhattan_spearman": 0.6284626064369306,
        "pearson": 0.4902074505157522,
        "spearman": 0.5686308988657246
      },
      {
        "cosine_pearson": 0.11440915154776213,
        "cosine_spearman": 0.15434293282151884,
        "euclidean_pearson": 0.09398299325536114,
        "euclidean_spearman": 0.1252502346157205,
        "hf_subset": "nl-en",
        "languages": [
          "nld-Latn",
          "eng-Latn"
        ],
        "main_score": 0.15434293282151884,
        "manhattan_pearson": -0.04765043808549595,
        "manhattan_spearman": -0.027794177021950566,
        "pearson": 0.11440915154776213,
        "spearman": 0.15434293282151884
      },
      {
        "cosine_pearson": 0.03512234439334262,
        "cosine_spearman": 0.01386326161448078,
        "euclidean_pearson": -0.03449244480487501,
        "euclidean_spearman": -0.05039208146648395,
        "hf_subset": "en-de",
        "languages": [
          "eng-Latn",
          "deu-Latn"
        ],
        "main_score": 0.01386326161448078,
        "manhattan_pearson": -0.0368249400919598,
        "manhattan_spearman": -0.04471031604506039,
        "pearson": 0.03512234439334262,
        "spearman": 0.01386326161448078
      },
      {
        "cosine_pearson": -0.04146254400135298,
        "cosine_spearman": -0.027054982454235425,
        "euclidean_pearson": -0.00815464550773904,
        "euclidean_spearman": 0.020042051776442905,
        "hf_subset": "fr-en",
        "languages": [
          "fra-Latn",
          "eng-Latn"
        ],
        "main_score": -0.027054982454235425,
        "manhattan_pearson": -0.09828072826730991,
        "manhattan_spearman": -0.08885364717728675,
        "pearson": -0.04146254400135298,
        "spearman": -0.027054982454235425
      },
      {
        "cosine_pearson": -0.006262428818091338,
        "cosine_spearman": 0.0030403952752644835,
        "euclidean_pearson": -0.09158035608007106,
        "euclidean_spearman": -0.09593585127098139,
        "hf_subset": "en-tr",
        "languages": [
          "eng-Latn",
          "tur-Latn"
        ],
        "main_score": 0.0030403952752644835,
        "manhattan_pearson": -0.12884348179902202,
        "manhattan_spearman": -0.11449079770238496,
        "pearson": -0.006262428818091338,
        "spearman": 0.0030403952752644835
      }
    ]
  },
  "task_name": "STS17"
}