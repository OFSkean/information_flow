{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 25.875484466552734,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.7969676242590059,
        "f1": 0.791122740396501,
        "f1_weighted": 0.7998207349226918,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7969676242590059,
        "scores_per_experiment": [
          {
            "accuracy": 0.7585499316005472,
            "f1": 0.7512323221923711,
            "f1_weighted": 0.7605971087588871
          },
          {
            "accuracy": 0.8166894664842681,
            "f1": 0.8150054433289408,
            "f1_weighted": 0.8201773224022688
          },
          {
            "accuracy": 0.7991336069311445,
            "f1": 0.7869503653995433,
            "f1_weighted": 0.8021457549361716
          },
          {
            "accuracy": 0.8178294573643411,
            "f1": 0.8127894880176353,
            "f1_weighted": 0.8223539666213281
          },
          {
            "accuracy": 0.8260373917008664,
            "f1": 0.8181229422588412,
            "f1_weighted": 0.8298918653450298
          },
          {
            "accuracy": 0.7918376652986776,
            "f1": 0.7864540220131736,
            "f1_weighted": 0.7944625113027497
          },
          {
            "accuracy": 0.7749658002735978,
            "f1": 0.7704609732949393,
            "f1_weighted": 0.7742306315818434
          },
          {
            "accuracy": 0.7745098039215687,
            "f1": 0.7728571688228709,
            "f1_weighted": 0.7794158932084455
          },
          {
            "accuracy": 0.8020975832193342,
            "f1": 0.7994839135389888,
            "f1_weighted": 0.8060187272996064
          },
          {
            "accuracy": 0.8080255357957137,
            "f1": 0.7978707650977054,
            "f1_weighted": 0.8089135677705879
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7914988814317674,
        "f1": 0.7887186700606806,
        "f1_weighted": 0.7937245872021327,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7914988814317674,
        "scores_per_experiment": [
          {
            "accuracy": 0.7472035794183445,
            "f1": 0.7438024481385509,
            "f1_weighted": 0.7473488289622366
          },
          {
            "accuracy": 0.8049217002237137,
            "f1": 0.8056764470331289,
            "f1_weighted": 0.8077555764348577
          },
          {
            "accuracy": 0.7968680089485458,
            "f1": 0.7903432127709425,
            "f1_weighted": 0.8000071937584526
          },
          {
            "accuracy": 0.825503355704698,
            "f1": 0.8234084849066883,
            "f1_weighted": 0.8292530951117656
          },
          {
            "accuracy": 0.8228187919463087,
            "f1": 0.8206296568976015,
            "f1_weighted": 0.8264642376943868
          },
          {
            "accuracy": 0.78165548098434,
            "f1": 0.7819486978555775,
            "f1_weighted": 0.783912517240516
          },
          {
            "accuracy": 0.7727069351230426,
            "f1": 0.7679249260631852,
            "f1_weighted": 0.7720551575448957
          },
          {
            "accuracy": 0.7606263982102909,
            "f1": 0.763398758122558,
            "f1_weighted": 0.7650808564161459
          },
          {
            "accuracy": 0.7950782997762863,
            "f1": 0.7904070542045638,
            "f1_weighted": 0.7972193349419677
          },
          {
            "accuracy": 0.8076062639821029,
            "f1": 0.7996470146140102,
            "f1_weighted": 0.8081490739161031
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}