{
  "dataset_revision": "4672e20407010da34463acc759c162ca9734bca6",
  "evaluation_time": 48.82743978500366,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.5575319435104236,
        "f1": 0.5312090434997292,
        "f1_weighted": 0.5596800032251903,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5575319435104236,
        "scores_per_experiment": [
          {
            "accuracy": 0.5551445864156019,
            "f1": 0.5483147099375613,
            "f1_weighted": 0.5585180296456682
          },
          {
            "accuracy": 0.5581708137188971,
            "f1": 0.5406065898617819,
            "f1_weighted": 0.560378526979291
          },
          {
            "accuracy": 0.5527908540685945,
            "f1": 0.5187553395546034,
            "f1_weighted": 0.551936749773692
          },
          {
            "accuracy": 0.5830531271015468,
            "f1": 0.5486566020754743,
            "f1_weighted": 0.5854786298550023
          },
          {
            "accuracy": 0.5716207128446537,
            "f1": 0.532102431092098,
            "f1_weighted": 0.5713744888046819
          },
          {
            "accuracy": 0.5342972427706792,
            "f1": 0.5160698508587349,
            "f1_weighted": 0.5399234822669167
          },
          {
            "accuracy": 0.543039677202421,
            "f1": 0.5240803562016143,
            "f1_weighted": 0.5427804226140314
          },
          {
            "accuracy": 0.543039677202421,
            "f1": 0.5120314880565328,
            "f1_weighted": 0.5497358745134121
          },
          {
            "accuracy": 0.5689307330195024,
            "f1": 0.5385476166099544,
            "f1_weighted": 0.5704113764467503
          },
          {
            "accuracy": 0.5652320107599192,
            "f1": 0.5329254507489366,
            "f1_weighted": 0.5662624513524568
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.5653221839645843,
        "f1": 0.537290207751146,
        "f1_weighted": 0.5676026740499596,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5653221839645843,
        "scores_per_experiment": [
          {
            "accuracy": 0.5494343334972946,
            "f1": 0.5324628409492658,
            "f1_weighted": 0.5492046572026417
          },
          {
            "accuracy": 0.5745204131824889,
            "f1": 0.5459944129318848,
            "f1_weighted": 0.5802704363472619
          },
          {
            "accuracy": 0.5804230201672406,
            "f1": 0.5518540671000138,
            "f1_weighted": 0.5827241379887174
          },
          {
            "accuracy": 0.5814067879980325,
            "f1": 0.5414468771926264,
            "f1_weighted": 0.5816479959854421
          },
          {
            "accuracy": 0.5779636005902608,
            "f1": 0.5518107744188432,
            "f1_weighted": 0.5780799625475502
          },
          {
            "accuracy": 0.543531726512543,
            "f1": 0.5262570708722872,
            "f1_weighted": 0.5489731695207911
          },
          {
            "accuracy": 0.5327102803738317,
            "f1": 0.5143468375394767,
            "f1_weighted": 0.5334892862908049
          },
          {
            "accuracy": 0.5577963600590261,
            "f1": 0.5241494997799924,
            "f1_weighted": 0.562565300036592
          },
          {
            "accuracy": 0.5656665027053616,
            "f1": 0.5418288149501365,
            "f1_weighted": 0.5705954941079378
          },
          {
            "accuracy": 0.5897688145597639,
            "f1": 0.5427508817769338,
            "f1_weighted": 0.588476300471857
          }
        ]
      }
    ]
  },
  "task_name": "MassiveIntentClassification"
}