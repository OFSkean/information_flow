{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 34.69782590866089,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.7983356133150934,
        "f1": 0.7919226431428498,
        "f1_weighted": 0.7993803685040979,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7983356133150934,
        "scores_per_experiment": [
          {
            "accuracy": 0.736890104879161,
            "f1": 0.730866445249324,
            "f1_weighted": 0.7365645990120985
          },
          {
            "accuracy": 0.8299133606931145,
            "f1": 0.8272590010652273,
            "f1_weighted": 0.8314644418602183
          },
          {
            "accuracy": 0.7875056999544003,
            "f1": 0.776545323476779,
            "f1_weighted": 0.789539657408061
          },
          {
            "accuracy": 0.8164614683082535,
            "f1": 0.8064204396027886,
            "f1_weighted": 0.8182369283608472
          },
          {
            "accuracy": 0.8381212950296397,
            "f1": 0.8283924199330489,
            "f1_weighted": 0.8384786207057281
          },
          {
            "accuracy": 0.7966256269949841,
            "f1": 0.7900477381811961,
            "f1_weighted": 0.7984071868471682
          },
          {
            "accuracy": 0.7829457364341085,
            "f1": 0.7775033892773764,
            "f1_weighted": 0.7803805282091605
          },
          {
            "accuracy": 0.7836297309621523,
            "f1": 0.7795863758607543,
            "f1_weighted": 0.7868721769894701
          },
          {
            "accuracy": 0.8068855449156407,
            "f1": 0.8034969672219908,
            "f1_weighted": 0.807746167308085
          },
          {
            "accuracy": 0.8043775649794802,
            "f1": 0.7991083315600125,
            "f1_weighted": 0.8061133783401425
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7940492170022371,
        "f1": 0.7901673530725486,
        "f1_weighted": 0.7948000388948686,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7940492170022371,
        "scores_per_experiment": [
          {
            "accuracy": 0.7319910514541387,
            "f1": 0.7302162178485474,
            "f1_weighted": 0.730193012954726
          },
          {
            "accuracy": 0.8223713646532439,
            "f1": 0.8223482825067648,
            "f1_weighted": 0.8242596344698541
          },
          {
            "accuracy": 0.7861297539149888,
            "f1": 0.779421633218326,
            "f1_weighted": 0.7869322434338991
          },
          {
            "accuracy": 0.8201342281879195,
            "f1": 0.8161202923393673,
            "f1_weighted": 0.8221786495656347
          },
          {
            "accuracy": 0.8308724832214766,
            "f1": 0.8263450800373356,
            "f1_weighted": 0.8313940910508398
          },
          {
            "accuracy": 0.7955257270693512,
            "f1": 0.7907283446119845,
            "f1_weighted": 0.7961994632944617
          },
          {
            "accuracy": 0.7865771812080536,
            "f1": 0.7803201192391067,
            "f1_weighted": 0.7850986551558784
          },
          {
            "accuracy": 0.7736017897091723,
            "f1": 0.771045957922389,
            "f1_weighted": 0.7770969156660161
          },
          {
            "accuracy": 0.8040268456375839,
            "f1": 0.8001086465365937,
            "f1_weighted": 0.8039968659384658
          },
          {
            "accuracy": 0.789261744966443,
            "f1": 0.7850189564650715,
            "f1_weighted": 0.790650857418911
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}