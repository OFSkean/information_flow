{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 22.415222644805908,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.7880756953944369,
        "f1": 0.7814584160900553,
        "f1_weighted": 0.7906626381273187,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7880756953944369,
        "scores_per_experiment": [
          {
            "accuracy": 0.758093935248518,
            "f1": 0.7491879136642798,
            "f1_weighted": 0.7581750099020866
          },
          {
            "accuracy": 0.7897856817145463,
            "f1": 0.7879998124160956,
            "f1_weighted": 0.7935758809681583
          },
          {
            "accuracy": 0.782717738258094,
            "f1": 0.7693176738206357,
            "f1_weighted": 0.7849224107940614
          },
          {
            "accuracy": 0.8096215230278158,
            "f1": 0.8032768835805044,
            "f1_weighted": 0.8123561526900729
          },
          {
            "accuracy": 0.8157774737802097,
            "f1": 0.8068966797118786,
            "f1_weighted": 0.8203696507286682
          },
          {
            "accuracy": 0.7906976744186046,
            "f1": 0.7888965161762084,
            "f1_weighted": 0.7929249251319259
          },
          {
            "accuracy": 0.7740538075695395,
            "f1": 0.7667600088633809,
            "f1_weighted": 0.7730724302244218
          },
          {
            "accuracy": 0.7621979024167806,
            "f1": 0.7579163280856419,
            "f1_weighted": 0.7690350843559552
          },
          {
            "accuracy": 0.8050615595075239,
            "f1": 0.802804705772182,
            "f1_weighted": 0.8089332825604294
          },
          {
            "accuracy": 0.792749658002736,
            "f1": 0.7815276388097453,
            "f1_weighted": 0.7932615539174083
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7792841163310962,
        "f1": 0.7763371744775202,
        "f1_weighted": 0.7813099268909652,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7792841163310962,
        "scores_per_experiment": [
          {
            "accuracy": 0.7413870246085011,
            "f1": 0.7387475576534827,
            "f1_weighted": 0.7385238177694988
          },
          {
            "accuracy": 0.7865771812080536,
            "f1": 0.7876490817512306,
            "f1_weighted": 0.7891200933660981
          },
          {
            "accuracy": 0.7785234899328859,
            "f1": 0.7704144753453527,
            "f1_weighted": 0.7805840857558121
          },
          {
            "accuracy": 0.8040268456375839,
            "f1": 0.8035660585487513,
            "f1_weighted": 0.806706112888471
          },
          {
            "accuracy": 0.8093959731543624,
            "f1": 0.8057375345768264,
            "f1_weighted": 0.8146930928460584
          },
          {
            "accuracy": 0.7843400447427293,
            "f1": 0.785618385468894,
            "f1_weighted": 0.786847483125254
          },
          {
            "accuracy": 0.7534675615212528,
            "f1": 0.7465720409194971,
            "f1_weighted": 0.7529254740417708
          },
          {
            "accuracy": 0.7579418344519016,
            "f1": 0.757096312972045,
            "f1_weighted": 0.7629797429493241
          },
          {
            "accuracy": 0.8022371364653244,
            "f1": 0.8007589677503545,
            "f1_weighted": 0.8045838068137392
          },
          {
            "accuracy": 0.7749440715883669,
            "f1": 0.7672113297887676,
            "f1_weighted": 0.7761355593536245
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}