{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 111.55092144012451,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.3003,
        "f1": 0.29842411546214515,
        "f1_weighted": 0.29842411546214526,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.3003,
        "scores_per_experiment": [
          {
            "accuracy": 0.3338,
            "f1": 0.33446869000085305,
            "f1_weighted": 0.33446869000085305
          },
          {
            "accuracy": 0.3162,
            "f1": 0.31438041237654923,
            "f1_weighted": 0.31438041237654923
          },
          {
            "accuracy": 0.2838,
            "f1": 0.28547128332219207,
            "f1_weighted": 0.28547128332219207
          },
          {
            "accuracy": 0.2838,
            "f1": 0.28788260054312265,
            "f1_weighted": 0.2878826005431226
          },
          {
            "accuracy": 0.339,
            "f1": 0.3299673532146049,
            "f1_weighted": 0.3299673532146049
          },
          {
            "accuracy": 0.2646,
            "f1": 0.2606805050588276,
            "f1_weighted": 0.26068050505882767
          },
          {
            "accuracy": 0.2578,
            "f1": 0.2572923260330051,
            "f1_weighted": 0.25729232603300517
          },
          {
            "accuracy": 0.3158,
            "f1": 0.3114462260234384,
            "f1_weighted": 0.3114462260234384
          },
          {
            "accuracy": 0.2972,
            "f1": 0.29763833547781443,
            "f1_weighted": 0.29763833547781443
          },
          {
            "accuracy": 0.311,
            "f1": 0.30501342257104436,
            "f1_weighted": 0.30501342257104436
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.29952,
        "f1": 0.29733936184368226,
        "f1_weighted": 0.29733936184368226,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.29952,
        "scores_per_experiment": [
          {
            "accuracy": 0.32,
            "f1": 0.3198912098599204,
            "f1_weighted": 0.3198912098599204
          },
          {
            "accuracy": 0.3226,
            "f1": 0.323637975753566,
            "f1_weighted": 0.323637975753566
          },
          {
            "accuracy": 0.2934,
            "f1": 0.2944368460362238,
            "f1_weighted": 0.2944368460362237
          },
          {
            "accuracy": 0.275,
            "f1": 0.27896680075769215,
            "f1_weighted": 0.27896680075769215
          },
          {
            "accuracy": 0.3462,
            "f1": 0.3361691018792718,
            "f1_weighted": 0.33616910187927185
          },
          {
            "accuracy": 0.2606,
            "f1": 0.25487431092941143,
            "f1_weighted": 0.2548743109294115
          },
          {
            "accuracy": 0.266,
            "f1": 0.2639644877301339,
            "f1_weighted": 0.2639644877301339
          },
          {
            "accuracy": 0.2988,
            "f1": 0.2935882948888961,
            "f1_weighted": 0.29358829488889604
          },
          {
            "accuracy": 0.2906,
            "f1": 0.2905336304381936,
            "f1_weighted": 0.2905336304381936
          },
          {
            "accuracy": 0.322,
            "f1": 0.31733096016351336,
            "f1_weighted": 0.3173309601635133
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}