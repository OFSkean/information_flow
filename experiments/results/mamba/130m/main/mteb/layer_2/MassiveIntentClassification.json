{
  "dataset_revision": "4672e20407010da34463acc759c162ca9734bca6",
  "evaluation_time": 35.811049938201904,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.5714525891055817,
        "f1": 0.5505642144584695,
        "f1_weighted": 0.5733612197293162,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5714525891055817,
        "scores_per_experiment": [
          {
            "accuracy": 0.5699394754539341,
            "f1": 0.5521949692777526,
            "f1_weighted": 0.5704308528868786
          },
          {
            "accuracy": 0.5894418291862811,
            "f1": 0.5676221844091025,
            "f1_weighted": 0.5912530058520868
          },
          {
            "accuracy": 0.5817081371889711,
            "f1": 0.5494584523974919,
            "f1_weighted": 0.5784376823063384
          },
          {
            "accuracy": 0.5840618695359785,
            "f1": 0.5469167569072346,
            "f1_weighted": 0.585487612894297
          },
          {
            "accuracy": 0.5817081371889711,
            "f1": 0.5556386846893262,
            "f1_weighted": 0.5841144912483401
          },
          {
            "accuracy": 0.547074646940148,
            "f1": 0.5401844698952986,
            "f1_weighted": 0.5512957561202533
          },
          {
            "accuracy": 0.5544720914593141,
            "f1": 0.5418053751130713,
            "f1_weighted": 0.5586251787968399
          },
          {
            "accuracy": 0.5581708137188971,
            "f1": 0.5370430915191737,
            "f1_weighted": 0.5614865725998767
          },
          {
            "accuracy": 0.5648957632817754,
            "f1": 0.5524136498326147,
            "f1_weighted": 0.5673203734178042
          },
          {
            "accuracy": 0.5830531271015468,
            "f1": 0.5623645105436289,
            "f1_weighted": 0.5851606711704478
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.5793408755533694,
        "f1": 0.5597799824202555,
        "f1_weighted": 0.5794980244965199,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5793408755533694,
        "scores_per_experiment": [
          {
            "accuracy": 0.5696015740285293,
            "f1": 0.5539669995530629,
            "f1_weighted": 0.5654013677353825
          },
          {
            "accuracy": 0.5937038858829317,
            "f1": 0.5777685879339557,
            "f1_weighted": 0.5952324769827414
          },
          {
            "accuracy": 0.5927201180521396,
            "f1": 0.5725283219966972,
            "f1_weighted": 0.5925069042537361
          },
          {
            "accuracy": 0.5892769306443679,
            "f1": 0.5549967992468511,
            "f1_weighted": 0.5892444223985214
          },
          {
            "accuracy": 0.5966551893753075,
            "f1": 0.5758737327629222,
            "f1_weighted": 0.5972299124524169
          },
          {
            "accuracy": 0.5764879488440728,
            "f1": 0.5691581044704738,
            "f1_weighted": 0.581271494406744
          },
          {
            "accuracy": 0.5499262174126907,
            "f1": 0.5447827666893249,
            "f1_weighted": 0.5512059898520307
          },
          {
            "accuracy": 0.5568125922282341,
            "f1": 0.5183268492500049,
            "f1_weighted": 0.5527901007203551
          },
          {
            "accuracy": 0.5700934579439252,
            "f1": 0.5527109354922861,
            "f1_weighted": 0.5715988460042151
          },
          {
            "accuracy": 0.5981308411214953,
            "f1": 0.5776867268069772,
            "f1_weighted": 0.5984987301590559
          }
        ]
      }
    ]
  },
  "task_name": "MassiveIntentClassification"
}