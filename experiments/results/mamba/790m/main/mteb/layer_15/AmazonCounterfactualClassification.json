{
  "dataset_revision": "e8379541af4e31359cca9fbcf4b00f2671dba205",
  "evaluation_time": 48.94262170791626,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.20",
  "scores": {
    "test": [
      {
        "accuracy": 0.7667166416791604,
        "ap": 0.238749210727739,
        "ap_weighted": 0.238749210727739,
        "f1": 0.6315898659755581,
        "f1_weighted": 0.8078946694957312,
        "hf_subset": "en-ext",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7667166416791604,
        "scores_per_experiment": [
          {
            "accuracy": 0.8260869565217391,
            "ap": 0.2822498545967746,
            "ap_weighted": 0.2822498545967746,
            "f1": 0.6831418801318673,
            "f1_weighted": 0.8516128630199306
          },
          {
            "accuracy": 0.7481259370314842,
            "ap": 0.22237707464186676,
            "ap_weighted": 0.22237707464186676,
            "f1": 0.6141853739154386,
            "f1_weighted": 0.7941360541324158
          },
          {
            "accuracy": 0.7946026986506747,
            "ap": 0.26695141131430433,
            "ap_weighted": 0.26695141131430433,
            "f1": 0.6596545854764999,
            "f1_weighted": 0.8293036420383196
          },
          {
            "accuracy": 0.7833583208395802,
            "ap": 0.23260222406782222,
            "ap_weighted": 0.23260222406782222,
            "f1": 0.6370314090234214,
            "f1_weighted": 0.8194649614175934
          },
          {
            "accuracy": 0.7271364317841079,
            "ap": 0.22123009011909422,
            "ap_weighted": 0.22123009011909422,
            "f1": 0.6029761904761906,
            "f1_weighted": 0.7787311701292213
          },
          {
            "accuracy": 0.7353823088455772,
            "ap": 0.22827050340101374,
            "ap_weighted": 0.22827050340101374,
            "f1": 0.6106738893008943,
            "f1_weighted": 0.7851004999488217
          },
          {
            "accuracy": 0.7346326836581709,
            "ap": 0.21598545698725824,
            "ap_weighted": 0.21598545698725824,
            "f1": 0.6040945674044265,
            "f1_weighted": 0.7840531193155937
          },
          {
            "accuracy": 0.8133433283358321,
            "ap": 0.27093169174880455,
            "ap_weighted": 0.27093169174880455,
            "f1": 0.6712617536942302,
            "f1_weighted": 0.8423428743573222
          },
          {
            "accuracy": 0.7563718140929535,
            "ap": 0.24034867107593774,
            "ap_weighted": 0.24034867107593774,
            "f1": 0.6273201694100818,
            "f1_weighted": 0.8009234009834736
          },
          {
            "accuracy": 0.7481259370314842,
            "ap": 0.2065451293245134,
            "ap_weighted": 0.2065451293245134,
            "f1": 0.6055588409225311,
            "f1_weighted": 0.7932781096146191
          }
        ]
      },
      {
        "accuracy": 0.7929850746268656,
        "ap": 0.4211819217667048,
        "ap_weighted": 0.4211819217667048,
        "f1": 0.7279936940370872,
        "f1_weighted": 0.8087231854068542,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7929850746268656,
        "scores_per_experiment": [
          {
            "accuracy": 0.7611940298507462,
            "ap": 0.3841412959446779,
            "ap_weighted": 0.3841412959446779,
            "f1": 0.6982525671050261,
            "f1_weighted": 0.782174517432653
          },
          {
            "accuracy": 0.8462686567164179,
            "ap": 0.5056969523228477,
            "ap_weighted": 0.5056969523228477,
            "f1": 0.7871973011893639,
            "f1_weighted": 0.8554724089940043
          },
          {
            "accuracy": 0.7820895522388059,
            "ap": 0.39209941001926973,
            "ap_weighted": 0.39209941001926973,
            "f1": 0.7111693772218877,
            "f1_weighted": 0.7983242910981005
          },
          {
            "accuracy": 0.755223880597015,
            "ap": 0.3693977361434436,
            "ap_weighted": 0.3693977361434436,
            "f1": 0.6885487528344671,
            "f1_weighted": 0.776301824212272
          },
          {
            "accuracy": 0.7970149253731343,
            "ap": 0.41167303991760096,
            "ap_weighted": 0.41167303991760096,
            "f1": 0.7266126612661266,
            "f1_weighted": 0.8110953781945359
          },
          {
            "accuracy": 0.8029850746268656,
            "ap": 0.41907666599474735,
            "ap_weighted": 0.41907666599474735,
            "f1": 0.732457254873489,
            "f1_weighted": 0.8161065294647033
          },
          {
            "accuracy": 0.8507462686567164,
            "ap": 0.49796024170218967,
            "ap_weighted": 0.49796024170218967,
            "f1": 0.7852564102564104,
            "f1_weighted": 0.8574722541140452
          },
          {
            "accuracy": 0.8313432835820895,
            "ap": 0.4702720085854892,
            "ap_weighted": 0.4702720085854892,
            "f1": 0.7665368449941565,
            "f1_weighted": 0.8414406040419657
          },
          {
            "accuracy": 0.7597014925373134,
            "ap": 0.396272130318432,
            "ap_weighted": 0.396272130318432,
            "f1": 0.7028792098079885,
            "f1_weighted": 0.7820037536768096
          },
          {
            "accuracy": 0.7432835820895523,
            "ap": 0.36522973671834963,
            "ap_weighted": 0.36522973671834963,
            "f1": 0.6810265608219572,
            "f1_weighted": 0.7668402928394529
          }
        ]
      }
    ]
  },
  "task_name": "AmazonCounterfactualClassification"
}