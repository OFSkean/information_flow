{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 214.16443705558777,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.2847,
        "f1": 0.2640237611608326,
        "f1_weighted": 0.2640237611608326,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.2847,
        "scores_per_experiment": [
          {
            "accuracy": 0.3406,
            "f1": 0.3177137173603792,
            "f1_weighted": 0.3177137173603792
          },
          {
            "accuracy": 0.2806,
            "f1": 0.26901497901465204,
            "f1_weighted": 0.26901497901465204
          },
          {
            "accuracy": 0.2588,
            "f1": 0.2488137492220258,
            "f1_weighted": 0.24881374922202576
          },
          {
            "accuracy": 0.281,
            "f1": 0.24728630352356723,
            "f1_weighted": 0.24728630352356726
          },
          {
            "accuracy": 0.3184,
            "f1": 0.27495133979077196,
            "f1_weighted": 0.27495133979077196
          },
          {
            "accuracy": 0.2396,
            "f1": 0.2212375293208289,
            "f1_weighted": 0.22123752932082894
          },
          {
            "accuracy": 0.2502,
            "f1": 0.23907353794503275,
            "f1_weighted": 0.23907353794503278
          },
          {
            "accuracy": 0.2884,
            "f1": 0.25906867610822387,
            "f1_weighted": 0.25906867610822387
          },
          {
            "accuracy": 0.278,
            "f1": 0.2665626475069368,
            "f1_weighted": 0.2665626475069368
          },
          {
            "accuracy": 0.3114,
            "f1": 0.2965151318159075,
            "f1_weighted": 0.29651513181590755
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.27562,
        "f1": 0.24578878564269674,
        "f1_weighted": 0.24578878564269674,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.27562,
        "scores_per_experiment": [
          {
            "accuracy": 0.3306,
            "f1": 0.293974915012487,
            "f1_weighted": 0.293974915012487
          },
          {
            "accuracy": 0.2838,
            "f1": 0.25348707749400373,
            "f1_weighted": 0.2534870774940037
          },
          {
            "accuracy": 0.249,
            "f1": 0.2344583491016833,
            "f1_weighted": 0.23445834910168328
          },
          {
            "accuracy": 0.2502,
            "f1": 0.20295685964067892,
            "f1_weighted": 0.20295685964067894
          },
          {
            "accuracy": 0.311,
            "f1": 0.2571465379983608,
            "f1_weighted": 0.2571465379983608
          },
          {
            "accuracy": 0.2534,
            "f1": 0.2262027523093376,
            "f1_weighted": 0.22620275230933762
          },
          {
            "accuracy": 0.2474,
            "f1": 0.23596542312400315,
            "f1_weighted": 0.23596542312400315
          },
          {
            "accuracy": 0.266,
            "f1": 0.22859761990678695,
            "f1_weighted": 0.22859761990678698
          },
          {
            "accuracy": 0.2592,
            "f1": 0.24007362062970844,
            "f1_weighted": 0.2400736206297084
          },
          {
            "accuracy": 0.3056,
            "f1": 0.2850247012099176,
            "f1_weighted": 0.28502470120991763
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}