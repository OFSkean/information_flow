{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 29.480452299118042,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.7871637026903785,
        "f1": 0.7792718585728028,
        "f1_weighted": 0.7901600035562459,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7871637026903785,
        "scores_per_experiment": [
          {
            "accuracy": 0.761969904240766,
            "f1": 0.7513504944563608,
            "f1_weighted": 0.7626333189025422
          },
          {
            "accuracy": 0.7733698130414957,
            "f1": 0.7734563803576961,
            "f1_weighted": 0.7798113154528689
          },
          {
            "accuracy": 0.7881896944824441,
            "f1": 0.77484174953666,
            "f1_weighted": 0.7921577894054155
          },
          {
            "accuracy": 0.7891016871865025,
            "f1": 0.784175246178932,
            "f1_weighted": 0.7954759510150765
          },
          {
            "accuracy": 0.8073415412676699,
            "f1": 0.7993781726240686,
            "f1_weighted": 0.8105393048849667
          },
          {
            "accuracy": 0.7849977200182399,
            "f1": 0.7799683169729659,
            "f1_weighted": 0.7865251476259759
          },
          {
            "accuracy": 0.7886456908344733,
            "f1": 0.7789797162497986,
            "f1_weighted": 0.7871606319833918
          },
          {
            "accuracy": 0.759233926128591,
            "f1": 0.7525375425197897,
            "f1_weighted": 0.7637259995372715
          },
          {
            "accuracy": 0.8141814865481076,
            "f1": 0.8083265255304277,
            "f1_weighted": 0.8181890233371657
          },
          {
            "accuracy": 0.8046055631554948,
            "f1": 0.7897044413013277,
            "f1_weighted": 0.805381553417786
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7812527964205818,
        "f1": 0.7784148135729213,
        "f1_weighted": 0.7837758912301205,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7812527964205818,
        "scores_per_experiment": [
          {
            "accuracy": 0.7440715883668904,
            "f1": 0.7413137119764529,
            "f1_weighted": 0.7436640135558108
          },
          {
            "accuracy": 0.7691275167785235,
            "f1": 0.7722520316793172,
            "f1_weighted": 0.774612096728075
          },
          {
            "accuracy": 0.7762863534675615,
            "f1": 0.7693722948416106,
            "f1_weighted": 0.7807284177319636
          },
          {
            "accuracy": 0.7879194630872484,
            "f1": 0.7897062370798206,
            "f1_weighted": 0.7932077530311283
          },
          {
            "accuracy": 0.8049217002237137,
            "f1": 0.8021258831656262,
            "f1_weighted": 0.8081264646183083
          },
          {
            "accuracy": 0.7794183445190157,
            "f1": 0.778935654457261,
            "f1_weighted": 0.7804931881510545
          },
          {
            "accuracy": 0.7829977628635347,
            "f1": 0.7744673364570115,
            "f1_weighted": 0.7805231604945969
          },
          {
            "accuracy": 0.752572706935123,
            "f1": 0.7514920338829341,
            "f1_weighted": 0.7556169681272612
          },
          {
            "accuracy": 0.8125279642058165,
            "f1": 0.8124209319644021,
            "f1_weighted": 0.8163367662642728
          },
          {
            "accuracy": 0.8026845637583893,
            "f1": 0.792062020224776,
            "f1_weighted": 0.804450083598732
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}