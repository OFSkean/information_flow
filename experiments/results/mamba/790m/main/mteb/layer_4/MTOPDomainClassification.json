{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 36.419960260391235,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.7437300501595987,
        "f1": 0.7390632550514936,
        "f1_weighted": 0.7485338909577057,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7437300501595987,
        "scores_per_experiment": [
          {
            "accuracy": 0.7222982216142271,
            "f1": 0.7116330997220829,
            "f1_weighted": 0.7215825768401857
          },
          {
            "accuracy": 0.7302781577747378,
            "f1": 0.7344748282276187,
            "f1_weighted": 0.7393478923202776
          },
          {
            "accuracy": 0.7350661194710443,
            "f1": 0.7299779223215205,
            "f1_weighted": 0.7452109369649761
          },
          {
            "accuracy": 0.740766073871409,
            "f1": 0.7417630739583089,
            "f1_weighted": 0.7508579334193463
          },
          {
            "accuracy": 0.7731418148654811,
            "f1": 0.7682300679708259,
            "f1_weighted": 0.7786020936660634
          },
          {
            "accuracy": 0.7314181486548108,
            "f1": 0.7301770941425677,
            "f1_weighted": 0.7358898517536171
          },
          {
            "accuracy": 0.7663018695850433,
            "f1": 0.7508020913451628,
            "f1_weighted": 0.763357608062082
          },
          {
            "accuracy": 0.7154582763337893,
            "f1": 0.7154117568714633,
            "f1_weighted": 0.7178138253266945
          },
          {
            "accuracy": 0.7747378020975833,
            "f1": 0.7688777493025678,
            "f1_weighted": 0.7797977468192582
          },
          {
            "accuracy": 0.7478340173278614,
            "f1": 0.7392848666528178,
            "f1_weighted": 0.7528784444045559
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7335570469798658,
        "f1": 0.7329604462940177,
        "f1_weighted": 0.737779468726918,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7335570469798658,
        "scores_per_experiment": [
          {
            "accuracy": 0.70917225950783,
            "f1": 0.705336795159242,
            "f1_weighted": 0.7063121923333017
          },
          {
            "accuracy": 0.7261744966442953,
            "f1": 0.7344667305090286,
            "f1_weighted": 0.7355459089261752
          },
          {
            "accuracy": 0.7051454138702461,
            "f1": 0.7078022973764355,
            "f1_weighted": 0.7179706330852083
          },
          {
            "accuracy": 0.7472035794183445,
            "f1": 0.7516624747926607,
            "f1_weighted": 0.7547181310848569
          },
          {
            "accuracy": 0.7633109619686801,
            "f1": 0.764279956724469,
            "f1_weighted": 0.769541287314601
          },
          {
            "accuracy": 0.7288590604026846,
            "f1": 0.7314285394444666,
            "f1_weighted": 0.7326539207036187
          },
          {
            "accuracy": 0.7552572706935123,
            "f1": 0.7432204882135017,
            "f1_weighted": 0.7517915135022915
          },
          {
            "accuracy": 0.7064876957494407,
            "f1": 0.7057251850820226,
            "f1_weighted": 0.7067689404942138
          },
          {
            "accuracy": 0.763758389261745,
            "f1": 0.7595307139064095,
            "f1_weighted": 0.7669559301805005
          },
          {
            "accuracy": 0.7302013422818792,
            "f1": 0.726151281731941,
            "f1_weighted": 0.7355362296444132
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}