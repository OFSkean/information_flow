{
  "dataset_revision": "1399c76144fd37290681b995c656ef9b2e06e26d",
  "evaluation_time": 367.09797191619873,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.28250000000000003,
        "f1": 0.2761801794487347,
        "f1_weighted": 0.2761801794487347,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.28250000000000003,
        "scores_per_experiment": [
          {
            "accuracy": 0.3132,
            "f1": 0.3077696775019523,
            "f1_weighted": 0.3077696775019523
          },
          {
            "accuracy": 0.2854,
            "f1": 0.2837405630183333,
            "f1_weighted": 0.2837405630183333
          },
          {
            "accuracy": 0.249,
            "f1": 0.24701259493264266,
            "f1_weighted": 0.2470125949326427
          },
          {
            "accuracy": 0.2558,
            "f1": 0.2510033405345998,
            "f1_weighted": 0.2510033405345998
          },
          {
            "accuracy": 0.317,
            "f1": 0.2998364171271392,
            "f1_weighted": 0.29983641712713927
          },
          {
            "accuracy": 0.2552,
            "f1": 0.24710255158082947,
            "f1_weighted": 0.24710255158082947
          },
          {
            "accuracy": 0.2328,
            "f1": 0.2312365694645032,
            "f1_weighted": 0.2312365694645032
          },
          {
            "accuracy": 0.3156,
            "f1": 0.30356827464710195,
            "f1_weighted": 0.30356827464710195
          },
          {
            "accuracy": 0.2936,
            "f1": 0.29101231236227443,
            "f1_weighted": 0.2910123123622744
          },
          {
            "accuracy": 0.3074,
            "f1": 0.2995194933179704,
            "f1_weighted": 0.2995194933179704
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.27818000000000004,
        "f1": 0.2676769884195707,
        "f1_weighted": 0.2676769884195707,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.27818000000000004,
        "scores_per_experiment": [
          {
            "accuracy": 0.2976,
            "f1": 0.2839632454389861,
            "f1_weighted": 0.2839632454389861
          },
          {
            "accuracy": 0.2806,
            "f1": 0.2734894396532354,
            "f1_weighted": 0.27348943965323547
          },
          {
            "accuracy": 0.2446,
            "f1": 0.24117605232132638,
            "f1_weighted": 0.24117605232132636
          },
          {
            "accuracy": 0.2368,
            "f1": 0.22802715939617949,
            "f1_weighted": 0.22802715939617946
          },
          {
            "accuracy": 0.3244,
            "f1": 0.29839596545609154,
            "f1_weighted": 0.2983959654560915
          },
          {
            "accuracy": 0.263,
            "f1": 0.25190330724019316,
            "f1_weighted": 0.25190330724019316
          },
          {
            "accuracy": 0.2324,
            "f1": 0.22841454845736903,
            "f1_weighted": 0.22841454845736903
          },
          {
            "accuracy": 0.3074,
            "f1": 0.29286941591081633,
            "f1_weighted": 0.29286941591081633
          },
          {
            "accuracy": 0.276,
            "f1": 0.2681136046548976,
            "f1_weighted": 0.2681136046548976
          },
          {
            "accuracy": 0.319,
            "f1": 0.3104171456666118,
            "f1_weighted": 0.3104171456666118
          }
        ]
      }
    ]
  },
  "task_name": "AmazonReviewsClassification"
}