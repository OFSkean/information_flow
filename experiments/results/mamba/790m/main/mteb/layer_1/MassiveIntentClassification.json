{
  "dataset_revision": "4672e20407010da34463acc759c162ca9734bca6",
  "evaluation_time": 44.41461682319641,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.5641896435776732,
        "f1": 0.5468229432199518,
        "f1_weighted": 0.5681494801584888,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5641896435776732,
        "scores_per_experiment": [
          {
            "accuracy": 0.5722932078009415,
            "f1": 0.5574079830712575,
            "f1_weighted": 0.5752795481097025
          },
          {
            "accuracy": 0.5766644250168124,
            "f1": 0.5518287946239047,
            "f1_weighted": 0.5813882036530972
          },
          {
            "accuracy": 0.5615332885003362,
            "f1": 0.5429251349973027,
            "f1_weighted": 0.5608987661835855
          },
          {
            "accuracy": 0.574310692669805,
            "f1": 0.5502423833678488,
            "f1_weighted": 0.5799731993807868
          },
          {
            "accuracy": 0.570275722932078,
            "f1": 0.5412284685135637,
            "f1_weighted": 0.5732708703261871
          },
          {
            "accuracy": 0.5386684599865501,
            "f1": 0.5324023511365985,
            "f1_weighted": 0.5467721042119015
          },
          {
            "accuracy": 0.5551445864156019,
            "f1": 0.545270247251403,
            "f1_weighted": 0.5598414162128897
          },
          {
            "accuracy": 0.554808338937458,
            "f1": 0.5390709607879991,
            "f1_weighted": 0.557418178447286
          },
          {
            "accuracy": 0.5635507733691997,
            "f1": 0.5519412447961042,
            "f1_weighted": 0.5642846337854166
          },
          {
            "accuracy": 0.5746469401479489,
            "f1": 0.5559118636535366,
            "f1_weighted": 0.5823678812740346
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.5740285292670928,
        "f1": 0.5600949539493632,
        "f1_weighted": 0.5761129080237744,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.5740285292670928,
        "scores_per_experiment": [
          {
            "accuracy": 0.5636989670437776,
            "f1": 0.5685412282177797,
            "f1_weighted": 0.5631048939308134
          },
          {
            "accuracy": 0.5873093949827841,
            "f1": 0.5561189154362363,
            "f1_weighted": 0.5906085028130249
          },
          {
            "accuracy": 0.5902606984751598,
            "f1": 0.5725486555771094,
            "f1_weighted": 0.5890624837091202
          },
          {
            "accuracy": 0.5814067879980325,
            "f1": 0.5583619587211809,
            "f1_weighted": 0.5815233584213488
          },
          {
            "accuracy": 0.5932120019675357,
            "f1": 0.5785369966730645,
            "f1_weighted": 0.5951557542890985
          },
          {
            "accuracy": 0.5568125922282341,
            "f1": 0.5507225155024085,
            "f1_weighted": 0.56479627526583
          },
          {
            "accuracy": 0.5459911460895229,
            "f1": 0.5468965145953867,
            "f1_weighted": 0.5473820379672912
          },
          {
            "accuracy": 0.5543531726512543,
            "f1": 0.52772176725253,
            "f1_weighted": 0.5521592994411012
          },
          {
            "accuracy": 0.5740285292670929,
            "f1": 0.5668865723989353,
            "f1_weighted": 0.5786222757288486
          },
          {
            "accuracy": 0.5932120019675357,
            "f1": 0.5746144151190007,
            "f1_weighted": 0.5987141986712673
          }
        ]
      }
    ]
  },
  "task_name": "MassiveIntentClassification"
}