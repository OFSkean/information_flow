{
  "dataset_revision": "d80d48c1eb48d3562165c59d59d0034df9fff0bf",
  "evaluation_time": 27.984859943389893,
  "kg_co2_emissions": null,
  "mteb_version": "1.14.19",
  "scores": {
    "test": [
      {
        "accuracy": 0.7823301413588691,
        "f1": 0.7756946122336977,
        "f1_weighted": 0.7853763071018844,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7823301413588691,
        "scores_per_experiment": [
          {
            "accuracy": 0.7514819881440948,
            "f1": 0.7434699569697912,
            "f1_weighted": 0.7523760799146147
          },
          {
            "accuracy": 0.7781577747378021,
            "f1": 0.7784098039159296,
            "f1_weighted": 0.7836726526851477
          },
          {
            "accuracy": 0.7950296397628819,
            "f1": 0.7805652012938243,
            "f1_weighted": 0.7961516339020624
          },
          {
            "accuracy": 0.7831737346101231,
            "f1": 0.7801822295647661,
            "f1_weighted": 0.7860380310756455
          },
          {
            "accuracy": 0.8187414500683995,
            "f1": 0.8093386474360439,
            "f1_weighted": 0.8215717346261575
          },
          {
            "accuracy": 0.7733698130414957,
            "f1": 0.7715003180177658,
            "f1_weighted": 0.7764638410365297
          },
          {
            "accuracy": 0.7922936616507068,
            "f1": 0.7858247883498083,
            "f1_weighted": 0.7925126927596711
          },
          {
            "accuracy": 0.7371181030551756,
            "f1": 0.7312022303687193,
            "f1_weighted": 0.7455816679304439
          },
          {
            "accuracy": 0.8041495668034656,
            "f1": 0.8020823709617176,
            "f1_weighted": 0.8081714005498447
          },
          {
            "accuracy": 0.7897856817145463,
            "f1": 0.7743705754586105,
            "f1_weighted": 0.7912233365387273
          }
        ]
      }
    ],
    "validation": [
      {
        "accuracy": 0.7747203579418345,
        "f1": 0.7726894314579312,
        "f1_weighted": 0.7773517589985739,
        "hf_subset": "en",
        "languages": [
          "eng-Latn"
        ],
        "main_score": 0.7747203579418345,
        "scores_per_experiment": [
          {
            "accuracy": 0.7342281879194631,
            "f1": 0.7310107074404378,
            "f1_weighted": 0.7337866251006342
          },
          {
            "accuracy": 0.7736017897091723,
            "f1": 0.776763415055839,
            "f1_weighted": 0.7785488808269629
          },
          {
            "accuracy": 0.7861297539149888,
            "f1": 0.7774561596197038,
            "f1_weighted": 0.7868289778549443
          },
          {
            "accuracy": 0.7753914988814318,
            "f1": 0.7803349542997499,
            "f1_weighted": 0.7784219521850674
          },
          {
            "accuracy": 0.8080536912751678,
            "f1": 0.80371368392621,
            "f1_weighted": 0.8104085105931771
          },
          {
            "accuracy": 0.7700223713646532,
            "f1": 0.7720214939269282,
            "f1_weighted": 0.7739110054944013
          },
          {
            "accuracy": 0.778076062639821,
            "f1": 0.7729901821968143,
            "f1_weighted": 0.7778304861572816
          },
          {
            "accuracy": 0.7400447427293065,
            "f1": 0.7379456210376687,
            "f1_weighted": 0.7461197225295813
          },
          {
            "accuracy": 0.7959731543624161,
            "f1": 0.7990172285496708,
            "f1_weighted": 0.7999802642679367
          },
          {
            "accuracy": 0.7856823266219239,
            "f1": 0.775640868526289,
            "f1_weighted": 0.7876811649757522
          }
        ]
      }
    ]
  },
  "task_name": "MTOPDomainClassification"
}