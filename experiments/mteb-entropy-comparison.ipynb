{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses different layers of Llama3 as inputs to the MTEB (multitask embedding benchmark), which is an evaluation framework with a ton of datasets. The goal is to see if the layer-wise MTEB performance is correlated with entropy.\n",
    "\n",
    "Authors: Oscar Skean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GPT2LMHeadModel, GPT2Model, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from utils import get_model_path, get_dataloader, normalize, EleutherAI_sizes\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import repitl.matrix_itl as itl\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from transformers.utils import logging\n",
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wandb login # needed for llama access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_types = [\"baseline-llama\", \"llm2vec-unsupervised\", \"llm2vec-supervised\"]\n",
    "num_layers = 33\n",
    "task_names = [\"ArXivHierarchicalClusteringP2P\", \"Banking77Classification\",  \"EmotionClassification\", \"TwitterSemEval2015\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mteb\n",
    "from models.mteb_model_wrapper import baseline_llama3, llm2vec_llama3_8b_supervised, llm2vec_llama3_8b_unsupervised\n",
    "\n",
    "for model_type in model_types:\n",
    "    for layer in reversed(range(num_layers)):\n",
    "        if model_type == \"baseline-llama\":\n",
    "            model = baseline_llama3.loader(layer_cutoff=layer)\n",
    "        elif model_type == \"llm2vec-unsupervised\":\n",
    "            model = llm2vec_llama3_8b_unsupervised.loader(layer_cutoff=layer)\n",
    "        elif model_type == \"llm2vec-supervised\":\n",
    "            model = llm2vec_llama3_8b_supervised.loader(layer_cutoff=layer)\n",
    "        \n",
    "        # needed to properly neatly save to folder\n",
    "        model.mteb_model_meta = mteb.ModelMeta(\n",
    "                        name=model_type,\n",
    "                        revision=f\"layer-{layer}\",\n",
    "                        release_date=None,\n",
    "                        languages=None,\n",
    "                    )\n",
    "\n",
    "        #tasks = mteb.get_tasks(tasks=[\"Clustering\"])\n",
    "        tasks = mteb.get_tasks(tasks=task_names)\n",
    "\n",
    "        evaluation = mteb.MTEB(tasks=tasks)\n",
    "        results = evaluation.run(model)\n",
    "        del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mteb\n",
    "# from models.mteb_model_wrapper import baseline_llama3, llm2vec_llama3_8b_supervised\n",
    "# from utils import get_dataloader\n",
    "\n",
    "\n",
    "# model_name = \"baseline-llama\"\n",
    "\n",
    "# model = baseline_llama3.loader(layer_cutoff=2)\n",
    "# dataloader = get_dataloader(model.model.tokenizer, \"wikitext\", split=\"train\")\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for batch in tqdm.tqdm(dataloader):\n",
    "#         batch = {k: v.to(model.model.model.device) for k, v in batch.items()}\n",
    "#         outputs_2 = model.model.model(**batch)\n",
    "        \n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate layer entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mteb\n",
    "from models.mteb_model_wrapper import baseline_llama3, llm2vec_llama3_8b_supervised\n",
    "from utils import get_model_path, get_dataloader, normalize, EleutherAI_sizes\n",
    "from models.llm2vec import batch_to_device\n",
    "import torch\n",
    "import numpy as np\n",
    "import repitl.matrix_itl as itl\n",
    "\n",
    "def no_pooling_forward(model, sentence_feature):\n",
    "    if \"embed_mask\" in sentence_feature:\n",
    "        sentence_feature.pop(\"embed_mask\")\n",
    "    outputs = model.model(**sentence_feature)\n",
    "\n",
    "    return outputs.hidden_states\n",
    "\n",
    "def calculate_sentence_entropy(sentence_embeddings):\n",
    "    N, D = sentence_embeddings.shape\n",
    "\n",
    "\n",
    "    sentence_embeddings = normalize(sentence_embeddings)\n",
    "    if N > D:\n",
    "        cov = sentence_embeddings.T @ sentence_embeddings\n",
    "    else:\n",
    "        cov = (sentence_embeddings @ sentence_embeddings.T)\n",
    "    cov /= torch.trace(cov)\n",
    "    entropy = itl.matrixAlphaEntropy(cov, alpha=1)\n",
    "    logN_normalized_entropy = entropy / np.log(N)\n",
    "\n",
    "    return logN_normalized_entropy.item()\n",
    "\n",
    "def calculate_batch_entropy(features, embeddings):\n",
    "    seq_lengths = features[\"attention_mask\"].sum(dim=-1)\n",
    "\n",
    "    total_entropy = 0\n",
    "    for i, length in enumerate(seq_lengths):\n",
    "        sentence_entropy = calculate_sentence_entropy(embeddings[i, -length:, :].double())\n",
    "        total_entropy += sentence_entropy\n",
    "    \n",
    "    return total_entropy\n",
    "\n",
    "def encode_batch_and_get_layerwise_entropy(model, sentences_batch, layer_cutoff=-1, device=None):\n",
    "    model.to(device)\n",
    "    features = model.tokenize(\n",
    "        [model.prepare_for_tokenization(sentence) for sentence in sentences_batch]\n",
    "    )\n",
    "    features = batch_to_device(features, device)\n",
    "    with torch.no_grad():\n",
    "        embeddings = no_pooling_forward(model, features)\n",
    "\n",
    "        layerwise_entropies = []\n",
    "        for layer in range(len(embeddings)):\n",
    "            layerwise_entropies.append(calculate_batch_entropy(features, embeddings[layer].detach()))\n",
    "    return layerwise_entropies\n",
    "\n",
    "def encode_dataset_and_get_entropy(model, sentences, batch_size=8, device=None):\n",
    "    if isinstance(sentences[0], str) and isinstance(sentences[-1], int):\n",
    "        sentences = [sentences]\n",
    "    # required for MEDI version of MTEB\n",
    "    if isinstance(sentences[0], str):\n",
    "        sentences = [[\"\"] + [sentence] for sentence in sentences]\n",
    "\n",
    "    concatenated_input_texts = []\n",
    "    for sentence in sentences:\n",
    "        assert isinstance(sentence[0], str)\n",
    "        assert isinstance(sentence[1], str)\n",
    "        concatenated_input_texts.append(\n",
    "            model._convert_to_str(sentence[0], sentence[1])\n",
    "        )\n",
    "    sentences = concatenated_input_texts\n",
    "\n",
    "    model.eval()\n",
    "    length_sorted_idx = np.argsort([-model._text_length(sen) for sen in sentences])\n",
    "    sentences_sorted = [sentences[idx] for idx in length_sorted_idx]\n",
    "\n",
    "    batched_layerwise_entropies = []\n",
    "    for i in tqdm.tqdm(range(0, len(sentences_sorted), batch_size)):\n",
    "        sentences_batch = sentences_sorted[i : i + batch_size]\n",
    "\n",
    "        layerwise_entropies = encode_batch_and_get_layerwise_entropy(model, sentences_batch, device=device)\n",
    "        layerwise_entropies = [x / len(sentences_batch) for x in layerwise_entropies]\n",
    "        batched_layerwise_entropies.append(layerwise_entropies)\n",
    "\n",
    "    batched_layerwise_entropies = np.array(batched_layerwise_entropies)\n",
    "    batched_layerwise_entropies = np.mean(batched_layerwise_entropies, axis=0)\n",
    "    return batched_layerwise_entropies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mteb\n",
    "import glob\n",
    "import json\n",
    "\n",
    "\n",
    "import mteb\n",
    "from models.mteb_model_wrapper import baseline_llama3, llm2vec_llama3_8b_supervised, llm2vec_llama3_8b_unsupervised\n",
    "\n",
    "\n",
    "tasks = mteb.get_tasks(tasks=task_names)\n",
    "REDO_RESULTS = True\n",
    "NUM_SAMPLES=64\n",
    "\n",
    "for model_type in model_types:\n",
    "    if model_type == \"baseline-llama\":\n",
    "        model = baseline_llama3.loader()\n",
    "    elif model_type == \"llm2vec-unsupervised\":\n",
    "        model = llm2vec_llama3_8b_unsupervised.loader()\n",
    "    elif model_type == \"llm2vec-supervised\":\n",
    "        model = llm2vec_llama3_8b_supervised.loader()\n",
    "\n",
    "    model.model.eval()\n",
    "\n",
    "    for task in tasks:\n",
    "        # check if we've already calculated the entropy for this task\n",
    "        if not REDO_RESULTS:\n",
    "            with open(f\"results/{model_type}/layer-0/{task.metadata.name}.json\", \"r\") as f:\n",
    "                results = json.load(f)\n",
    "                if \"avg_layerwise_entropy\" in results:\n",
    "                    print(f\"Skipping {task.metadata.name} for {model_type} as it has already been calculated\")\n",
    "                    continue\n",
    "\n",
    "        # load data from HF\n",
    "        task.load_data(eval_splits=task.metadata.eval_splits)\n",
    "\n",
    "        # load inputs\n",
    "        task_dataset = task.dataset[\"test\"]\n",
    "        if \"sentences\" in task_dataset.features:\n",
    "            sentences = task_dataset[\"sentences\"]\n",
    "        elif \"text\" in task_dataset.features:\n",
    "            sentences = task_dataset[\"text\"]\n",
    "        else:\n",
    "            print(task.dataset)\n",
    "            print(task_dataset)\n",
    "            raise ValueError(\"Dataset does not contain sentences or text, unsure where data is living\")\n",
    "        \n",
    "        samples = sentences[0:NUM_SAMPLES]\n",
    "        avg_layerwise_entropy = encode_dataset_and_get_entropy(model.model, samples)\n",
    "\n",
    "        files = glob.glob(f\"results/{model_type}/layer-*/{task.metadata.name}.json\")\n",
    "        for file in files:\n",
    "            layer_num = int(file.split(\"/\")[2].split(\"-\")[1])\n",
    "\n",
    "            # save entropy to json results file\n",
    "            with open(file, \"r\") as f:\n",
    "                results = json.load(f)\n",
    "                results[\"avg_layerwise_entropy\"] = avg_layerwise_entropy[layer_num]\n",
    "                results[\"num_samples\"] = len(samples)\n",
    "                \n",
    "            with open(file, \"w\") as f:\n",
    "                json.dump(results, f)\n",
    "\n",
    "    del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "results_per_layer = {\n",
    "    model_type: {\n",
    "        task_name : {} for task_name in task_names\n",
    "    } for model_type in model_types\n",
    "}\n",
    "entropies_per_layer = {\n",
    "    model_type: {\n",
    "        task_name : {} for task_name in task_names\n",
    "    } for model_type in model_types\n",
    "}\n",
    "\n",
    "for model_type in model_types:\n",
    "    for task_name in task_names:\n",
    "        files = glob.glob(f\"results/{model_type}/layer-*/{task_name}.json\")\n",
    "        print(files)\n",
    "        for file in files:\n",
    "            layer_num = int(file.split(\"/\")[2].split(\"-\")[1])\n",
    "\n",
    "            with open(file, \"r\") as f:\n",
    "                file_json = json.load(f)\n",
    "            score = float(file_json[\"scores\"][\"test\"][0][\"main_score\"])\n",
    "            results_per_layer[model_type][task_name][layer_num] = score\n",
    "            entropies_per_layer[model_type][task_name][layer_num] = float(file_json[\"avg_layerwise_entropy\"])\n",
    "\n",
    "        results_per_layer[model_type][task_name] = pd.Series(results_per_layer[model_type][task_name])\n",
    "        results_per_layer[model_type][task_name] = results_per_layer[model_type][task_name].sort_index()\n",
    "\n",
    "        entropies_per_layer[model_type][task_name] = pd.Series(entropies_per_layer[model_type][task_name])\n",
    "        entropies_per_layer[model_type][task_name] = entropies_per_layer[model_type][task_name].sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_per_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(task_names), 2, figsize=(20, 15))\n",
    "for i, task_name in enumerate(task_names):\n",
    "    for j, model_name in enumerate(model_types):\n",
    "        axes[i, 0].plot(results_per_layer[model_name][task_name], label=model_name)\n",
    "        axes[i, 0].set_title(f\"Score {task_name}\")\n",
    "        axes[i, 0].set_xlabel(\"Layer\")\n",
    "        axes[i, 0].set_ylabel(\"Score\")\n",
    "\n",
    "        axes[i, 1].plot(entropies_per_layer[model_name][task_name], label=model_name)\n",
    "        axes[i, 1].set_title(f\"Entropy {task_name}\")\n",
    "        axes[i, 1].set_xlabel(\"Layer\")\n",
    "        axes[i, 1].set_ylabel(\"Entropy\")\n",
    "\n",
    "axes[0,0].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# compute correlation between results and entropy\n",
    "correlation = results_per_layer.corr(-entropies_per_layer, method=\"spearman\")\n",
    "print(\"total correlation\", correlation)\n",
    "\n",
    "# early layers correlations\n",
    "correlation = results_per_layer[:15].corr(-entropies_per_layer[:15], method=\"spearman\")\n",
    "print(\"first half correlation\", correlation)\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 10))\n",
    "results_per_layer.plot(ax=axes[0], title=\"Results per layer\")\n",
    "entropies_per_layer.plot(ax=axes[1], title=\"Entropy per layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #print(entropies_per_layer)\n",
    "\n",
    "# plt.scatter(results_per_layer[0:15], entropies_per_layer[0:15], color=\"red\")\n",
    "# plt.scatter(results_per_layer[15:], entropies_per_layer[15:], color=\"blue\")\n",
    "# plt.scatter(results_per_layer[0:3], entropies_per_layer[0:3], color=\"green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try more datasets\n",
    "try more models (llama instruct)\n",
    "try dataset that the model was trained on\n",
    "\n",
    "on ood data, should be less compression\n",
    "\tcan you interpolate between trained/untrained data and show how compression is controllable\n",
    "\t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "information_plane",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
