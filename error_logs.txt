2024-09-17 11:06:05.911528 >>> AmazonCounterfactualClassification
Traceback (most recent call last):
  File "/home/AD/ofsk222/miniconda3/envs/information_plane/lib/python3.10/site-packages/mteb/evaluation/MTEB.py", line 385, in run
    results, tick, tock = self._run_eval(
  File "/home/AD/ofsk222/miniconda3/envs/information_plane/lib/python3.10/site-packages/mteb/evaluation/MTEB.py", line 260, in _run_eval
    results = task.evaluate(
  File "/home/AD/ofsk222/miniconda3/envs/information_plane/lib/python3.10/site-packages/mteb/abstasks/AbsTaskClassification.py", line 102, in evaluate
    scores[hf_subset] = self._evaluate_subset(
  File "/home/AD/ofsk222/miniconda3/envs/information_plane/lib/python3.10/site-packages/mteb/abstasks/AbsTaskClassification.py", line 178, in _evaluate_subset
    scores_exp, test_cache = evaluator(model, test_cache=test_cache)
  File "/home/AD/ofsk222/miniconda3/envs/information_plane/lib/python3.10/site-packages/mteb/evaluation/evaluators/ClassificationEvaluator.py", line 296, in __call__
    X_train = model_encode(
  File "/home/AD/ofsk222/miniconda3/envs/information_plane/lib/python3.10/site-packages/mteb/evaluation/evaluators/model_encode.py", line 40, in model_encode
    embeddings = model.encode(sentences, **kwargs)
  File "/home/AD/ofsk222/miniconda3/envs/information_plane/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/AD/ofsk222/Research/exploration/information_plane/experiments/utils/model_definitions/mteb_automodel_wrapper.py", line 67, in encode
    optimal_batch_size = find_optimal_batch_size(self.model,
  File "/home/AD/ofsk222/miniconda3/envs/information_plane/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/AD/ofsk222/Research/exploration/information_plane/experiments/utils/misc/batch_size_utils.py", line 32, in find_optimal_batch_size
    model(**worst_case_batch)
  File "/home/AD/ofsk222/miniconda3/envs/information_plane/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/AD/ofsk222/miniconda3/envs/information_plane/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/AD/ofsk222/miniconda3/envs/information_plane/lib/python3.10/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py", line 895, in forward
    inputs_embeds = self.embed_in(input_ids)
  File "/home/AD/ofsk222/miniconda3/envs/information_plane/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/AD/ofsk222/miniconda3/envs/information_plane/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/AD/ofsk222/miniconda3/envs/information_plane/lib/python3.10/site-packages/torch/nn/modules/sparse.py", line 163, in forward
    return F.embedding(
  File "/home/AD/ofsk222/miniconda3/envs/information_plane/lib/python3.10/site-packages/torch/nn/functional.py", line 2264, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)


